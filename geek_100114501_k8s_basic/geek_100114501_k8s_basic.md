geek_100114501_k8s_basic

https://kubernetes.io/zh-cn/

æ“ä½œç³»ç»Ÿ

Ubuntu 22.04 Jammy Jellyfish æ¡Œé¢ç‰ˆ https://ubuntu.com/download/desktop

https://launchpad.net/ubuntu/+archivemirrors

https://launchpad.net/ubuntu/+cdmirrors

https://ftp.sjtu.edu.cn/ubuntu-cd/22.04.2/

å› ä¸º Kubernetes ä¸æ˜¯ä¸€èˆ¬çš„åº”ç”¨è½¯ä»¶, è€Œæ˜¯ä¸€ä¸ªå¤æ‚çš„ç³»ç»Ÿè½¯ä»¶, å¯¹ç¡¬ä»¶èµ„æºçš„è¦æ±‚æœ‰ä¸€ç‚¹é«˜, å¥½åœ¨å¹¶ä¸å¤ªé«˜, 2 æ ¸ CPU, 2G å†…å­˜æ˜¯æœ€ä½è¦æ±‚, å¦‚æœæ¡ä»¶å…è®¸, æˆ‘å»ºè®®æŠŠå†…å­˜å¢å¤§åˆ° 4G, ç¡¬ç›˜ 40G ä»¥ä¸Š, è¿™æ ·è¿è¡Œèµ·æ¥ä¼šæ›´æµç•…ä¸€äº›. å¦å¤–, ä¸€äº›å¯¹äºæœåŠ¡å™¨æ¥è¯´ä¸å¿…è¦çš„è®¾å¤‡ä¹Ÿå¯ä»¥ç¦ç”¨æˆ–è€…åˆ é™¤, æ¯”å¦‚å£°å¡, æ‘„åƒå¤´, è½¯é©±ç­‰ç­‰, å¯ä»¥èŠ‚çº¦ä¸€ç‚¹ç³»ç»Ÿèµ„æº. 

å¯¹äº VMWare Fusion, ä½ éœ€è¦åœ¨ "åå¥½è®¾ç½® - ç½‘ç»œ"é‡Œ, æ·»åŠ ä¸€ä¸ªè‡ªå®šä¹‰çš„ç½‘ç»œ, æ¯”å¦‚è¿™é‡Œçš„ "vmnet3", ç½‘æ®µæ˜¯ "192.168.10.0", å…è®¸ä½¿ç”¨ NAT è¿æ¥å¤–ç½‘, ç„¶ååœ¨è™šæ‹Ÿæœºçš„ç½‘ç»œè®¾ç½®é‡Œé€‰ç”¨è¿™ä¸ªç½‘ç»œ: 

åœ¨å®‰è£…çš„è¿‡ç¨‹ä¸­, ä¸ºäº†èŠ‚çº¦æ—¶é—´, å»ºè®®é€‰æ‹© "æœ€å°å®‰è£…", åŒæ—¶ç‰©ç†æ–­ç½‘, é¿å…ä¸‹è½½å‡çº§åŒ…. æ³¨æ„, æ–­ç½‘å¯¹äº Apple M1 æ¥è¯´ç‰¹åˆ«é‡è¦, å¦åˆ™ Ubuntu ä¼šè‡ªåŠ¨æ›´æ–°åˆ° 5.15 å†…æ ¸, å¯¼è‡´å®‰è£…åæ— æ³•æ­£å¸¸å¯åŠ¨. 

å®‰è£…å®Œ Linux ç³»ç»Ÿä¹‹å, æˆ‘ä»¬è¿˜è¦å†åšä¸€äº›ç¯å¢ƒçš„åˆå§‹åŒ–æ“ä½œ. 

sudo apt update
sudo apt install -y git vim curl jq

Ubuntu æ¡Œé¢ç‰ˆé»˜è®¤æ˜¯ä¸æ”¯æŒè¿œç¨‹ç™»å½•çš„, æ‰€ä»¥ä¸ºäº†è®©åç»­çš„å®éªŒæ›´åŠ ä¾¿åˆ©, æˆ‘ä»¬è¿˜éœ€è¦å®‰è£… "openssh-server", å†ä½¿ç”¨å‘½ä»¤ ip addr , æŸ¥çœ‹è™šæ‹Ÿæœºçš„ IP åœ°å€, ç„¶åå°±å¯ä»¥åœ¨å®¿ä¸»æœºä¸Šä½¿ç”¨ ssh å‘½ä»¤ç™»å½•è™šæ‹Ÿæœº: 



| ip              | hostname | hosts           |
| --------------- | -------- | --------------- |
| 192.168.116.150 | server01 | server01.k8s.ts |
| 192.168.116.151 | server02 | server02.k8s.ts |
| 192.168.116.152 | server03 | server03.k8s.ts |
| 192.168.116.153 | worker01 | worker01.k8s.ts |
| 192.168.116.154 | worker02 | worker02.k8s.ts |
| 192.168.116.155 | worker03 | worker03.k8s.ts |



```
192.168.116.150 server01 server01.k8s.ts
192.168.116.151 server01 server01.k8s.ts
192.168.116.152 server01 server01.k8s.ts
192.168.116.153 worker01 worker01.k8s.ts
192.168.116.154 worker02 worker02.k8s.ts
192.168.116.155 worker03 worker03.k8s.ts
```



è®¾ç½®æ—¶åŒº

[Ubuntuå¼€å¯NTPæ—¶é—´åŒæ­¥-é˜¿é‡Œäº‘å¼€å‘è€…ç¤¾åŒº (aliyun.com)](https://developer.aliyun.com/article/1141208)

```shell
ubuntu@server01:~$ cat /etc/localtime
TZif2UTCTZif2UTC
UTC0

ubuntu@server01:~$ timedatectl
               Local time: Tue 2023-03-28 11:14:26 UTC
           Universal time: Tue 2023-03-28 11:14:26 UTC
                 RTC time: Tue 2023-03-28 11:14:26
                Time zone: Etc/UTC (UTC, +0000)
System clock synchronized: yes
              NTP service: active
          RTC in local TZ: no

timedatectl list-timezones
ubuntu@server01:~$ timedatectl list-timezones | grep Shanghai
Asia/Shanghai

sudo timedatectl set-timezone Asia/Shanghai
```





```
$ resolvectl status | grep Current
      Current Scopes: DNS
  Current DNS Server: 192.168.1.1

root@server01:~# resolvectl status | grep Current
    Current Scopes: DNS
Current DNS Server: 192.168.116.2
Current Scopes: none

$ ping -c 5 server01

```

sudo apt install -y openssh-server
ip addr

ä¿®æ”¹ä¸»æœºå

hostnamectl set-hostname server01

cat /etc/hosts

127.0.0.1  localhost localhost.localdomain localhost4

apt install iputils-ping



10.1.1.11 web01 web01.itcast.cn



```yml
network:
    version: 2
    renderer: networkd
    ethernets:
        eth0:
            addresses:
                - 192.168.1.212/24
            nameservers:
                addresses: [8.8.8.8, 8.8.4.4]
            routes:
                - to: default
                  via: 192.168.1.2


$ sudo vi 00-installer-config.yaml
# This is the network config written by 'subiquity'
network:
  renderer: networkd
  ethernets:
    ens33:
      addresses:
        - 192.168.1.247/24
      nameservers:
        addresses: [4.2.2.2, 8.8.8.8]
      routes:
        - to: default
          via: 192.168.1.1
  version: 2

ubuntu server
# This is the network config written by 'subiquity'
network:
  ethernets:
    ens33:
      dhcp4: true
  version: 2

```



master, desktop 22.04.2 minimal install

worker, server 22.04.2 minimal install

servername: ut

user: ubuntu

password: Dm@8481

apt install vim

desktop ip addr

server ip addr

åœ¨ vmware ä¸Šå®‰è£…æ—¶



apt install open-vm-tools open-vm-tools-dev

é…ç½® ssh ç™»å½•

apt install openssh-server

cp /etc/ssh/sshd_config /etc/ssh/sshd_config.backup

vim /etc/ssh/sshd_config



PermitRootLogin yes-å…è®¸rootç™»å½•, è®¾ä¸ºyes. 
PermitRootLogin prohibit-password-å…è®¸rootç™»å½•, ä½†æ˜¯ç¦æ­¢rootç”¨å¯†ç ç™»å½•, è¿™è¡Œæ˜¯éœ€è¦è¢«æ³¨é‡Šæ‰çš„ï¼ï¼ï¼

```shell
# å…è®¸ root ç™»å½•
PermitRootLogin yes

# å…è®¸ä½¿ç”¨ ssh key éªŒè¯ç™»å½•
PubkeyAuthentication yes

```

å…å¯†ç™»å½•

git bash on windows ç”Ÿæˆ ssh key

ssh-keygen -t rsa

mkdir ~/.ssh

vim ~/.ssh/authorized_keys

chmod 700 ~/.ssh

chmod 600 ~/.ssh/authorized_keys

service sshd restart



æŸ¥çœ‹å½“å‰æ­£åœ¨ä½¿ç”¨çš„shell

```
âœ  ~ echo $SHELL
/bin/zsh
```

æŸ¥çœ‹ç³»ç»Ÿä¸­å®‰è£…äº†å“ªäº›shell

```
âœ  ~ cat /etc/shells
# List of acceptable shells for chpass(1).
# Ftpd will not allow users to connect who are not using
# one of these shells.

/bin/bash
/bin/csh
/bin/ksh
/bin/sh
/bin/tcsh
/bin/zsh
```

åˆ‡æ¢é»˜è®¤shell, åˆ‡æ¢åˆ°zsh

```
âœ  ~ chsh -s /bin/zsh
```

1.23 æ–‡æ¡£

https://v1-23.docs.kubernetes.io/

https://github.com/kubernetes/sig-release/tree/master/releases

https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md

ä½¿ç”¨ 1.23.17

ç®€å•æ¥è¯´, Kubernetes å°±æ˜¯ä¸€ä¸ªç”Ÿäº§çº§åˆ«çš„å®¹å™¨ç¼–æ’å¹³å°å’Œé›†ç¾¤ç®¡ç†ç³»ç»Ÿ, ä¸ä»…èƒ½å¤Ÿåˆ›å»º, è°ƒåº¦å®¹å™¨, è¿˜èƒ½å¤Ÿç›‘æ§, ç®¡ç†æœåŠ¡å™¨, å®ƒå‡èšäº† Google ç­‰å¤§å…¬å¸å’Œå¼€æºç¤¾åŒºçš„é›†ä½“æ™ºæ…§, ä»è€Œè®©ä¸­å°å‹å…¬å¸ä¹Ÿå¯ä»¥å…·å¤‡è½»æ¾è¿ç»´æµ·é‡è®¡ç®—èŠ‚ç‚¹â€”â€”ä¹Ÿå°±æ˜¯ "äº‘è®¡ç®—"çš„èƒ½åŠ›. 

### Docker

```shell
vmrun.exe snapshot C:\vmware\k8s\server01\server01.vmx 20230329-before-docker
vmrun.exe snapshot C:\vmware\k8s\worker01\worker01.vmx 20230329-before-docker
vmrun.exe snapshot C:\vmware\k8s\worker02\worker02.vmx 20230329-before-docker
vmrun.exe snapshot C:\vmware\k8s\worker03\worker03.vmx 20230329-before-docker

vmrun.exe start C:\vmware\k8s\server01\server01.vmx
vmrun.exe start C:\vmware\k8s\worker01\worker01.vmx
vmrun.exe start C:\vmware\k8s\worker02\worker02.vmx
vmrun.exe start C:\vmware\k8s\worker03\worker03.vmx
```



```shell
vmrun.exe clone C:\vmware\k8s\worker01\worker01.vmx C:\vmware\k8s\server02\server02.vmx full -snapshot=20230329-pull-k8s -cloneName=server02
vmrun.exe clone C:\vmware\k8s\worker01\worker01.vmx C:\vmware\k8s\server03\server03.vmx full -snapshot=20230329-pull-k8s -cloneName=server03
vmrun.exe start C:\vmware\k8s\server02\server02.vmx
```



## minikube

ä»€ä¹ˆæ˜¯ minikube

Kubernetes æä¾›äº†ä¸€äº›å¿«é€Ÿæ­å»º Kubernetes ç¯å¢ƒçš„å·¥å…·, åœ¨å®˜ç½‘ï¼ˆhttps://kubernetes.io/zh/docs/tasks/tools/)ä¸Šæ¨èçš„æœ‰ä¸¤ä¸ª: kind å’Œ minikube, å®ƒä»¬éƒ½å¯ä»¥åœ¨æœ¬æœºä¸Šè¿è¡Œå®Œæ•´çš„ Kubernetes ç¯å¢ƒ. 

å¦‚ä½•æ­å»º minikube ç¯å¢ƒ

https://minikube.sigs.k8s.io

### What youâ€™ll need

- 2 CPUs or more
- 2GB of free memory
- 20GB of free disk space
- Internet connection

### Installation

#### Linux

To install the latest minikube **stable** release on **x86-64** **Linux** using **Debian package**:

```shell
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube_latest_amd64.deb
sudo dpkg -i minikube_latest_amd64.deb

# alternative
# sudo install minikube /usr/local/bin/
minikube version
# minikube version: v1.29.0
# commit: ddac20b4b34a9c8c857fc602203b6ba2679794d3

```

#### windows

å®‰è£… vmware station

å®‰è£… minikube exe package

ç»™ vmware æ·»åŠ ç¯å¢ƒå˜é‡

ä½¿ç”¨ vmware driver å¯åŠ¨ minikube

https://minikube.sigs.k8s.io/docs/drivers/vmware/

D:\David\Desktop>minikube start --driver vmware
ğŸ˜„  Microsoft Windows 10 Pro 10.0.19045.2728 Build 19045.2728 ä¸Šçš„ minikube v1.29.0
âœ¨  æ ¹æ®ç°æœ‰çš„é…ç½®æ–‡ä»¶ä½¿ç”¨ vmware é©±åŠ¨ç¨‹åº
ğŸ‘  Starting control plane node minikube in cluster minikube
ğŸ’¾  Downloading Kubernetes v1.26.1 preload ...
    > preloaded-images-k8s-v18-v1...:  397.05 MiB / 397.05 MiB  100.00% 2.19 Mi
ğŸ”„  Restarting existing vmware VM for "minikube" ...
ğŸ¤¦  StartHost failed, but will try again: driver start: Machine didn't return an IP after 120 seconds, aborting
ğŸ”„  Restarting existing vmware VM for "minikube" ...
ğŸ˜¿  Failed to start vmware VM. Running "minikube delete" may fix it: driver start: Machine didn't return an IP after 120 seconds, aborting

âŒ  Exiting due to GUEST_PROVISION: Failed to start host: driver start: Machine didn't return an IP after 120 seconds, aborting

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                           â”‚
â”‚    ğŸ˜¿  If the above advice does not help, please let us know:                             â”‚
â”‚    ğŸ‘‰  https://github.com/kubernetes/minikube/issues/new/choose                           â”‚
â”‚                                                                                           â”‚
â”‚    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    â”‚
â”‚                                                                                           â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

### åˆ›å»º Kubernetes å®éªŒç¯å¢ƒ

ç”±äºå›½å†…ç½‘ç»œç¯å¢ƒä¸‹è½½ gcr.io çš„é•œåƒæ¯”è¾ƒå›°éš¾, minikube æä¾›äº†ç‰¹æ®Šçš„å¯åŠ¨å‚æ•°

--image-mirror-country=cn

--registry-mirror=xxx

--image-repository=xxx

minikube start æ— æ³•å¯åŠ¨ ç¾¤å‹å»ºè®®å°è¯•ä»¥ä¸‹å‘½ä»¤è§£å†³

minikube delete --all --purge

```shell
minikube start

# ä½¿ç”¨æŸç‰¹å®šçš„ç‰ˆæœ¬
# minikube start --kubernetes-version=v1.23.3

minikube start
* minikube v1.29.0 on Ubuntu 22.04 (amd64)
* Automatically selected the docker driver. Other choices: none, ssh
* Using Docker driver with root privileges
* Starting control plane node minikube in cluster minikube
* Pulling base image ...
* Downloading Kubernetes v1.26.1 preload ...
    > index.docker.io/kicbase/sta...:  407.18 MiB / 407.19 MiB  100.00% 9.67 Mi
    > preloaded-images-k8s-v18-v1...:  331.09 MiB / 397.05 MiB  83.39% 4.10 MiB! minikube was unable to download gcr.io/k8s-minikube/kicbase:v0.0.37, but successfully downloaded docker.io/kicbase/stable:v0.0.37 as a fallback image
    > preloaded-images-k8s-v18-v1...:  397.05 MiB / 397.05 MiB  100.00% 5.38 Mi
* Creating docker container (CPUs=2, Memory=2200MB) ...
* Preparing Kubernetes v1.26.1 on Docker 20.10.23 ...
  - Generating certificates and keys ...
  - Booting up control plane ...
  - Configuring RBAC rules ...
* Configuring bridge CNI (Container Networking Interface) ...
  - Using image gcr.io/k8s-minikube/storage-provisioner:v5
* Verifying Kubernetes components...
* Enabled addons: default-storageclass, storage-provisioner
* kubectl not found. If you need it, try: 'minikube kubectl -- get pods -A'
* Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
ubuntu@VM-0-23-ubuntu:~$ kubectl
Command 'kubectl' not found, but can be installed with:
sudo snap install kubectl



```



If minikube fails to start with command `minikube start`, see the [drivers page](https://minikube.sigs.k8s.io/docs/drivers/) for help setting up a compatible container or virtual-machine manager.

https://minikube.sigs.k8s.io/docs/drivers/

æŸ¥çœ‹é›†ç¾¤çš„çŠ¶æ€

```shell
minikube status
minikube node list
```



Kubernetes é›†ç¾¤é‡Œç°åœ¨åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹, åå­—å°±å« "minikube", ç±»å‹æ˜¯ "Control Plane", é‡Œé¢æœ‰ host, kubelet, apiserver ä¸‰ä¸ªæœåŠ¡, IP åœ°å€æ˜¯ 192.168.49.2. 

minikube ssh ç™»å½•åˆ°è¿™ä¸ªèŠ‚ç‚¹ä¸Š

```shell
ubuntu@VM-0-23-ubuntu:~$ minikube ssh
docker@minikube:~$
docker@minikube:~$ ps
    PID TTY          TIME CMD
  74871 pts/1    00:00:00 bash
  74900 pts/1    00:00:00 ps

docker@minikube:~$ docker images
REPOSITORY                                TAG       IMAGE ID       CREATED         SIZE
nginx                                     alpine    2bc7edbc3cf2   6 weeks ago     40.7MB
registry.k8s.io/kube-apiserver            v1.26.1   deb04688c4a3   2 months ago    134MB
registry.k8s.io/kube-controller-manager   v1.26.1   e9c08e11b07f   2 months ago    124MB
registry.k8s.io/kube-scheduler            v1.26.1   655493523f60   2 months ago    56.3MB
registry.k8s.io/kube-proxy                v1.26.1   46a6bb3c77ce   2 months ago    65.6MB
registry.k8s.io/etcd                      3.5.6-0   fce326961ae2   4 months ago    299MB
registry.k8s.io/pause                     3.9       e6f181688397   5 months ago    744kB
kubernetesui/dashboard                    <none>    07655ddf2eeb   6 months ago    246MB
kubernetesui/metrics-scraper              <none>    115053965e86   10 months ago   43.8MB
registry.k8s.io/coredns/coredns           v1.9.3    5185b96f0bec   10 months ago   48.8MB
registry.k8s.io/pause                     3.6       6270bb605e12   19 months ago   683kB
gcr.io/k8s-minikube/storage-provisioner   v5        6e38f40d628d   24 months ago   31.5MB

docker@minikube:~$ docker ps -a
CONTAINER ID   IMAGE                          COMMAND                  CREATED          STATUS                   PORTS     NAMES
e43737535cbc   kubernetesui/dashboard         "/dashboard --insecuâ€¦"   52 minutes ago   Up 52 minutes                      k8s_kubernetes-dashboard_kubernetes-dashboard-55c4cbbc7c-w7g7b_kubernetes-dashboard_4cf72413-4380-4f44-b8e9-747d4732e591_0
4cd6398a1a4b   kubernetesui/metrics-scraper   "/metrics-sidecar"       52 minutes ago   Up 52 minutes                      k8s_dashboard-metrics-scraper_dashboard-metrics-scraper-5c6664855-z2xsd_kubernetes-dashboard_b8960149-b03c-4eb7-8f16-8c86c510b1e7_0
cae50c92be20   registry.k8s.io/pause:3.6      "/pause"                 52 minutes ago   Up 52 minutes                      k8s_POD_dashboard-metrics-scraper-5c6664855-z2xsd_kubernetes-dashboard_b8960149-b03c-4eb7-8f16-8c86c510b1e7_0
4d7b3034fbac   registry.k8s.io/pause:3.6      "/pause"                 52 minutes ago   Up 52 minutes                      k8s_POD_kubernetes-dashboard-55c4cbbc7c-w7g7b_kubernetes-dashboard_4cf72413-4380-4f44-b8e9-747d4732e591_0
45c324a035ba   nginx                          "/docker-entrypoint.â€¦"   56 minutes ago   Up 56 minutes                      k8s_ngx_ngx_default_24a0addd-b436-4c25-aa5b-d8456c90f7b8_0
4982c3217931   registry.k8s.io/pause:3.6      "/pause"                 56 minutes ago   Up 56 minutes                      k8s_POD_ngx_default_24a0addd-b436-4c25-aa5b-d8456c90f7b8_0
e014878ced05   6e38f40d628d                   "/storage-provisioner"   2 hours ago      Up 2 hours                         k8s_storage-provisioner_storage-provisioner_kube-system_ddd42ef6-8056-4f16-89bb-c03dbc379d24_1
f1f7c434ec3e   5185b96f0bec                   "/coredns -conf /etcâ€¦"   2 hours ago      Up 2 hours                         k8s_coredns_coredns-787d4945fb-jh8mm_kube-system_150ab818-bc7e-4bf2-901f-f77e0f39366c_0
f6929c3ee52f   registry.k8s.io/pause:3.6      "/pause"                 2 hours ago      Up 2 hours                         k8s_POD_coredns-787d4945fb-jh8mm_kube-system_150ab818-bc7e-4bf2-901f-f77e0f39366c_0
fa93f139f97d   46a6bb3c77ce                   "/usr/local/bin/kubeâ€¦"   2 hours ago      Up 2 hours                         k8s_kube-proxy_kube-proxy-cxv9r_kube-system_44599790-45ff-4530-83da-98eb1814c84f_0
84cfd1435367   registry.k8s.io/pause:3.6      "/pause"                 2 hours ago      Up 2 hours                         k8s_POD_kube-proxy-cxv9r_kube-system_44599790-45ff-4530-83da-98eb1814c84f_0
7476782cf959   6e38f40d628d                   "/storage-provisioner"   2 hours ago      Exited (1) 2 hours ago             k8s_storage-provisioner_storage-provisioner_kube-system_ddd42ef6-8056-4f16-89bb-c03dbc379d24_0
c3df2d2e0ff6   registry.k8s.io/pause:3.6      "/pause"                 2 hours ago      Up 2 hours                         k8s_POD_storage-provisioner_kube-system_ddd42ef6-8056-4f16-89bb-c03dbc379d24_0
22abe45a714b   deb04688c4a3                   "kube-apiserver --adâ€¦"   2 hours ago      Up 2 hours                         k8s_kube-apiserver_kube-apiserver-minikube_kube-system_5239bb256c1be9f71fd10c884d9299b1_0
a449fadae57a   fce326961ae2                   "etcd --advertise-clâ€¦"   2 hours ago      Up 2 hours                         k8s_etcd_etcd-minikube_kube-system_a121e106627e5c6efa9ba48006cc43bf_0
04407e84a212   e9c08e11b07f                   "kube-controller-manâ€¦"   2 hours ago      Up 2 hours                         k8s_kube-controller-manager_kube-controller-manager-minikube_kube-system_5175bba984ed52052d891b5a45b584b6_0
191b52eef416   655493523f60                   "kube-scheduler --auâ€¦"   2 hours ago      Up 2 hours                         k8s_kube-scheduler_kube-scheduler-minikube_kube-system_197cd0de602d7cb722d0bd2daf878121_0
276d136a25d1   registry.k8s.io/pause:3.6      "/pause"                 2 hours ago      Up 2 hours                         k8s_POD_kube-scheduler-minikube_kube-system_197cd0de602d7cb722d0bd2daf878121_0
ddf8e8342aa9   registry.k8s.io/pause:3.6      "/pause"                 2 hours ago      Up 2 hours                         k8s_POD_etcd-minikube_kube-system_a121e106627e5c6efa9ba48006cc43bf_0
a1b6056bf379   registry.k8s.io/pause:3.6      "/pause"                 2 hours ago      Up 2 hours                         k8s_POD_kube-apiserver-minikube_kube-system_5239bb256c1be9f71fd10c884d9299b1_0
59a21faca399   registry.k8s.io/pause:3.6      "/pause"                 2 hours ago      Up 2 hours                         k8s_POD_kube-controller-manager-minikube_kube-system_5175bba984ed52052d891b5a45b584b6_0

```



Pause Kubernetes without impacting deployed applications:

```shell
minikube pause
```

Unpause a paused instance:

```shell
minikube unpause
```

Halt the cluster:

```shell
minikube stop
```

Change the default memory limit (requires a restart):

```shell
minikube config set memory 9001
```

Browse the catalog of easily installed Kubernetes services:

```shell
minikube addons list
```

Create a second cluster running an older Kubernetes release:

```shell
minikube start -p aged --kubernetes-version=v1.16.1
```

Delete all of the minikube clusters:

```shell
minikube delete --all
```

## kubectl

minikube åªèƒ½å¤Ÿæ­å»º Kubernetes ç¯å¢ƒ, è¦æ“ä½œ Kubernetes, è¿˜éœ€è¦å¦ä¸€ä¸ªä¸“é—¨çš„å®¢æˆ·ç«¯å·¥å…· "kubectl"

### è‡ªåŠ¨å®‰è£… kubectl

kubectl æ˜¯ä¸€ä¸ªä¸ Kubernetes, minikube å½¼æ­¤ç‹¬ç«‹çš„é¡¹ç›®, æ‰€ä»¥ä¸åŒ…å«åœ¨ minikube é‡Œ, ä½† minikube æä¾›äº†å®‰è£…å®ƒçš„ç®€åŒ–æ–¹å¼, ä½ åªéœ€æ‰§è¡Œä¸‹é¢çš„è¿™æ¡å‘½ä»¤: 

```shell
minikube kubectl
```

å®ƒå°±ä¼šæŠŠä¸å½“å‰ Kubernetes ç‰ˆæœ¬åŒ¹é…çš„ kubectl ä¸‹è½½ä¸‹æ¥, å­˜æ”¾åœ¨å†…éƒ¨ç›®å½•ï¼ˆä¾‹å¦‚ .minikube/cache/linux/arm64/v1.23.3), ç„¶åæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨å®ƒæ¥å¯¹ Kubernetes "å‘å·æ–½ä»¤"äº†. 

```
find / -name kubectl
/var/lib/docker/volumes/minikube/_data/lib/minikube/binaries/v1.26.1/kubectl

ubuntu@VM-0-23-ubuntu:~$ alias kubectl="minikube kubectl --"
ubuntu@VM-0-23-ubuntu:~$ kubectl
    > kubectl.sha256:  64 B / 64 B [-------------------------] 100.00% ? p/s 0s
    > kubectl:  45.80 MiB / 45.80 MiB [------------] 100.00% 16.28 MiB p/s 3.0s
kubectl controls the Kubernetes cluster manager.

Find more information at: https://kubernetes.io/docs/reference/kubectl/

Basic Commands (Beginner):
  create          Create a resource from a file or from stdin
  expose          Take a replication controller, service, deployment or pod and expose it as a new Kubernetes service
  run             Run a particular image on the cluster
  set             Set specific features on objects

Basic Commands (Intermediate):
  explain         Get documentation for a resource
  get             Display one or many resources
  edit            Edit a resource on the server
  delete          Delete resources by file names, stdin, resources and names, or by resources and label selector

Deploy Commands:
  rollout         Manage the rollout of a resource
  scale           Set a new size for a deployment, replica set, or replication controller
  autoscale       Auto-scale a deployment, replica set, stateful set, or replication controller

Cluster Management Commands:
  certificate     Modify certificate resources.
  cluster-info    Display cluster information
  top             Display resource (CPU/memory) usage
  cordon          Mark node as unschedulable
  uncordon        Mark node as schedulable
  drain           Drain node in preparation for maintenance
  taint           Update the taints on one or more nodes

Troubleshooting and Debugging Commands:
  describe        Show details of a specific resource or group of resources
  logs            Print the logs for a container in a pod
  attach          Attach to a running container
  exec            Execute a command in a container
  port-forward    Forward one or more local ports to a pod
  proxy           Run a proxy to the Kubernetes API server
  cp              Copy files and directories to and from containers
  auth            Inspect authorization
  debug           Create debugging sessions for troubleshooting workloads and nodes
  events          List events

Advanced Commands:
  diff            Diff the live version against a would-be applied version
  apply           Apply a configuration to a resource by file name or stdin
  patch           Update fields of a resource
  replace         Replace a resource by file name or stdin
  wait            Experimental: Wait for a specific condition on one or many resources
  kustomize       Build a kustomization target from a directory or URL.

Settings Commands:
  label           Update the labels on a resource
  annotate        Update the annotations on a resource
  completion      Output shell completion code for the specified shell (bash, zsh, fish, or powershell)

Other Commands:
  alpha           Commands for features in alpha
  api-resources   Print the supported API resources on the server
  api-versions    Print the supported API versions on the server, in the form of "group/version"
  config          Modify kubeconfig files
  plugin          Provides utilities for interacting with plugins
  version         Print the client and server version information

Usage:
  kubectl [flags] [options]

Use "kubectl <command> --help" for more information about a given command.
Use "kubectl options" for a list of global command-line options (applies to all commands).


```

### æ‰‹åŠ¨å®‰è£… kubectl

https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/#install-kubectl-binary-with-curl-on-linux

```bash
# å®‰è£…æœ€æ–° stable ç‰ˆæœ¬
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
# å®‰è£…æŒ‡å®šç‰ˆæœ¬
curl -LO https://dl.k8s.io/release/v1.26.0/bin/linux/amd64/kubectl

```

### kubctl å‘½ä»¤

```shell
ubuntu@VM-0-23-ubuntu:~$ kubectl version
WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
Client Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.1", GitCommit:"8f94681cd294aa8cfd3407b8191f6c70214973a4", GitTreeState:"clean", BuildDate:"2023-01-18T15:58:16Z", GoVersion:"go1.19.5", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v4.5.7
Server Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.1", GitCommit:"8f94681cd294aa8cfd3407b8191f6c70214973a4", GitTreeState:"clean", BuildDate:"2023-01-18T15:51:25Z", GoVersion:"go1.19.5", Compiler:"gc", Platform:"linux/amd64"}

ubuntu@VM-0-23-ubuntu:~$ kubectl version --output=yaml
clientVersion:
  buildDate: "2023-01-18T15:58:16Z"
  compiler: gc
  gitCommit: 8f94681cd294aa8cfd3407b8191f6c70214973a4
  gitTreeState: clean
  gitVersion: v1.26.1
  goVersion: go1.19.5
  major: "1"
  minor: "26"
  platform: linux/amd64
kustomizeVersion: v4.5.7
serverVersion:
  buildDate: "2023-01-18T15:51:25Z"
  compiler: gc
  gitCommit: 8f94681cd294aa8cfd3407b8191f6c70214973a4
  gitTreeState: clean
  gitVersion: v1.26.1
  goVersion: go1.19.5
  major: "1"
  minor: "26"
  platform: linux/amd64

ubuntu@VM-0-23-ubuntu:~$ kubectl version --output=json
{
  "clientVersion": {
    "major": "1",
    "minor": "26",
    "gitVersion": "v1.26.1",
    "gitCommit": "8f94681cd294aa8cfd3407b8191f6c70214973a4",
    "gitTreeState": "clean",
    "buildDate": "2023-01-18T15:58:16Z",
    "goVersion": "go1.19.5",
    "compiler": "gc",
    "platform": "linux/amd64"
  },
  "kustomizeVersion": "v4.5.7",
  "serverVersion": {
    "major": "1",
    "minor": "26",
    "gitVersion": "v1.26.1",
    "gitCommit": "8f94681cd294aa8cfd3407b8191f6c70214973a4",
    "gitTreeState": "clean",
    "buildDate": "2023-01-18T15:51:25Z",
    "goVersion": "go1.19.5",
    "compiler": "gc",
    "platform": "linux/amd64"
  }
}

```



### kubectl å‘½ä»¤è‡ªåŠ¨è¡¥å…¨

https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/#optional-kubectl-configurations-and-plugins

https://github.com/scop/bash-completion#installation

You now need to ensure that the kubectl completion script gets sourced in all your shell sessions. There are two ways in which you can do this:

```bash
echo 'source <(kubectl completion bash)' >>~/.bashrc
```

If you have an alias for kubectl, you can extend shell completion to work with that alias:

```bash
echo 'alias k=kubectl' >>~/.bashrc
echo 'complete -o default -F __start_kubectl k' >>~/.bashrc
```

**Note:** bash-completion sources all completion scripts in `/etc/bash_completion.d`.

#### Kubernetes é‡Œè¿è¡Œä¸€ä¸ª Nginx åº”ç”¨

ä¸‹é¢æˆ‘ä»¬åœ¨ Kubernetes é‡Œè¿è¡Œä¸€ä¸ª Nginx åº”ç”¨, å‘½ä»¤ä¸ Docker ä¸€æ ·, ä¹Ÿæ˜¯ run, ä¸è¿‡å½¢å¼ä¸Šæœ‰ç‚¹åŒºåˆ«, éœ€è¦ç”¨ --image æŒ‡å®šé•œåƒ, ç„¶å Kubernetes ä¼šè‡ªåŠ¨æ‹‰å–å¹¶è¿è¡Œ: 

```shell

ubuntu@VM-0-23-ubuntu:~$ kubectl run ngx --image=nginx:alpine
pod/ngx created
ubuntu@VM-0-23-ubuntu:~$ kubectl get pod
NAME   READY   STATUS    RESTARTS   AGE
ngx    1/1     Running   0          10s

ubuntu@VM-0-23-ubuntu:~$ kubectl get po -A
NAMESPACE     NAME                               READY   STATUS    RESTARTS      AGE
default       ngx                                1/1     Running   0             3m44s
kube-system   coredns-787d4945fb-jh8mm           1/1     Running   0             52m
kube-system   etcd-minikube                      1/1     Running   0             52m
kube-system   kube-apiserver-minikube            1/1     Running   0             52m
kube-system   kube-controller-manager-minikube   1/1     Running   0             52m
kube-system   kube-proxy-cxv9r                   1/1     Running   0             52m
kube-system   kube-scheduler-minikube            1/1     Running   0             52m
kube-system   storage-provisioner                1/1     Running   1 (51m ago)   52m

```

æ³¨: READY æ˜¾ç¤ºçš„æ˜¯ Pod å†…éƒ¨çš„å®¹å™¨çŠ¶æ€, æ ¼å¼æ˜¯ x/y, è¡¨ç¤º Pod ä¸­ä¸€å…±å®šä¹‰äº† y ä¸ªå®¹å™¨, å…¶ä¸­ x ä¸ªæ˜¯æ­£å¸¸çš„ ready

### Kubernetes æ¶æ„å’Œç»„ä»¶ä»‹ç»

Kubernetes é‡‡ç”¨äº†ç°ä»Šæµè¡Œçš„ "æ§åˆ¶é¢ / æ•°æ®é¢"ï¼ˆControl Plane / Data Plane)æ¶æ„, é›†ç¾¤é‡Œçš„è®¡ç®—æœºè¢«ç§°ä¸º "èŠ‚ç‚¹"ï¼ˆNode), å¯ä»¥æ˜¯å®æœºä¹Ÿå¯ä»¥æ˜¯è™šæœº, å°‘é‡çš„èŠ‚ç‚¹ç”¨ä½œæ§åˆ¶é¢æ¥æ‰§è¡Œé›†ç¾¤çš„ç®¡ç†ç»´æŠ¤å·¥ä½œ, å…¶ä»–çš„å¤§éƒ¨åˆ†èŠ‚ç‚¹éƒ½è¢«åˆ’å½’æ•°æ®é¢, ç”¨æ¥è·‘ä¸šåŠ¡åº”ç”¨. 

æ§åˆ¶é¢çš„èŠ‚ç‚¹åœ¨ Kubernetes é‡Œå«åš Master Node, ä¸€èˆ¬ç®€ç§°ä¸º Master, å®ƒæ˜¯æ•´ä¸ªé›†ç¾¤é‡Œæœ€é‡è¦çš„éƒ¨åˆ†, å¯ä»¥è¯´æ˜¯ Kubernetes çš„å¤§è„‘å’Œå¿ƒè„. 

æ•°æ®é¢çš„èŠ‚ç‚¹å«åš Worker Node, ä¸€èˆ¬å°±ç®€ç§°ä¸º Worker æˆ–è€… Node, ç›¸å½“äº Kubernetes çš„æ‰‹å’Œè„š, åœ¨ Master çš„æŒ‡æŒ¥ä¸‹å¹²æ´». 

æŸ¥çœ‹ Kubernetes çš„èŠ‚ç‚¹çŠ¶æ€

```shell
kubectl get node
ubuntu@VM-0-23-ubuntu:~$ kubectl get node
NAME       STATUS   ROLES           AGE    VERSION
minikube   Ready    control-plane   114m   v1.26.1

```

Master å’Œ Node çš„åˆ’åˆ†ä¸æ˜¯ç»å¯¹çš„. å½“é›†ç¾¤çš„è§„æ¨¡è¾ƒå°, å·¥ä½œè´Ÿè½½è¾ƒå°‘çš„æ—¶å€™, Master ä¹Ÿå¯ä»¥æ‰¿æ‹… Node çš„å·¥ä½œ, å°±åƒæˆ‘ä»¬æ­å»ºçš„ minikube ç¯å¢ƒ, å®ƒå°±åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹, è¿™ä¸ªèŠ‚ç‚¹æ—¢æ˜¯ Master åˆæ˜¯ Node. 

#### Master é‡Œçš„ç»„ä»¶æœ‰å“ªäº›

ä¸ºäº†ç¡®ä¿æ§åˆ¶é¢çš„é«˜å¯ç”¨, Kubernetes é›†ç¾¤é‡Œéƒ½ä¼šéƒ¨ç½²å¤šä¸ª Master èŠ‚ç‚¹, æ•°é‡ä¸€èˆ¬ä¼šæ˜¯å¥‡æ•° 3/5/7

Master é‡Œæœ‰ 4 ä¸ªç»„ä»¶, åˆ†åˆ«æ˜¯ apiserver, etcd, scheduler, controller-manager. 

- apiserver æ˜¯ Master èŠ‚ç‚¹â€”â€”åŒæ—¶ä¹Ÿæ˜¯æ•´ä¸ª Kubernetes ç³»ç»Ÿçš„å”¯ä¸€å…¥å£, å®ƒå¯¹å¤–å…¬å¼€äº†ä¸€ç³»åˆ—çš„ RESTful API, å¹¶ä¸”åŠ ä¸Šäº†éªŒè¯, æˆæƒç­‰åŠŸèƒ½, æ‰€æœ‰å…¶ä»–ç»„ä»¶éƒ½åªèƒ½å’Œå®ƒç›´æ¥é€šä¿¡, å¯ä»¥è¯´æ˜¯ Kubernetes é‡Œçš„è”ç»œå‘˜. 

- etcd æ˜¯ä¸€ä¸ªé«˜å¯ç”¨çš„åˆ†å¸ƒå¼ Key-Value æ•°æ®åº“, ç”¨æ¥æŒä¹…åŒ–å­˜å‚¨ç³»ç»Ÿé‡Œçš„å„ç§èµ„æºå¯¹è±¡å’ŒçŠ¶æ€, ç›¸å½“äº Kubernetes é‡Œçš„é…ç½®ç®¡ç†å‘˜. æ³¨æ„å®ƒåªä¸ apiserver æœ‰ç›´æ¥è”ç³», ä¹Ÿå°±æ˜¯è¯´ä»»ä½•å…¶ä»–ç»„ä»¶æƒ³è¦è¯»å†™ etcd é‡Œçš„æ•°æ®éƒ½å¿…é¡»ç»è¿‡ apiserver. 

- scheduler è´Ÿè´£å®¹å™¨çš„ç¼–æ’å·¥ä½œ, æ£€æŸ¥èŠ‚ç‚¹çš„èµ„æºçŠ¶æ€, æŠŠ Pod è°ƒåº¦åˆ°æœ€é€‚åˆçš„èŠ‚ç‚¹ä¸Šè¿è¡Œ, ç›¸å½“äºéƒ¨ç½²äººå‘˜. å› ä¸ºèŠ‚ç‚¹çŠ¶æ€å’Œ Pod ä¿¡æ¯éƒ½å­˜å‚¨åœ¨ etcd é‡Œ, æ‰€ä»¥ scheduler å¿…é¡»é€šè¿‡ apiserver æ‰èƒ½è·å¾—. 

- controller-manager è´Ÿè´£ç»´æŠ¤å®¹å™¨å’ŒèŠ‚ç‚¹ç­‰èµ„æºçš„çŠ¶æ€, å®ç°æ•…éšœæ£€æµ‹, æœåŠ¡è¿ç§», åº”ç”¨ä¼¸ç¼©ç­‰åŠŸèƒ½, ç›¸å½“äºç›‘æ§è¿ç»´äººå‘˜. åŒæ ·åœ°, å®ƒä¹Ÿå¿…é¡»é€šè¿‡ apiserver è·å¾—å­˜å‚¨åœ¨ etcd é‡Œçš„ä¿¡æ¯, æ‰èƒ½å¤Ÿå®ç°å¯¹èµ„æºçš„å„ç§æ“ä½œ. 
  - controller-manager æ˜¯å¾ˆå¤šä¸ª controller çš„é›†åˆä½“, æ¯ä¸€ä¸ª controller è´Ÿè´£ä¸€ç§æ§åˆ¶å¾ªç¯, å¦‚ node controller, namespace controller, ä½†ä¸ºäº†ç®€ä½“è¢«åˆå¹¶åˆ°ä¸€ä¸ªè¿›ç¨‹ä¸­æ‰§è¡Œäº†

è¿™ 4 ä¸ªç»„ä»¶ä¹Ÿéƒ½è¢«å®¹å™¨åŒ–äº†, è¿è¡Œåœ¨é›†ç¾¤çš„ Pod é‡Œ, æˆ‘ä»¬å¯ä»¥ç”¨ kubectl æ¥æŸ¥çœ‹å®ƒä»¬çš„çŠ¶æ€, ä½¿ç”¨å‘½ä»¤: 

```shell

kubectl get pod -n kube-system
# -n kube-system å‚æ•°, è¡¨ç¤ºæ£€æŸ¥ "kube-system"åå­—ç©ºé—´é‡Œçš„ Pod

ubuntu@VM-0-23-ubuntu:~$ kubectl get pod -n kube-system
NAME                               READY   STATUS    RESTARTS       AGE
coredns-787d4945fb-jh8mm           1/1     Running   0              116m
etcd-minikube                      1/1     Running   0              116m
kube-apiserver-minikube            1/1     Running   0              116m
kube-controller-manager-minikube   1/1     Running   0              116m
kube-proxy-cxv9r                   1/1     Running   0              116m
kube-scheduler-minikube            1/1     Running   0              116m
storage-provisioner                1/1     Running   1 (115m ago)   116m

```

#### Node é‡Œçš„ç»„ä»¶æœ‰å“ªäº›

è¿™å°±éœ€è¦ Node é‡Œçš„ 3 ä¸ªç»„ä»¶äº†, åˆ†åˆ«æ˜¯ kubelet, kube-proxy, container-runtime. 

- kubelet æ˜¯ Node çš„ä»£ç†, è´Ÿè´£ç®¡ç† Node ç›¸å…³çš„ç»å¤§éƒ¨åˆ†æ“ä½œ, Node ä¸Šåªæœ‰å®ƒèƒ½å¤Ÿä¸ apiserver é€šä¿¡, å®ç°çŠ¶æ€æŠ¥å‘Š, å‘½ä»¤ä¸‹å‘, å¯åœå®¹å™¨ç­‰åŠŸèƒ½, ç›¸å½“äºæ˜¯ Node ä¸Šçš„ä¸€ä¸ª "å°ç®¡å®¶". 

- kube-proxy çš„ä½œç”¨æœ‰ç‚¹ç‰¹åˆ«, å®ƒæ˜¯ Node çš„ç½‘ç»œä»£ç†, åªè´Ÿè´£ç®¡ç†å®¹å™¨çš„ç½‘ç»œé€šä¿¡, ç®€å•æ¥è¯´å°±æ˜¯ä¸º Pod è½¬å‘ TCP/UDP æ•°æ®åŒ…, ç›¸å½“äºæ˜¯ä¸“èŒçš„ "å°é‚®å·®". 

- ç¬¬ä¸‰ä¸ªç»„ä»¶ container-runtime æˆ‘ä»¬å°±æ¯”è¾ƒç†Ÿæ‚‰äº†, å®ƒæ˜¯å®¹å™¨å’Œé•œåƒçš„å®é™…ä½¿ç”¨è€…, åœ¨ kubelet çš„æŒ‡æŒ¥ä¸‹åˆ›å»ºå®¹å™¨, ç®¡ç† Pod çš„ç”Ÿå‘½å‘¨æœŸ, æ˜¯çœŸæ­£å¹²æ´»çš„ "è‹¦åŠ›". 

è¿™ 3 ä¸ªç»„ä»¶ä¸­åªæœ‰ kube-proxy è¢«å®¹å™¨åŒ–äº†, è€Œ kubelet å› ä¸ºå¿…é¡»è¦ç®¡ç†æ•´ä¸ªèŠ‚ç‚¹, å®¹å™¨åŒ–ä¼šé™åˆ¶å®ƒçš„èƒ½åŠ›, æ‰€ä»¥å®ƒå¿…é¡»åœ¨ container-runtime ä¹‹å¤–è¿è¡Œ. 

ä½¿ç”¨ minikube ssh å‘½ä»¤ç™»å½•åˆ°èŠ‚ç‚¹å, å¯ä»¥ç”¨ docker ps çœ‹åˆ° kube-proxy: 

```shell
minikube ssh
docker ps |grep kube-proxy

ubuntu@VM-0-23-ubuntu:~$ minikube ssh
Last login: Mon Mar 27 02:29:39 2023 from 192.168.49.1
docker@minikube:~$ docker ps |grep kube-proxy
fa93f139f97d   46a6bb3c77ce                   "/usr/local/bin/kubeâ€¦"   2 hours ago         Up 2 hours                   k8s_kube-proxy_kube-proxy-cxv9r_kube-system_44599790-45ff-4530-83da-98eb1814c84f_0
84cfd1435367   registry.k8s.io/pause:3.6      "/pause"                 2 hours ago         Up 2 hours                   k8s_POD_kube-proxy-cxv9r_kube-system_44599790-45ff-4530-83da-98eb1814c84f_0

uname -a  #æ˜¾ç¤ºæ˜¯Ubuntuæ“ä½œç³»ç»Ÿ
docker version #è¿™ä¸ªèŠ‚ç‚¹é‡Œä¹Ÿè·‘äº†ä¸€ä¸ªdocker, ä½†å…¶å®æ˜¯å¤ç”¨äº†å®¿ä¸»æœºçš„docker
docker ps    #èƒ½å¤Ÿçœ‹åˆ°èŠ‚ç‚¹é‡Œä»¥å®¹å™¨å½¢å¼è¿è¡Œçš„Kubernetesè¿›ç¨‹, æ¯”å¦‚pause, schedulerç­‰ç­‰
exit

```

è€Œ kubelet ç”¨ docker ps æ˜¯æ‰¾ä¸åˆ°çš„, éœ€è¦ç”¨æ“ä½œç³»ç»Ÿçš„ ps å‘½ä»¤: 

```shell
ps -ef|grep kubelet

docker@minikube:~$ ps -ef|grep kubelet
root        1888    1827  3 00:44 ?        00:03:47 kube-apiserver --advertise-address=192.168.49.2 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/var/lib/minikube/certs/ca.crt --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota --enable-bootstrap-token-auth=true --etcd-cafile=/var/lib/minikube/certs/etcd/ca.crt --etcd-certfile=/var/lib/minikube/certs/apiserver-etcd-client.crt --etcd-keyfile=/var/lib/minikube/certs/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --kubelet-client-certificate=/var/lib/minikube/certs/apiserver-kubelet-client.crt --kubelet-client-key=/var/lib/minikube/certs/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/var/lib/minikube/certs/front-proxy-client.crt --proxy-client-key-file=/var/lib/minikube/certs/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/var/lib/minikube/certs/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=8443 --service-account-issuer=https://kubernetes.default.svc.cluster.local --service-account-key-file=/var/lib/minikube/certs/sa.pub --service-account-signing-key-file=/var/lib/minikube/certs/sa.key --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/var/lib/minikube/certs/apiserver.crt --tls-private-key-file=/var/lib/minikube/certs/apiserver.key
root        2089       1  1 00:44 ?        00:01:55 /var/lib/minikube/binaries/v1.26.1/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=/var/run/cri-dockerd.sock --hostname-override=minikube --image-service-endpoint=/var/run/cri-dockerd.sock --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2
```

è¿™äº› pod ä¸ä½¿ç”¨ `minikube ssh` å‘½ä»¤è¿›å…¥ minikube system ä¸­ä½¿ç”¨ `docker ps -a` å’Œ `docker images` å¾—åˆ°çš„å®¹å™¨å’Œé•œåƒæ˜¯å¯¹åº”çš„

#### Kubernetes çš„å¤§è‡´å·¥ä½œæµç¨‹

æŠŠ Node é‡Œçš„ç»„ä»¶å’Œ Master é‡Œçš„ç»„ä»¶æ”¾åœ¨ä¸€èµ·æ¥çœ‹, å°±èƒ½å¤Ÿæ˜ç™½ Kubernetes çš„å¤§è‡´å·¥ä½œæµç¨‹äº†: 

æ¯ä¸ª Node ä¸Šçš„ kubelet ä¼šå®šæœŸå‘ apiserver ä¸ŠæŠ¥èŠ‚ç‚¹çŠ¶æ€, apiserver å†å­˜åˆ° etcd é‡Œ. 

æ¯ä¸ª Node ä¸Šçš„ kube-proxy å®ç°äº† TCP/UDP åå‘ä»£ç†, è®©å®¹å™¨å¯¹å¤–æä¾›ç¨³å®šçš„æœåŠ¡. 

scheduler é€šè¿‡ apiserver å¾—åˆ°å½“å‰çš„èŠ‚ç‚¹çŠ¶æ€, è°ƒåº¦ Pod, ç„¶å apiserver ä¸‹å‘å‘½ä»¤ç»™æŸä¸ª Node çš„ kubelet, kubelet è°ƒç”¨ container-runtime å¯åŠ¨å®¹å™¨. 

controller-manager ä¹Ÿé€šè¿‡ apiserver å¾—åˆ°å®æ—¶çš„èŠ‚ç‚¹çŠ¶æ€, ç›‘æ§å¯èƒ½çš„å¼‚å¸¸æƒ…å†µ, å†ä½¿ç”¨ç›¸åº”çš„æ‰‹æ®µå»è°ƒèŠ‚æ¢å¤. 

#### Kubernetes æ’ä»¶ Addon

```
minikube addons list

ubuntu@VM-0-23-ubuntu:~$ minikube addons list
|-----------------------------|----------|--------------|--------------------------------|
|         ADDON NAME          | PROFILE  |    STATUS    |           MAINTAINER           |
|-----------------------------|----------|--------------|--------------------------------|
| ambassador                  | minikube | disabled     | 3rd party (Ambassador)         |
| auto-pause                  | minikube | disabled     | Google                         |
| cloud-spanner               | minikube | disabled     | Google                         |
| csi-hostpath-driver         | minikube | disabled     | Kubernetes                     |
| dashboard                   | minikube | enabled âœ…   | Kubernetes                     |
| default-storageclass        | minikube | enabled âœ…   | Kubernetes                     |
| efk                         | minikube | disabled     | 3rd party (Elastic)            |
| freshpod                    | minikube | disabled     | Google                         |
| gcp-auth                    | minikube | disabled     | Google                         |
| gvisor                      | minikube | disabled     | Google                         |
| headlamp                    | minikube | disabled     | 3rd party (kinvolk.io)         |
| helm-tiller                 | minikube | disabled     | 3rd party (Helm)               |
| inaccel                     | minikube | disabled     | 3rd party (InAccel             |
|                             |          |              | [info@inaccel.com])            |
| ingress                     | minikube | disabled     | Kubernetes                     |
| ingress-dns                 | minikube | disabled     | Google                         |
| istio                       | minikube | disabled     | 3rd party (Istio)              |
| istio-provisioner           | minikube | disabled     | 3rd party (Istio)              |
| kong                        | minikube | disabled     | 3rd party (Kong HQ)            |
| kubevirt                    | minikube | disabled     | 3rd party (KubeVirt)           |
| logviewer                   | minikube | disabled     | 3rd party (unknown)            |
| metallb                     | minikube | disabled     | 3rd party (MetalLB)            |
| metrics-server              | minikube | disabled     | Kubernetes                     |
| nvidia-driver-installer     | minikube | disabled     | Google                         |
| nvidia-gpu-device-plugin    | minikube | disabled     | 3rd party (Nvidia)             |
| olm                         | minikube | disabled     | 3rd party (Operator Framework) |
| pod-security-policy         | minikube | disabled     | 3rd party (unknown)            |
| portainer                   | minikube | disabled     | 3rd party (Portainer.io)       |
| registry                    | minikube | disabled     | Google                         |
| registry-aliases            | minikube | disabled     | 3rd party (unknown)            |
| registry-creds              | minikube | disabled     | 3rd party (UPMC Enterprises)   |
| storage-provisioner         | minikube | enabled âœ…   | Google                         |
| storage-provisioner-gluster | minikube | disabled     | 3rd party (Gluster)            |
| volumesnapshots             | minikube | disabled     | Kubernetes                     |
|-----------------------------|----------|--------------|--------------------------------|

```

### Kubernetes API å¯¹è±¡

https://kubernetes.io/docs/reference/kubernetes-api/

å› ä¸º apiserver æ˜¯ Kubernetes ç³»ç»Ÿçš„å”¯ä¸€å…¥å£, å¤–éƒ¨ç”¨æˆ·å’Œå†…éƒ¨ç»„ä»¶éƒ½å¿…é¡»å’Œå®ƒé€šä¿¡, è€Œå®ƒé‡‡ç”¨äº† HTTP åè®®çš„ URL èµ„æºç†å¿µ, API é£æ ¼ä¹Ÿç”¨ RESTful çš„ GET/POST/DELETE ç­‰ç­‰, æ‰€ä»¥, è¿™äº›æ¦‚å¿µå¾ˆè‡ªç„¶åœ°å°±è¢«ç§°ä¸ºæ˜¯ "API å¯¹è±¡"äº†. 

kubectl api-resources æ¥æŸ¥çœ‹å½“å‰ Kubernetes ç‰ˆæœ¬æ”¯æŒçš„æ‰€æœ‰å¯¹è±¡

å› ä¸º kubernetes çš„å¼€å‘è¯­è¨€æ˜¯ Go, API å¯¹è±¡çš„å‘½åéµå¾ª Camel Case é£æ ¼

```shell

ubuntu@VM-0-23-ubuntu:~$ kubectl api-resources
NAME                              SHORTNAMES   APIVERSION                             NAMESPACED   KIND
bindings                                       v1                                     true         Binding
componentstatuses                 cs           v1                                     false        ComponentStatus
configmaps                        cm           v1                                     true         ConfigMap
endpoints                         ep           v1                                     true         Endpoints
events                            ev           v1                                     true         Event
limitranges                       limits       v1                                     true         LimitRange
namespaces                        ns           v1                                     false        Namespace
nodes                             no           v1                                     false        Node
persistentvolumeclaims            pvc          v1                                     true         PersistentVolumeClaim
persistentvolumes                 pv           v1                                     false        PersistentVolume
pods                              po           v1                                     true         Pod
podtemplates                                   v1                                     true         PodTemplate
replicationcontrollers            rc           v1                                     true         ReplicationController
resourcequotas                    quota        v1                                     true         ResourceQuota
secrets                                        v1                                     true         Secret
serviceaccounts                   sa           v1                                     true         ServiceAccount
services                          svc          v1                                     true         Service
mutatingwebhookconfigurations                  admissionregistration.k8s.io/v1        false        MutatingWebhookConfiguration
validatingwebhookconfigurations                admissionregistration.k8s.io/v1        false        ValidatingWebhookConfiguration
customresourcedefinitions         crd,crds     apiextensions.k8s.io/v1                false        CustomResourceDefinition
apiservices                                    apiregistration.k8s.io/v1              false        APIService
controllerrevisions                            apps/v1                                true         ControllerRevision
daemonsets                        ds           apps/v1                                true         DaemonSet
deployments                       deploy       apps/v1                                true         Deployment
replicasets                       rs           apps/v1                                true         ReplicaSet
statefulsets                      sts          apps/v1                                true         StatefulSet
tokenreviews                                   authentication.k8s.io/v1               false        TokenReview
localsubjectaccessreviews                      authorization.k8s.io/v1                true         LocalSubjectAccessReview
selfsubjectaccessreviews                       authorization.k8s.io/v1                false        SelfSubjectAccessReview
selfsubjectrulesreviews                        authorization.k8s.io/v1                false        SelfSubjectRulesReview
subjectaccessreviews                           authorization.k8s.io/v1                false        SubjectAccessReview
horizontalpodautoscalers          hpa          autoscaling/v2                         true         HorizontalPodAutoscaler
cronjobs                          cj           batch/v1                               true         CronJob
jobs                                           batch/v1                               true         Job
certificatesigningrequests        csr          certificates.k8s.io/v1                 false        CertificateSigningRequest
leases                                         coordination.k8s.io/v1                 true         Lease
endpointslices                                 discovery.k8s.io/v1                    true         EndpointSlice
events                            ev           events.k8s.io/v1                       true         Event
flowschemas                                    flowcontrol.apiserver.k8s.io/v1beta3   false        FlowSchema
prioritylevelconfigurations                    flowcontrol.apiserver.k8s.io/v1beta3   false        PriorityLevelConfiguration
ingressclasses                                 networking.k8s.io/v1                   false        IngressClass
ingresses                         ing          networking.k8s.io/v1                   true         Ingress
networkpolicies                   netpol       networking.k8s.io/v1                   true         NetworkPolicy
runtimeclasses                                 node.k8s.io/v1                         false        RuntimeClass
poddisruptionbudgets              pdb          policy/v1                              true         PodDisruptionBudget
clusterrolebindings                            rbac.authorization.k8s.io/v1           false        ClusterRoleBinding
clusterroles                                   rbac.authorization.k8s.io/v1           false        ClusterRole
rolebindings                                   rbac.authorization.k8s.io/v1           true         RoleBinding
roles                                          rbac.authorization.k8s.io/v1           true         Role
priorityclasses                   pc           scheduling.k8s.io/v1                   false        PriorityClass
csidrivers                                     storage.k8s.io/v1                      false        CSIDriver
csinodes                                       storage.k8s.io/v1                      false        CSINode
csistoragecapacities                           storage.k8s.io/v1                      true         CSIStorageCapacity
storageclasses                    sc           storage.k8s.io/v1                      false        StorageClass
volumeattachments                              storage.k8s.io/v1                      false        VolumeAttachment

```

kubectl å‘½ä»¤çš„æ—¶å€™, ä½ è¿˜å¯ä»¥åŠ ä¸Šä¸€ä¸ªå‚æ•° --v=9, å®ƒä¼šæ˜¾ç¤ºå‡ºè¯¦ç»†çš„å‘½ä»¤æ‰§è¡Œè¿‡ç¨‹, æ¸…æ¥šåœ°çœ‹åˆ°å‘å‡ºçš„ HTTP è¯·æ±‚, æ¯”å¦‚: 

kubectl get pod --v=9

```
ubuntu@VM-0-23-ubuntu:~$ kubectl get pod --v=9
I0327 11:19:29.843772 1122373 loader.go:373] Config loaded from file:  /home/ubuntu/.kube/config
I0327 11:19:29.844495 1122373 cert_rotation.go:137] Starting client certificate rotation controller
I0327 11:19:29.849431 1122373 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json;as=Table;v=v1;g=meta.k8s.io,application/json;as=Table;v=v1beta1;g=meta.k8s.io,application/json" -H "User-Agent: kubectl/v1.26.1 (linux/amd64) kubernetes/8f94681" 'https://192.168.49.2:8443/api/v1/namespaces/default/pods?limit=500'
I0327 11:19:29.849723 1122373 round_trippers.go:510] HTTP Trace: Dial to tcp:192.168.49.2:8443 succeed
I0327 11:19:29.856230 1122373 round_trippers.go:553] GET https://192.168.49.2:8443/api/v1/namespaces/default/pods?limit=500 200 OK in 6 milliseconds
I0327 11:19:29.856278 1122373 round_trippers.go:570] HTTP Statistics: DNSLookup 0 ms Dial 0 ms TLSHandshake 4 ms ServerProcessing 2 ms Duration 6 ms
I0327 11:19:29.856294 1122373 round_trippers.go:577] Response Headers:
I0327 11:19:29.856310 1122373 round_trippers.go:580]     X-Kubernetes-Pf-Prioritylevel-Uid: 6e762326-699f-4a84-aa81-6347b350db0e
I0327 11:19:29.856325 1122373 round_trippers.go:580]     Date: Mon, 27 Mar 2023 03:19:29 GMT
I0327 11:19:29.856343 1122373 round_trippers.go:580]     Audit-Id: cd5ec4f2-db88-4e0f-bd54-3ca295643d39
I0327 11:19:29.856361 1122373 round_trippers.go:580]     Cache-Control: no-cache, private
I0327 11:19:29.856377 1122373 round_trippers.go:580]     Content-Type: application/json
I0327 11:19:29.856397 1122373 round_trippers.go:580]     X-Kubernetes-Pf-Flowschema-Uid: c14f8e80-8525-4286-bdd5-07e3e589784c
I0327 11:19:29.856518 1122373 request.go:1171] Response Body: {"kind":"Table","apiVersion":"meta.k8s.io/v1","metadata":{"resourceVersion":"7905"},"columnDefinitions":[{"name":"Name","type":"string","format":"name","description":"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names","priority":0},{"name":"Ready","type":"string","format":"","description":"The aggregate readiness state of this pod for accepting traffic.","priority":0},{"name":"Status","type":"string","format":"","description":"The aggregate status of the containers in this pod.","priority":0},{"name":"Restarts","type":"string","format":"","description":"The number of times the containers in this pod have been restarted and when the last container in this pod has restarted.","priority":0},{"name":"Age","type":"string","format":"","description":"CreationTimestamp is a timestamp representing the server time when this object was created. It is not guaranteed to be set in happens-before order across separate operations. Clients may not set this value. It is represented in RFC3339 form and is in UTC.\n\nPopulated by the system. Read-only. Null for lists. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata","priority":0},{"name":"IP","type":"string","format":"","description":"IP address allocated to the pod. Routable at least within the cluster. Empty if not yet allocated.","priority":1},{"name":"Node","type":"string","format":"","description":"NodeName is a request to schedule this pod onto a specific node. If it is non-empty, the scheduler simply schedules this pod onto that node, assuming that it fits resource requirements.","priority":1},{"name":"Nominated Node","type":"string","format":"","description":"nominatedNodeName is set only when this pod preempts other pods on the node, but it cannot be scheduled right away as preemption victims receive their graceful termination periods. This field does not guarantee that the pod will be scheduled on this node. Scheduler may decide to place the pod elsewhere if other nodes become available sooner. Scheduler may also decide to give the resources on this node to a higher priority pod that is created after preemption. As a result, this field may be different than PodSpec.nodeName when the pod is scheduled.","priority":1},{"name":"Readiness Gates","type":"string","format":"","description":"If specified, all readiness gates will be evaluated for pod readiness. A pod is ready when all its containers are ready AND all conditions specified in the readiness gates have status equal to \"True\" More info: https://git.k8s.io/enhancements/keps/sig-network/580-pod-readiness-gates","priority":1}],"rows":[{"cells":["ngx","1/1","Running","0","106m","10.244.0.3","minikube","\u003cnone\u003e","\u003cnone\u003e"],"object":{"kind":"PartialObjectMetadata","apiVersion":"meta.k8s.io/v1","metadata":{"name":"ngx","namespace":"default","uid":"24a0addd-b436-4c25-aa5b-d8456c90f7b8","resourceVersion":"2715","creationTimestamp":"2023-03-27T01:33:05Z","labels":{"run":"ngx"},"managedFields":[{"manager":"kubectl-run","operation":"Update","apiVersion":"v1","time":"2023-03-27T01:33:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:labels":{".":{},"f:run":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"ngx\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-03-27T01:33:09Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.0.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]}}}]}
NAME   READY   STATUS    RESTARTS   AGE
ngx    1/1     Running   0          106m

```

ä»æˆªå›¾é‡Œå¯ä»¥çœ‹åˆ°, kubectl å®¢æˆ·ç«¯ç­‰ä»·äºè°ƒç”¨äº† curl, å‘ 8443 ç«¯å£å‘é€äº† HTTP GET è¯·æ±‚, URL æ˜¯ /api/v1/namespaces/default/pods. 

ç›®å‰çš„ Kubernetes 1.23 ç‰ˆæœ¬æœ‰ 50 å¤šç§ API å¯¹è±¡, å…¨é¢åœ°æè¿°äº†é›†ç¾¤çš„èŠ‚ç‚¹, åº”ç”¨, é…ç½®, æœåŠ¡, è´¦å·ç­‰ç­‰ä¿¡æ¯, apiserver ä¼šæŠŠå®ƒä»¬éƒ½å­˜å‚¨åœ¨æ•°æ®åº“ etcd é‡Œ, ç„¶å kubelet, scheduler, controller-manager ç­‰ç»„ä»¶é€šè¿‡ apiserver æ¥æ“ä½œå®ƒä»¬, å°±åœ¨ API å¯¹è±¡è¿™ä¸ªæŠ½è±¡å±‚æ¬¡å®ç°äº†å¯¹æ•´ä¸ªé›†ç¾¤çš„ç®¡ç†. 

#### ä½¿ç”¨ YAML æè¿°å¹¶åˆ›å»º Pod å¯¹è±¡

å¦‚ä½•ä»¥ YAML è¯­è¨€, ä½¿ç”¨ "å£°æ˜å¼"åœ¨ Kubernetes é‡Œæè¿°å¹¶åˆ›å»º API å¯¹è±¡. 

```shell
kubectl run ngx --image=nginx:alpine
```



```yaml
# header
apiVersion: v1
kind: Pod
metadata:
  # ç»™ Pod èµ·äº†ä¸ªåå­—å« ngx-pod
  name: ngx-pod
  # ç»™ Pod "è´´"ä¸Šäº†ä¸€äº›ä¾¿äºæŸ¥æ‰¾çš„æ ‡ç­¾, åˆ†åˆ«æ˜¯ env å’Œ owner. 
  labels:
    env: demo
    owner: chrono

# body
spec:
  containers:
  # ä½¿ç”¨çš„é•œåƒ
  - image: nginx:alpine
    # é•œåƒçš„åç§°
    name: ngx
    # å®¹å™¨å¯¹å¤–æš´éœ²çš„ç«¯å£
    ports:
    - containerPort: 80
```

å› ä¸º API å¯¹è±¡é‡‡ç”¨æ ‡å‡†çš„ HTTP åè®®, ä¸ºäº†æ–¹ä¾¿ç†è§£, æˆ‘ä»¬å¯ä»¥å€Ÿé‰´ä¸€ä¸‹ HTTP çš„æŠ¥æ–‡æ ¼å¼, æŠŠ API å¯¹è±¡çš„æè¿°åˆ†æˆ "header"å’Œ "body"ä¸¤éƒ¨åˆ†. 

 "header"é‡Œçš„ apiVersion, kind, metadata è¿™ä¸‰ä¸ªå­—æ®µæ˜¯ä»»ä½•å¯¹è±¡éƒ½å¿…é¡»æœ‰çš„, è€Œ "body"éƒ¨åˆ†åˆ™ä¼šä¸å¯¹è±¡ç‰¹å®šç›¸å…³, æ¯ç§å¯¹è±¡ä¼šæœ‰ä¸åŒçš„è§„æ ¼å®šä¹‰, åœ¨ YAML é‡Œå°±è¡¨ç°ä¸º spec å­—æ®µï¼ˆå³ specification), è¡¨ç¤ºæˆ‘ä»¬å¯¹å¯¹è±¡çš„ "æœŸæœ›çŠ¶æ€"ï¼ˆdesired status). 



-  "header"åŒ…å«çš„æ˜¯ API å¯¹è±¡çš„åŸºæœ¬ä¿¡æ¯, æœ‰ä¸‰ä¸ªå­—æ®µ: apiVersion, kind, metadata. 

  - apiVersion è¡¨ç¤ºæ“ä½œè¿™ç§èµ„æºçš„ API ç‰ˆæœ¬å·, ç”±äº Kubernetes çš„è¿­ä»£é€Ÿåº¦å¾ˆå¿«, ä¸åŒçš„ç‰ˆæœ¬åˆ›å»ºçš„å¯¹è±¡ä¼šæœ‰å·®å¼‚, ä¸ºäº†åŒºåˆ†è¿™äº›ç‰ˆæœ¬å°±éœ€è¦ä½¿ç”¨ apiVersion è¿™ä¸ªå­—æ®µ, æ¯”å¦‚ v1, v1alpha1, v1beta1 ç­‰ç­‰. 

  - kind è¡¨ç¤ºèµ„æºå¯¹è±¡çš„ç±»å‹, è¿™ä¸ªåº”è¯¥å¾ˆå¥½ç†è§£, æ¯”å¦‚ Pod, Node, Job, Service ç­‰ç­‰. 

  - metadata è¿™ä¸ªå­—æ®µé¡¾åæ€ä¹‰, è¡¨ç¤ºçš„æ˜¯èµ„æºçš„ä¸€äº› "å…ƒä¿¡æ¯", ä¹Ÿå°±æ˜¯ç”¨æ¥æ ‡è®°å¯¹è±¡, æ–¹ä¾¿ Kubernetes ç®¡ç†çš„ä¸€äº›ä¿¡æ¯. 



```shell
# åˆ›å»º api å¯¹è±¡
kubectl apply -f ngx-pod.yml
# åˆ é™¤ api å¯¹è±¡
kubectl delete -f ngx-pod.yml
# å¯¹è±¡å­—æ®µçš„è¯¦ç»†è¯´æ˜
kubectl explain pod
kubectl explain pod.metadata
kubectl explain pod.spec
kubectl explain pod.spec.containers
```

#### ç”Ÿæˆ kubectl run å¯¹åº”çš„ yaml æ–‡ä»¶

~/.bashrc

```
# kubectl
alias kubectl="minikube kubectl --"
source <(kubectl completion bash)
alias k=kubectl
complete -o default -F __start_kubectl k

export out="--dry-run=client -o yaml"

```



```shell
kubectl run ngx --image=nginx:alpine --dry-run=client -o yaml

export out="--dry-run=client -o yaml"
kubectl run ngx --image=nginx:alpine $out

apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: ngx
  name: ngx
spec:
  containers:
  - image: nginx:alpine
    name: ngx
    resources: {}
  dnsPolicy: ClusterFirst
  # é‡å¯ç­–ç•¥, å¯¹äºç¡®å®ä¸éœ€è¦é‡å¯çš„ pod, å¯ä»¥è®¾ç½® restartPolicy: Never
  restartPolicy: Always
status: {}

```



kubectl run ngx --image=busybox:latest $out

```yaml
# busy-pod.yml
apiVersion: v1
kind: Pod
metadata:
  name: busy-pod
  labels:
    owner: chrono
    env: demo
    region: north
    tier: back
 
spec:
  containers:
  - image: busybox:latest
    name: busy
    # æŒ‡å®šé•œåƒçš„æ‹‰å–ç­–ç•¥, å¯ä»¥æ˜¯ Always/Never/IfNotPresent, ä¸€èˆ¬é»˜è®¤æ˜¯ IfNotPresent
    imagePullPolicy: IfNotPresent
    # å®šä¹‰ Pod çš„ç¯å¢ƒå˜é‡, å’Œ Dockerfile é‡Œçš„ ENV æŒ‡ä»¤æœ‰ç‚¹ç±»ä¼¼, ä½†å®ƒæ˜¯è¿è¡Œæ—¶æŒ‡å®šçš„, æ›´åŠ çµæ´»å¯é…ç½®. 
    env:
      - name: os
        value: "ubuntu"
      - name: debug
        value: "on"
    # å®šä¹‰å®¹å™¨å¯åŠ¨æ—¶è¦æ‰§è¡Œçš„å‘½ä»¤, ç›¸å½“äº Dockerfile é‡Œçš„ ENTRYPOINT æŒ‡ä»¤. 
    command:
      - /bin/echo
    # command è¿è¡Œæ—¶çš„å‚æ•°, ç›¸å½“äº Dockerfile é‡Œçš„ CMD æŒ‡ä»¤
    args:
      - "$(os), $(debug)"
```



```shell
# å¯åŠ¨ pod
kubectl apply -f busy-pod.yml
# åˆ é™¤ pod
kubectl delete -f busy-pod.yml
# ä½¿ç”¨åå­—åˆ é™¤ pod
kubectl delete pod busy-pod
# æŸ¥çœ‹ pod è¿è¡Œæ—¥å¿—
kubectl logs busy-pod

# æŸ¥çœ‹ pod åˆ—è¡¨å’Œè¿è¡ŒçŠ¶æ€
kubectl get pod

# æ£€æŸ¥å®¹å™¨çš„è¯¦ç»†çŠ¶æ€
kubectl describe pod busy-pod

ubuntu@VM-0-23-ubuntu:~$ kubectl describe pod busy-pod
Name:             busy-pod
Namespace:        default
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Mon, 27 Mar 2023 17:51:06 +0800
Labels:           env=demo
                  owner=chrono
                  region=north
                  tier=back
Annotations:      <none>
Status:           Running
IP:               10.244.0.6
IPs:
  IP:  10.244.0.6
Containers:
  busy:
    Container ID:  docker://39782e4c5ce2b2b24d50b32f1b17f925491521f9c3bbbe033e6f97e05be37bd7
    Image:         busybox:latest
    Image ID:      docker-pullable://busybox@sha256:b5d6fe0712636ceb7430189de28819e195e8966372edfc2d9409d79402a0dc16
    Port:          <none>
    Host Port:     <none>
    Command:
      /bin/echo
    Args:
      $(os), $(debug)
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Mon, 27 Mar 2023 17:51:53 +0800
      Finished:     Mon, 27 Mar 2023 17:51:53 +0800
    Last State:     Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Mon, 27 Mar 2023 17:51:22 +0800
      Finished:     Mon, 27 Mar 2023 17:51:22 +0800
    Ready:          False
    Restart Count:  3
    Environment:
      os:     ubuntu
      debug:  on
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-2wc6f (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             False
  ContainersReady   False
  PodScheduled      True
Volumes:
  kube-api-access-2wc6f:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age               From               Message
  ----     ------     ----              ----               -------
  Normal   Scheduled  56s               default-scheduler  Successfully assigned default/busy-pod to minikube
  Normal   Pulling    55s               kubelet            Pulling image "busybox:latest"
  Normal   Pulled     53s               kubelet            Successfully pulled image "busybox:latest" in 2.020284029s (2.020291092s including waiting)
  Normal   Created    9s (x4 over 53s)  kubelet            Created container busy
  Normal   Started    9s (x4 over 53s)  kubelet            Started container busy
  Normal   Pulled     9s (x3 over 53s)  kubelet            Container image "busybox:latest" already present on machine
  Warning  BackOff    8s (x5 over 52s)  kubelet            Back-off restarting failed container busy in pod busy-pod_default(ea193e32-6fd3-49ac-931a-e9ab26276b09)

```





```shell
# å¤åˆ¶æ–‡ä»¶åˆ° pod ä¸­

echo 'aaa' > a.txt
kubectl cp a.txt ngx-pod:/tmp

# è¿›å…¥ pod æ‰§è¡Œå‘½ä»¤, è¦åœ¨ Pod åé¢åŠ ä¸Š --, æŠŠ kubectl çš„å‘½ä»¤ä¸ Shell å‘½ä»¤åˆ†éš”å¼€
kubectl exec -it ngx-pod -- sh

# æ³¨æ„: kubectl cp å’Œ kubectl exec æ“ä½œçš„æ˜¯ Pod ä¸­çš„å®¹å™¨, éœ€è¦ç”¨ -c å‚æ•°æŒ‡å®šå®¹å™¨å, ä¸è¿‡å› ä¸ºå¤§å¤šæ•° Pod é‡Œåªæœ‰ä¸€ä¸ªå®¹å™¨, æ‰€ä»¥å°±çœç•¥äº†
```



### Job

é¢å‘å¯¹è±¡çš„è®¾è®¡æœ‰è®¸å¤šåŸºæœ¬åŸåˆ™, å…¶ä¸­æœ‰ä¸¤æ¡æˆ‘è®¤ä¸ºæ¯”è¾ƒæ°å½“åœ°æè¿°äº† Kubernetes å¯¹è±¡è®¾è®¡æ€è·¯, ä¸€ä¸ªæ˜¯ "å•ä¸€èŒè´£", å¦ä¸€ä¸ªæ˜¯ "ç»„åˆä¼˜äºç»§æ‰¿". 

 "å•ä¸€èŒè´£"çš„æ„æ€æ˜¯å¯¹è±¡åº”è¯¥åªä¸“æ³¨äºåšå¥½ä¸€ä»¶äº‹æƒ…, ä¸è¦è´ªå¤§æ±‚å…¨, ä¿æŒè¶³å¤Ÿå°çš„ç²’åº¦æ‰æ›´æ–¹ä¾¿å¤ç”¨å’Œç®¡ç†. 

 "ç»„åˆä¼˜äºç»§æ‰¿"çš„æ„æ€æ˜¯åº”è¯¥å°½é‡è®©å¯¹è±¡åœ¨è¿è¡Œæ—¶äº§ç”Ÿè”ç³», ä¿æŒæ¾è€¦åˆ, è€Œä¸è¦ç”¨ç¡¬ç¼–ç çš„æ–¹å¼å›ºå®šå¯¹è±¡çš„å…³ç³». 

åº”ç”¨è¿™ä¸¤æ¡åŸåˆ™, æˆ‘ä»¬å†æ¥çœ‹ Kubernetes çš„èµ„æºå¯¹è±¡å°±ä¼šå¾ˆæ¸…æ™°äº†. å› ä¸º Pod å·²ç»æ˜¯ä¸€ä¸ªç›¸å¯¹å®Œå–„çš„å¯¹è±¡, ä¸“é—¨è´Ÿè´£ç®¡ç†å®¹å™¨, é‚£ä¹ˆæˆ‘ä»¬å°±ä¸åº”è¯¥å† "ç”»è›‡æ·»è¶³"åœ°ç›²ç›®ä¸ºå®ƒæ‰©å……åŠŸèƒ½, è€Œæ˜¯è¦ä¿æŒå®ƒçš„ç‹¬ç«‹æ€§, å®¹å™¨ä¹‹å¤–çš„åŠŸèƒ½å°±éœ€è¦å®šä¹‰å…¶ä»–çš„å¯¹è±¡, æŠŠ Pod ä½œä¸ºå®ƒçš„ä¸€ä¸ªæˆå‘˜ "ç»„åˆ"è¿›å». 

ubernetes é‡Œçš„ä¸¤å¤§ç±»ä¸šåŠ¡. ä¸€ç±»æ˜¯åƒ Nginx è¿™æ ·é•¿æ—¶é—´è¿è¡Œçš„ "åœ¨çº¿ä¸šåŠ¡", å¦ä¸€ç±»æ˜¯åƒ busybox è¿™æ ·çŸ­æ—¶é—´è¿è¡Œçš„ "ç¦»çº¿ä¸šåŠ¡"

 "åœ¨çº¿ä¸šåŠ¡"ç±»å‹çš„åº”ç”¨æœ‰å¾ˆå¤š, æ¯”å¦‚ Nginx, Node.js, MySQL, Redis ç­‰ç­‰, ä¸€æ—¦è¿è¡Œèµ·æ¥åŸºæœ¬ä¸Šä¸ä¼šåœ, ä¹Ÿå°±æ˜¯æ°¸è¿œåœ¨çº¿. 

è€Œ "ç¦»çº¿ä¸šåŠ¡"ç±»å‹çš„åº”ç”¨ä¹Ÿå¹¶ä¸å°‘è§, å®ƒä»¬ä¸€èˆ¬ä¸ç›´æ¥æœåŠ¡äºå¤–éƒ¨ç”¨æˆ·, åªå¯¹å†…éƒ¨ç”¨æˆ·æœ‰æ„ä¹‰, æ¯”å¦‚æ—¥å¿—åˆ†æ, æ•°æ®å»ºæ¨¡, è§†é¢‘è½¬ç ç­‰ç­‰, è™½ç„¶è®¡ç®—é‡å¾ˆå¤§, ä½†åªä¼šè¿è¡Œä¸€æ®µæ—¶é—´.  "ç¦»çº¿ä¸šåŠ¡"çš„ç‰¹ç‚¹æ˜¯å¿…å®šä¼šé€€å‡º, ä¸ä¼šæ— æœŸé™åœ°è¿è¡Œä¸‹å», æ‰€ä»¥å®ƒçš„è°ƒåº¦ç­–ç•¥ä¹Ÿå°±ä¸ "åœ¨çº¿ä¸šåŠ¡"å­˜åœ¨å¾ˆå¤§çš„ä¸åŒ, éœ€è¦è€ƒè™‘è¿è¡Œè¶…æ—¶, çŠ¶æ€æ£€æŸ¥, å¤±è´¥é‡è¯•, è·å–è®¡ç®—ç»“æœç­‰ç®¡ç†äº‹é¡¹. 

 "ç¦»çº¿ä¸šåŠ¡"ä¹Ÿå¯ä»¥åˆ†ä¸ºä¸¤ç§. ä¸€ç§æ˜¯ "ä¸´æ—¶ä»»åŠ¡", è·‘å®Œå°±å®Œäº‹äº†, ä¸‹æ¬¡æœ‰éœ€æ±‚äº†è¯´ä¸€å£°å†é‡æ–°å®‰æ’; å¦ä¸€ç§æ˜¯ "å®šæ—¶ä»»åŠ¡", å¯ä»¥æŒ‰æ—¶æŒ‰ç‚¹å‘¨æœŸè¿è¡Œ, ä¸éœ€è¦è¿‡å¤šå¹²é¢„. 

å¯¹åº”åˆ° Kubernetes é‡Œ, "ä¸´æ—¶ä»»åŠ¡"å°±æ˜¯ API å¯¹è±¡ Job, "å®šæ—¶ä»»åŠ¡"å°±æ˜¯ API å¯¹è±¡ CronJob, ä½¿ç”¨è¿™ä¸¤ä¸ªå¯¹è±¡ä½ å°±èƒ½å¤Ÿåœ¨ Kubernetes é‡Œè°ƒåº¦ç®¡ç†ä»»æ„çš„ç¦»çº¿ä¸šåŠ¡äº†. 

#### åˆ›å»º job yaml æ–‡ä»¶

```shell

export out="--dry-run=client -o yaml"              # å®šä¹‰Shellå˜é‡
kubectl create job echo-job --image=busybox $out

apiVersion: batch/v1
kind: Job
metadata:
  creationTimestamp: null
  name: echo-job
spec:
  template:
    metadata:
      creationTimestamp: null
    spec:
      containers:
      - image: busybox
        name: echo-job
        resources: {}
      restartPolicy: Never
status: {}

```

```yaml
# echo-job.yml

apiVersion: batch/v1
kind: Job
metadata:
  name: echo-job

spec:
  # template å­—æ®µå®šä¹‰äº†ä¸€ä¸ª "åº”ç”¨æ¨¡æ¿", é‡Œé¢åµŒå…¥äº†ä¸€ä¸ª Pod, è¿™æ · Job å°±å¯ä»¥ä»è¿™ä¸ªæ¨¡æ¿æ¥åˆ›å»ºå‡º Pod
  template:
    # Pod å¯¹è±¡
    spec:
      # å› ä¸º Job ä¸šåŠ¡çš„ç‰¹æ®Šæ€§, æ‰€ä»¥è¿˜å®šä¹‰äº† restartPolicy, ç¡®å®š Pod è¿è¡Œå¤±è´¥æ—¶çš„ç­–ç•¥
      # OnFailure æ˜¯å¤±è´¥åŸåœ°é‡å¯å®¹å™¨, è€Œ Never åˆ™æ˜¯ä¸é‡å¯å®¹å™¨, è®© Job å»é‡æ–°è°ƒåº¦ç”Ÿæˆä¸€ä¸ªæ–°çš„ Pod
      restartPolicy: OnFailure
      containers:
      - image: busybox
        name: echo-job
        imagePullPolicy: IfNotPresent
        command: ["/bin/echo"]
        args: ["hello", "world"]
```



å› ä¸º Pod è¢« Job ç®¡ç†, å®ƒå°±ä¸ä¼šåå¤é‡å¯æŠ¥é”™äº†, è€Œæ˜¯ä¼šæ˜¾ç¤ºä¸º Completed è¡¨ç¤ºä»»åŠ¡å®Œæˆ, è€Œ Job é‡Œä¹Ÿä¼šåˆ—å‡ºè¿è¡ŒæˆåŠŸçš„ä½œä¸šæ•°é‡, è¿™é‡Œåªæœ‰ä¸€ä¸ªä½œä¸š, æ‰€ä»¥å°±æ˜¯ 1/1. 

```shell
kubectl apply -f job.yml
kubectl get job
kubectl get pod

# æŸ¥çœ‹ job
ubuntu@VM-0-23-ubuntu:~$ kubectl get job
NAME       COMPLETIONS   DURATION   AGE
echo-job   1/1           4s         7s

# æŸ¥çœ‹ pod
ubuntu@VM-0-23-ubuntu:~$ kubectl get pod
NAME             READY   STATUS             RESTARTS        AGE
busy-pod         0/1     CrashLoopBackOff   12 (114s ago)   38m
echo-job-5r9bh   0/1     Completed          0               23s
ngx              1/1     Running            0               8h

# æŸ¥çœ‹ pod çš„æ—¥å¿—
ubuntu@VM-0-23-ubuntu:~$ kubectl logs echo-job-5r9bh
hello world


```



å†åˆ›å»ºä¸€ä¸ª Job å¯¹è±¡, åå­—å« "sleep-job", å®ƒéšæœºç¡çœ ä¸€æ®µæ—¶é—´å†é€€å‡º, æ¨¡æ‹Ÿè¿è¡Œæ—¶é—´è¾ƒé•¿çš„ä½œä¸šï¼ˆæ¯”å¦‚ MapReduce). Job çš„å‚æ•°è®¾ç½®æˆ 15 ç§’è¶…æ—¶, æœ€å¤šé‡è¯• 2 æ¬¡, æ€»å…±éœ€è¦è¿è¡Œå®Œ 4 ä¸ª Pod, ä½†åŒä¸€æ—¶åˆ»æœ€å¤šå¹¶å‘ 2 ä¸ª Pod: 

```yaml
# sleep-job.yml

apiVersion: batch/v1
kind: Job
metadata:
  name: sleep-job

spec:
  # Pod è¿è¡Œçš„è¶…æ—¶æ—¶é—´. 
  activeDeadlineSeconds: 15
  # Pod çš„å¤±è´¥é‡è¯•æ¬¡æ•°
  backoffLimit: 2
  # Job å®Œæˆéœ€è¦è¿è¡Œå¤šå°‘ä¸ª Pod, é»˜è®¤æ˜¯ 1 ä¸ª
  completions: 4
  # å®ƒä¸ completions ç›¸å…³, è¡¨ç¤ºå…è®¸å¹¶å‘è¿è¡Œçš„ Pod æ•°é‡, é¿å…è¿‡å¤šå ç”¨èµ„æº. 
  parallelism: 2

  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - image: busybox
        name: echo-job
        imagePullPolicy: IfNotPresent
        command:
          - sh
          - -c
          - sleep $(($RANDOM % 10 + 1)) && echo done
```



```shell
ubuntu@VM-0-23-ubuntu:~$ kubectl apply -f sleep-job.yml
job.batch/sleep-job created

# ä½¿ç”¨ kubectl apply åˆ›å»º Job ä¹‹å, æˆ‘ä»¬å¯ä»¥ç”¨ kubectl get pod -w æ¥å®æ—¶è§‚å¯Ÿ Pod çš„çŠ¶æ€, çœ‹åˆ° Pod ä¸æ–­è¢«æ’é˜Ÿ, åˆ›å»º, è¿è¡Œçš„è¿‡ç¨‹: 
ubuntu@VM-0-23-ubuntu:~$ kubectl get pod -w
NAME              READY   STATUS             RESTARTS         AGE
busy-pod          0/1     CrashLoopBackOff   13 (2m21s ago)   44m
echo-job-5r9bh    0/1     Completed          0                5m57s
ngx               1/1     Running            0                9h
sleep-job-62ffn   1/1     Running            0                5s
sleep-job-r6zq6   1/1     Running            0                5s
sleep-job-62ffn   0/1     Completed          0                6s
sleep-job-r6zq6   0/1     Completed          0                7s
sleep-job-62ffn   0/1     Completed          0                8s
sleep-job-r6zq6   0/1     Completed          0                9s
sleep-job-hprwb   0/1     Pending            0                0s
sleep-job-hprwb   0/1     Pending            0                0s
sleep-job-62ffn   0/1     Completed          0                9s
sleep-job-hprwb   0/1     ContainerCreating   0                0s
sleep-job-85d4v   0/1     Pending             0                0s
sleep-job-85d4v   0/1     Pending             0                0s
sleep-job-85d4v   0/1     ContainerCreating   0                0s
sleep-job-r6zq6   0/1     Completed           0                9s
sleep-job-85d4v   1/1     Running             0                1s
sleep-job-hprwb   1/1     Running             0                1s
sleep-job-hprwb   0/1     Completed           0                5s
sleep-job-hprwb   0/1     Terminating         0                6s
sleep-job-85d4v   1/1     Terminating         0                6s
sleep-job-hprwb   0/1     Terminating         0                6s
sleep-job-85d4v   1/1     Terminating         0                6s
sleep-job-85d4v   0/1     Terminating         0                6s
sleep-job-85d4v   0/1     Terminating         0                6s
sleep-job-85d4v   0/1     Terminating         0                6s
sleep-job-hprwb   0/1     Terminating         0                7s
sleep-job-hprwb   0/1     Terminating         0                7s
sleep-job-hprwb   0/1     Terminating         0                7s

ubuntu@VM-0-23-ubuntu:~$ kubectl get pod -w
NAME              READY   STATUS             RESTARTS         AGE
busy-pod          0/1     CrashLoopBackOff   13 (2m51s ago)   44m
echo-job-5r9bh    0/1     Completed          0                6m27s
ngx               1/1     Running            0                9h
sleep-job-62ffn   0/1     Completed          0                35s
sleep-job-r6zq6   0/1     Completed          0                35s

```

### CronJob

```shell

export out="--dry-run=client -o yaml"              # å®šä¹‰Shellå˜é‡
kubectl create cj echo-cj --image=busybox --schedule="" $out

apiVersion: batch/v1
kind: CronJob
metadata:
  creationTimestamp: null
  name: echo-cj

spec:
  jobTemplate:
    metadata:
      creationTimestamp: null
      name: echo-cj
    spec:
      template:
        metadata:
          creationTimestamp: null
        spec:
          containers:
          - image: busybox
            name: echo-cj
            resources: {}
          restartPolicy: OnFailure
  schedule: ""
status: {}

```



```yaml
# echo-cronjob.yml

apiVersion: batch/v1
kind: CronJobvmrun
metadata:
  name: echo-cj

# ç¬¬ä¸€ä¸ª spec æ˜¯ CronJob è‡ªå·±çš„å¯¹è±¡è§„æ ¼å£°æ˜
spec:
  # å®šä¹‰ä»»åŠ¡å‘¨æœŸè¿è¡Œçš„è§„åˆ™
  schedule: '*/1 * * * *'
  jobTemplate:
    # ç¬¬äºŒä¸ª spec ä»å±äº "jobTemplate", å®ƒå®šä¹‰äº†ä¸€ä¸ª Job å¯¹è±¡. 
    spec:
      template:
        # ç¬¬äºŒä¸ª spec ä»å±äº "jobTemplate", å®ƒå®šä¹‰äº†ä¸€ä¸ª Job å¯¹è±¡. 
        spec:
          restartPolicy: OnFailure
          containers:
          - image: busybox
            name: echo-cj
            imagePullPolicy: IfNotPresent
            command: ["/bin/echo"]
            args: ["hello", "world"]
```

```shell

kubectl apply -f cronjob.yml
kubectl get cj
kubectl get pod

```

æ³¨: 

1. Job åœ¨è¿è¡Œç»“æŸåä¸ä¼šç«‹å³åˆ é™¤, è¿™æ˜¯ä¸ºäº†æ–¹ä¾¿è·å–è®¡ç®—ç»“æœ. å¯ä»¥ä½¿ç”¨å­—æ®µ ttlSecondsAfterFinish è®¾ç½®ä¿ç•™çš„æ—¶é™

2. CronJob ä¹Ÿä¸ä¼šæ— é™åœ°ä¿ç•™å·²ç»è¿è¡Œçš„ Job, å®ƒé»˜è®¤åªä¿ç•™ 3 ä¸ªæœ€è¿‘çš„æ‰§è¡Œç»“æœ, å¯ä»¥ä½¿ç”¨ successfulJobsHistoryLimit æ”¹å˜



### é…ç½®ä¿¡æ¯

#### ConfigMap

```shell

export out="--dry-run=client -o yaml"        # å®šä¹‰Shellå˜é‡
kubectl create cm info-cm $out

# ConfigMap å­˜å‚¨çš„æ˜¯é…ç½®æ•°æ®, æ˜¯é™æ€çš„å­—ç¬¦ä¸², å¹¶ä¸æ˜¯å®¹å™¨, æ‰€ä»¥å®ƒä»¬å°±ä¸éœ€è¦ç”¨ "spec"å­—æ®µæ¥è¯´æ˜è¿è¡Œæ—¶çš„ "è§„æ ¼"
apiVersion: v1
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: info-cm

ConfigMap è¦å­˜å‚¨æ•°æ®, å°±éœ€è¦ç”¨å¦ä¸€ä¸ªå«ä¹‰æ›´æ˜ç¡®çš„å­—æ®µ "data". 
è¦ç”Ÿæˆå¸¦æœ‰ "data"å­—æ®µçš„ YAML æ ·æ¿, ä½ éœ€è¦åœ¨ kubectl create åé¢å¤šåŠ ä¸€ä¸ªå‚æ•° --from-literal , è¡¨ç¤ºä»å­—é¢å€¼ç”Ÿæˆä¸€äº›æ•°æ®: 


kubectl create cm info-cm --from-literal=k=v $out
apiVersion: v1
data:
  k: v
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: info-cm

```



```yaml
# info-cm.yml

apiVersion: v1
kind: ConfigMap
metadata:
  name: info-cm

data:
  count: '10'
  debug: 'on'
  path: '/etc/systemd'
  greeting: |
    say hello to kubernetes.
```



```shell
ubuntu@VM-0-23-ubuntu:~$ kubectl apply -f info-cm.yml
configmap/info created

ubuntu@VM-0-23-ubuntu:~$ kubectl get cm
NAME               DATA   AGE
info               4      97s
info-cm            4      15s
kube-root-ca.crt   1      10h

# ConfigMap çš„ Key-Value ä¿¡æ¯å°±å·²ç»å­˜å…¥äº† etcd æ•°æ®åº“, åç»­å°±å¯ä»¥è¢«å…¶ä»– API å¯¹è±¡ä½¿ç”¨. 
ubuntu@VM-0-23-ubuntu:~$ kubectl describe cm info-cm
Name:         info-cm
Namespace:    default
Labels:       <none>
Annotations:  <none>

Data
====
count:
----
10
debug:
----
on
greeting:
----
say hello to kubernetes.

path:
----
/etc/systemd

BinaryData
====

Events:  <none>

```



#### Secret



åœ¨ Kubernetes é‡Œ Secret å¯¹è±¡åˆç»†åˆ†å‡ºå¾ˆå¤šç±», æ¯”å¦‚: è®¿é—®ç§æœ‰é•œåƒä»“åº“çš„è®¤è¯ä¿¡æ¯èº«ä»½è¯†åˆ«çš„å‡­è¯ä¿¡æ¯HTTPS é€šä¿¡çš„è¯ä¹¦å’Œç§é’¥ä¸€èˆ¬çš„æœºå¯†ä¿¡æ¯ï¼ˆæ ¼å¼ç”±ç”¨æˆ·è‡ªè¡Œè§£é‡Š)



```shell

kubectl create secret generic user-sc --from-literal=name=root $out

apiVersion: v1
kind: Secret
metadata:
  creationTimestamp: null
  name: user-sc

data:
  name: cm9vdA==


echo -n "123456" | base64
MTIzNDU2

echo cm9vdA== | base64 -d

```



```yaml
# user-sc.yml

apiVersion: v1
kind: Secret
metadata:
  name: user-sc

data:
  name: cm9vdA==  # root
  pwd: MTIzNDU2   # 123456
  db: bXlzcWw=    # mysql
```



```shell

kubectl apply -f user-sc.yml
kubectl get secret
kubectl describe secret user

ubuntu@VM-0-23-ubuntu:~$ kubectl get secret
NAME      TYPE     DATA   AGE
user-sc   Opaque   3      7s

ubuntu@VM-0-23-ubuntu:~$ kubectl describe secret user-sc
Name:         user-sc
Namespace:    default
Labels:       <none>
Annotations:  <none>

Type:  Opaque

Data
====
name:  4 bytes
pwd:   6 bytes
db:    5 bytes

```



#### ä»¥ç¯å¢ƒå˜é‡çš„æ–¹å¼ä½¿ç”¨ ConfigMap/Secret



```shell

kubectl explain pod.spec.containers.env.valueFrom

```



```yaml
# env-pod.yml

apiVersion: v1
kind: Pod
metadata:
  name: env-pod

spec:
  containers:
  # ä»¥ç¯å¢ƒå˜é‡çš„æ–¹å¼ä½¿ç”¨é…ç½®ä¿¡æ¯
  - env:
      # å®šä¹‰ç¯å¢ƒå˜é‡ COUNT, GREETING, å¼•ç”¨çš„æ˜¯ ConfigMap å¯¹è±¡
      - name: COUNT
        # æŒ‡å®š value ä»ä½•è€Œæ¥
        valueFrom:
          configMapKeyRef:
            # name"æ˜¯ ConfigMap å¯¹è±¡çš„åå­—
            name: info-cm
            #  "key"å­—æ®µåˆ†åˆ«æ˜¯ "info"å¯¹è±¡é‡Œçš„ count å’Œ greeting. 
            key: count
      - name: GREETING
        valueFrom:
          configMapKeyRef:
            name: info-cm
            key: greeting

      # å®šä¹‰ç¯å¢ƒå˜é‡ USERNAME, PASSWORD, å¼•ç”¨çš„æ˜¯ Secret å¯¹è±¡
      - name: USERNAME
        valueFrom:
          secretKeyRef:
            # name"æŒ‡å®š Secret å¯¹è±¡çš„åå­— user-sc
            name: user-sc
            key: name
      - name: PASSWORD
        valueFrom:
          secretKeyRef:
            name: user-sc
            key: pwd

    image: busybox
    name: busy
    imagePullPolicy: IfNotPresent
    command: ["/bin/sleep", "300"]
```

```shell
# ç”¨ kubectl apply åˆ›å»º Pod, å†ç”¨ kubectl exec è¿›å…¥ Pod, éªŒè¯ç¯å¢ƒå˜é‡æ˜¯å¦ç”Ÿæ•ˆ
kubectl apply -f env-pod.yml
kubectl exec -it env-pod -- sh

echo $COUNT
echo $GREETING
echo $USERNAME $PASSWORD
```



#### ä»¥ Volume çš„æ–¹å¼ä½¿ç”¨ ConfigMap/Secret

å¯ä»¥ä¸º Pod "æŒ‚è½½ï¼ˆmount)"å¤šä¸ª Volume, é‡Œé¢å­˜æ”¾ä¾› Pod è®¿é—®çš„æ•°æ®, è¿™ç§æ–¹å¼æœ‰ç‚¹ç±»ä¼¼ docker run -v, è™½ç„¶ç”¨æ³•å¤æ‚äº†ä¸€äº›, ä½†åŠŸèƒ½ä¹Ÿç›¸åº”å¼ºå¤§ä¸€äº›. 

åœ¨ Pod é‡ŒæŒ‚è½½ Volume å¾ˆå®¹æ˜“, åªéœ€è¦åœ¨ "spec"é‡Œå¢åŠ ä¸€ä¸ª "volumes"å­—æ®µ, ç„¶åå†å®šä¹‰å·çš„åå­—å’Œå¼•ç”¨çš„ ConfigMap/Secret å°±å¯ä»¥äº†. è¦æ³¨æ„çš„æ˜¯ Volume å±äº Pod, ä¸å±äºå®¹å™¨, æ‰€ä»¥å®ƒå’Œå­—æ®µ "containers"æ˜¯åŒçº§çš„, éƒ½å±äº "spec". 



```yaml

spec:
  # å®šä¹‰ä¸¤ä¸ª Volume, åˆ†åˆ«å¼•ç”¨ ConfigMap å’Œ Secret
  volumes:
  - name: cm-vol
    configMap:
      name: info
  - name: sec-vol
    secret:
      secretName: user

  containers:
  # volumeMounts æŠŠå®šä¹‰å¥½çš„ Volume æŒ‚è½½åˆ°å®¹å™¨é‡Œçš„æŸä¸ªè·¯å¾„ä¸‹
  - volumeMounts:
    # mountPath æŒ‡å®šæŒ‚è½½è·¯å¾„
    - mountPath: /tmp/cm-items
      # name æŒ‡å®šæŒ‚è½½ Volume çš„åå­—
      name: cm-vol
    - mountPath: /tmp/sec-items
      name: sec-vol
```



```yaml
# vol-pod.yml
apiVersion: v1
kind: Pod
metadata:
  name: vol-pod

spec:
  volumes:
  - name: cm-vol
    configMap:
      name: info
  - name: sec-vol
    secret:
      secretName: user

  containers:
  - volumeMounts:
    - mountPath: /tmp/cm-items
      name: cm-vol
    - mountPath: /tmp/sec-items
      name: sec-vol

    image: busybox
    name: busy
    imagePullPolicy: IfNotPresent
    command: ["/bin/sleep", "300"]

```

```shell

kubectl apply -f vol-pod.yml
kubectl get pod

kubectl exec -it vol-pod -- sh

```

ä½ ä¼šçœ‹åˆ°, ConfigMap å’Œ Secret éƒ½å˜æˆäº†ç›®å½•çš„å½¢å¼, è€Œå®ƒä»¬é‡Œé¢çš„ Key-Value å˜æˆäº†ä¸€ä¸ªä¸ªçš„æ–‡ä»¶, è€Œæ–‡ä»¶åå°±æ˜¯ Key. 

å› ä¸ºè¿™ç§å½¢å¼ä¸Šçš„å·®å¼‚, ä»¥ Volume çš„æ–¹å¼æ¥ä½¿ç”¨ ConfigMap/Secret, å°±å’Œç¯å¢ƒå˜é‡ä¸å¤ªä¸€æ ·. ç¯å¢ƒå˜é‡ç”¨æ³•ç®€å•, æ›´é€‚åˆå­˜æ”¾ç®€çŸ­çš„å­—ç¬¦ä¸², è€Œ Volume æ›´é€‚åˆå­˜æ”¾å¤§æ•°æ®é‡çš„é…ç½®æ–‡ä»¶, åœ¨ Pod é‡ŒåŠ è½½æˆæ–‡ä»¶åè®©åº”ç”¨ç›´æ¥è¯»å–ä½¿ç”¨. 

å¦‚æœå·²ç»å­˜åœ¨äº†ä¸€äº›é…ç½®æ–‡ä»¶, å¯ä»¥ä½¿ç”¨å‚æ•° --from-file ä»æ–‡ä»¶è‡ªåŠ¨åˆ›å»ºå‡º ConfigMap å’Œ Secret

Linux é‡Œå¯¹ç¯å¢ƒå˜é‡çš„å‘½åæœ‰é™åˆ¶, ä¸èƒ½ä½¿ç”¨ `-`  `.` ç­‰ç‰¹æ®Šå­—ç¬¦



### æ€»ç»“

Kubernetes çš„ Master/Node æ¶æ„æ˜¯å®ƒå…·æœ‰è‡ªåŠ¨åŒ–è¿ç»´èƒ½åŠ›çš„å…³é”®

Kubernetes æŠŠé›†ç¾¤é‡Œçš„è®¡ç®—èµ„æºå®šä¹‰ä¸ºèŠ‚ç‚¹ï¼ˆNode), å…¶ä¸­åˆåˆ’åˆ†æˆæ§åˆ¶é¢å’Œæ•°æ®é¢ä¸¤ç±». 

æ§åˆ¶é¢æ˜¯ Master èŠ‚ç‚¹, è´Ÿè´£ç®¡ç†é›†ç¾¤å’Œè¿ç»´ç›‘æ§åº”ç”¨, é‡Œé¢çš„æ ¸å¿ƒç»„ä»¶æ˜¯ apiserver, etcd, scheduler, controller-manager. 

æ•°æ®é¢æ˜¯ Worker èŠ‚ç‚¹, å— Master èŠ‚ç‚¹çš„ç®¡æ§, é‡Œé¢çš„æ ¸å¿ƒç»„ä»¶æ˜¯ kubelet, kube-proxy, container-runtime. 

ä¸ºäº†æ›´å¥½åœ°ç®¡ç†é›†ç¾¤å’Œä¸šåŠ¡åº”ç”¨, Kubernetes ä»ç°å®ä¸–ç•Œä¸­æŠ½è±¡å‡ºäº†è®¸å¤šæ¦‚å¿µ, ç§°ä¸º "API å¯¹è±¡", æè¿°è¿™äº›å¯¹è±¡å°±éœ€è¦ä½¿ç”¨ YAML è¯­è¨€. 

Kubernetes é‡Œæœ‰å¾ˆå¤šçš„ API å¯¹è±¡, å…¶ä¸­æœ€æ ¸å¿ƒçš„å¯¹è±¡æ˜¯ "Pod", å®ƒæ†ç»‘äº†ä¸€ç»„å­˜åœ¨å¯†åˆ‡åä½œå…³ç³»çš„å®¹å™¨, å®¹å™¨ä¹‹é—´å…±äº«ç½‘ç»œå’Œå­˜å‚¨, åœ¨é›†ç¾¤é‡Œå¿…é¡»ä¸€èµ·è°ƒåº¦ä¸€èµ·è¿è¡Œ. é€šè¿‡ Pod è¿™ä¸ªæ¦‚å¿µ, Kubernetes å°±ç®€åŒ–äº†å¯¹å®¹å™¨çš„ç®¡ç†å·¥ä½œ, å…¶ä»–çš„æ‰€æœ‰ä»»åŠ¡éƒ½æ˜¯é€šè¿‡å¯¹ Pod è¿™ä¸ªæœ€å°å•ä½çš„å†åŒ…è£…æ¥å®ç°çš„ï¼ˆ12 è®²). 

é™¤äº†æ ¸å¿ƒçš„ Pod å¯¹è±¡, åŸºäº "å•ä¸€èŒè´£"å’Œ "å¯¹è±¡ç»„åˆ"è¿™ä¸¤ä¸ªåŸºæœ¬åŸåˆ™, æˆ‘ä»¬åˆå­¦ä¹ äº† 4 ä¸ªæ¯”è¾ƒç®€å•çš„ API å¯¹è±¡, åˆ†åˆ«æ˜¯ Job/CronJob å’Œ ConfigMap/Secret. 

Job/CronJob å¯¹åº”çš„æ˜¯ç¦»çº¿ä½œä¸š, å®ƒä»¬é€å±‚åŒ…è£…äº† Pod, æ·»åŠ äº†ä½œä¸šæ§åˆ¶å’Œå®šæ—¶è§„åˆ™ï¼ˆ13 è®²). 

ConfigMap/Secret å¯¹åº”çš„æ˜¯é…ç½®ä¿¡æ¯, éœ€è¦ä»¥ç¯å¢ƒå˜é‡æˆ–è€…å­˜å‚¨å·çš„å½¢å¼æ³¨å…¥è¿› Pod, ç„¶åè¿›ç¨‹æ‰èƒ½åœ¨è¿è¡Œæ—¶ä½¿ç”¨ï¼ˆ14 è®²). 

#### WordPress ç½‘ç«™æ­å»ºæ­¥éª¤

ç¬¬ä¸€æ­¥å½“ç„¶æ˜¯è¦ç¼–æ’ MariaDB å¯¹è±¡

```yaml
# maria-cm.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: maria-cm

data:
  DATABASE: 'db'
  USER: 'wp'
  PASSWORD: '123'
  ROOT_PASSWORD: '123'
  
```

å®šä¹‰ Pod å¯¹è±¡ maria-pod, æŠŠé…ç½®ä¿¡æ¯æ³¨å…¥ Pod, è®© MariaDB è¿è¡Œæ—¶ä»ç¯å¢ƒå˜é‡è¯»å–è¿™äº›ä¿¡æ¯: 

```yaml
# mariadb-pod.yml
apiVersion: v1
kind: Pod
metadata:
  name: maria-pod
  labels:
    app: wordpress
    role: database

spec:
  containers:
  - image: mariadb:10
    name: maria
    imagePullPolicy: IfNotPresent
    ports:
    - containerPort: 3306

    # envFrom å¯ä»¥ä¸€æ¬¡æ€§åœ°æŠŠ ConfigMap é‡Œçš„å­—æ®µå…¨å¯¼å…¥è¿› Pod, å¹¶ä¸”èƒ½å¤ŸæŒ‡å®šå˜é‡åçš„å‰ç¼€
    envFrom:
    - prefix: 'MARIADB_'
      configMapRef:
        name: maria-cm
```



```shell

kubectl apply -f mariadb-pod.yml

# æƒ³è¦è·å– IP åœ°å€éœ€è¦åŠ ä¸Šå‚æ•° -o wide
kubectl get pod -o wide

# ç°åœ¨æ•°æ®åº“å°±æˆåŠŸåœ°åœ¨ Kubernetes é›†ç¾¤é‡Œè·‘èµ·æ¥äº†, IP åœ°å€æ˜¯ "172.17.0.2", æ³¨æ„è¿™ä¸ªåœ°å€å’Œ Docker çš„ä¸åŒ, æ˜¯ Kubernetes é‡Œçš„ç§æœ‰ç½‘æ®µ. 
```

ç¬¬äºŒæ­¥, ç¼–æ’ WordPress å¯¹è±¡, è¿˜æ˜¯å…ˆç”¨ ConfigMap å®šä¹‰å®ƒçš„ç¯å¢ƒå˜é‡: 

```yaml
# wp-cm.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: wp-cm

data:
  #  "HOST"å­—æ®µ, å®ƒå¿…é¡»æ˜¯ MariaDB Pod çš„ IP åœ°å€, å¦‚æœä¸å†™æ­£ç¡® WordPress ä¼šæ— æ³•æ­£å¸¸è¿æ¥æ•°æ®åº“. 
  HOST: '172.17.0.2'
  USER: 'wp'
  PASSWORD: '123'
  NAME: 'db'

```



```yaml
# wp-pod.yml
apiVersion: v1
kind: Pod
metadata:
  name: wp-pod
  labels:
    app: wordpress
    role: website

spec:
  containers:
  - image: wordpress:5
    name: wp-pod
    imagePullPolicy: IfNotPresent
    ports:
    - containerPort: 80

    envFrom:
    - prefix: 'WORDPRESS_DB_'
      configMapRef:
        name: wp-cm
```



```shell

kubectl apply -f wp-pod.yml
kubectl get pod -o wide

```

ç¬¬ä¸‰æ­¥æ˜¯ä¸º WordPress Pod æ˜ å°„ç«¯å£å·, è®©å®ƒåœ¨é›†ç¾¤å¤–å¯è§. 

å› ä¸º Pod éƒ½æ˜¯è¿è¡Œåœ¨ Kubernetes å†…éƒ¨çš„ç§æœ‰ç½‘æ®µé‡Œçš„, å¤–ç•Œæ— æ³•ç›´æ¥è®¿é—®, æƒ³è¦å¯¹å¤–æš´éœ²æœåŠ¡, éœ€è¦ä½¿ç”¨ä¸€ä¸ªä¸“é—¨çš„ kubectl port-forward å‘½ä»¤, å®ƒä¸“é—¨è´Ÿè´£æŠŠæœ¬æœºçš„ç«¯å£æ˜ å°„åˆ°åœ¨ç›®æ ‡å¯¹è±¡çš„ç«¯å£å·, æœ‰ç‚¹ç±»ä¼¼ Docker çš„å‚æ•° -p, ç»å¸¸ç”¨äº Kubernetes çš„ä¸´æ—¶è°ƒè¯•å’Œæµ‹è¯•. 

```shell

kubectl port-forward wp-pod 8080:80 &

```

å¦‚æœæƒ³å…³é—­ç«¯å£è½¬å‘, éœ€è¦æ•²å‘½ä»¤ fg , å®ƒä¼šæŠŠåå°çš„ä»»åŠ¡å¸¦å›åˆ°å‰å°, ç„¶åå°±å¯ä»¥ç®€å•åœ°ç”¨ "Ctrl + C"æ¥åœæ­¢è½¬å‘äº†. 

ç¬¬å››æ­¥æ˜¯åˆ›å»ºåå‘ä»£ç†çš„ Nginx, è®©æˆ‘ä»¬çš„ç½‘ç«™å¯¹å¤–æä¾›æœåŠ¡. 



```
# nginx.conf

server {
  listen 80;
  default_type text/html;

  location / {
      proxy_http_version 1.1;
      proxy_set_header Host $host;
      proxy_pass http://127.0.0.1:8080;
  }
}

```



```shell
#!/bin/sh

# chrono @ 2022-04

# in browser:
# http://192.168.10.208:80

# kubectl port-forward wp-pod 8080:80 &
# kubectl port-forward proxy-pod 8080:80 &

cat << "EOF" > /tmp/proxy.conf
server {
  listen 80;
  default_type text/html;

  location / {
      proxy_http_version 1.1;
      proxy_set_header Host $host;

      proxy_pass http://127.0.0.1:8080;
  }
}
EOF

docker run -d --rm \
    --net=host \
    -v /tmp/proxy.conf:/etc/nginx/conf.d/default.conf \
    nginx:alpine


```

å¯åŠ¨ nginx å®¹å™¨

```shell

docker run -d --rm \
    --net=host \
    -v /tmp/proxy.conf:/etc/nginx/conf.d/default.conf \
    nginx:alpine
```

æœ‰äº† Nginx çš„åå‘ä»£ç†ä¹‹å, å°±å¯ä»¥æ‰“å¼€æµè§ˆå™¨, è¾“å…¥æœ¬æœºçš„ "127.0.0.1"æˆ–è€…æ˜¯è™šæ‹Ÿæœºçš„ IP åœ°å€ï¼ˆæˆ‘è¿™é‡Œä»ç„¶æ˜¯ "http://192.168.10.208"), çœ‹åˆ° WordPress çš„ç•Œé¢: 



ä½ ä¹Ÿå¯ä»¥åœ¨ Kubernetes é‡Œä½¿ç”¨å‘½ä»¤ kubectl logs æŸ¥çœ‹ WordPress, MariaDB ç­‰ Pod çš„è¿è¡Œæ—¥å¿—, æ¥éªŒè¯å®ƒä»¬æ˜¯å¦å·²ç»æ­£ç¡®åœ°å“åº”äº†è¯·æ±‚: 



ä½¿ç”¨ Dashboard ç®¡ç† Kubernetes

```shell

minikube dashboard

```



## kubeadmin

https://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/



ä¸ºäº†ç®€åŒ– Kubernetes çš„éƒ¨ç½²å·¥ä½œ, è®©å®ƒèƒ½å¤Ÿæ›´ "æ¥åœ°æ°”", ç¤¾åŒºé‡Œå°±å‡ºç°äº†ä¸€ä¸ªä¸“é—¨ç”¨æ¥åœ¨é›†ç¾¤ä¸­å®‰è£… Kubernetes çš„å·¥å…·, åå­—å°±å« "kubeadm", æ„æ€å°±æ˜¯ "Kubernetes ç®¡ç†å‘˜". 

æ‰€è°“çš„å¤šèŠ‚ç‚¹é›†ç¾¤, è¦æ±‚æœåŠ¡å™¨åº”è¯¥æœ‰ä¸¤å°æˆ–è€…æ›´å¤š, ä¸ºäº†ç®€åŒ–æˆ‘ä»¬åªå–æœ€å°å€¼, æ‰€ä»¥è¿™ä¸ª Kubernetes é›†ç¾¤å°±åªæœ‰ä¸¤å°ä¸»æœº, ä¸€å°æ˜¯ Master èŠ‚ç‚¹, å¦ä¸€å°æ˜¯ Worker èŠ‚ç‚¹. å½“ç„¶, åœ¨å®Œå…¨æŒæ¡äº† kubeadm çš„ç”¨æ³•ä¹‹å, ä½ å¯ä»¥åœ¨è¿™ä¸ªé›†ç¾¤é‡Œæ·»åŠ æ›´å¤šçš„èŠ‚ç‚¹. 

è€Œ Worker èŠ‚ç‚¹æ²¡æœ‰ç®¡ç†å·¥ä½œ, åªè¿è¡Œä¸šåŠ¡åº”ç”¨, æ‰€ä»¥é…ç½®å¯ä»¥ä½ä¸€äº›, ä¸ºäº†èŠ‚çœèµ„æºæˆ‘ç»™å®ƒåˆ†é…äº† 1 æ ¸ CPU å’Œ 1GB çš„å†…å­˜, å¯ä»¥è¯´æ˜¯ä½åˆ°ä¸èƒ½å†ä½äº†. 

åŸºäºæ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒçš„è€ƒè™‘, åœ¨ Kubernetes é›†ç¾¤ä¹‹å¤–è¿˜éœ€è¦æœ‰ä¸€å°èµ·è¾…åŠ©ä½œç”¨çš„æœåŠ¡å™¨. 

å®ƒçš„åå­—å« Console, æ„æ€æ˜¯æ§åˆ¶å°, æˆ‘ä»¬è¦åœ¨ä¸Šé¢å®‰è£…å‘½ä»¤è¡Œå·¥å…· kubectl, æ‰€æœ‰å¯¹ Kubernetes é›†ç¾¤çš„ç®¡ç†å‘½ä»¤éƒ½æ˜¯ä»è¿™å°ä¸»æœºå‘å‡ºå»çš„. è¿™ä¹Ÿæ¯”è¾ƒç¬¦åˆå®é™…æƒ…å†µ, å› ä¸ºå®‰å…¨çš„åŸå› , é›†ç¾¤é‡Œçš„ä¸»æœºéƒ¨ç½²å¥½ä¹‹ååº”è¯¥å°½é‡å°‘ç›´æ¥ç™»å½•ä¸Šå»æ“ä½œ. 

è¦æé†’ä½ çš„æ˜¯, Console è¿™å°ä¸»æœºåªæ˜¯é€»è¾‘ä¸Šçš„æ¦‚å¿µ, ä¸ä¸€å®šè¦æ˜¯ç‹¬ç«‹, ä½ åœ¨å®é™…å®‰è£…éƒ¨ç½²çš„æ—¶å€™å®Œå…¨å¯ä»¥å¤ç”¨ä¹‹å‰ minikube çš„è™šæ‹Ÿæœº, æˆ–è€…ç›´æ¥ä½¿ç”¨ Master/Worker èŠ‚ç‚¹ä½œä¸ºæ§åˆ¶å°. 

#### å®‰è£…å‰çš„å‡†å¤‡å·¥ä½œ

åŒ…æ‹¬æ”¹ä¸»æœºå, æ”¹ Docker é…ç½®, æ”¹ç½‘ç»œè®¾ç½®, æ”¹äº¤æ¢åˆ†åŒºè¿™å››æ­¥. 

ç¬¬ä¸€, ç”±äº Kubernetes ä½¿ç”¨ä¸»æœºåæ¥åŒºåˆ†é›†ç¾¤é‡Œçš„èŠ‚ç‚¹, æ‰€ä»¥æ¯ä¸ªèŠ‚ç‚¹çš„ hostname å¿…é¡»ä¸èƒ½é‡å. ä½ éœ€è¦ä¿®æ”¹ "/etc/hostname"è¿™ä¸ªæ–‡ä»¶, æŠŠå®ƒæ”¹æˆå®¹æ˜“è¾¨è¯†çš„åå­—, æ¯”å¦‚ Master èŠ‚ç‚¹å°±å« master, Worker èŠ‚ç‚¹å°±å« worker: 

```shell

sudo vi /etc/hostname

```

ç¬¬äºŒ, è™½ç„¶ Kubernetes ç›®å‰æ”¯æŒå¤šç§å®¹å™¨è¿è¡Œæ—¶, ä½† Docker è¿˜æ˜¯æœ€æ–¹ä¾¿æœ€æ˜“ç”¨çš„ä¸€ç§, æ‰€ä»¥æˆ‘ä»¬ä»ç„¶ç»§ç»­ä½¿ç”¨ Docker ä½œä¸º Kubernetes çš„åº•å±‚æ”¯æŒ, ä½¿ç”¨ apt å®‰è£… Docker Engineï¼ˆå¯å‚è€ƒç¬¬ 1 è®²). 

docker 20 å¼€å§‹, é»˜è®¤é©±åŠ¨å°±æ˜¯ systemd, å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ¥æŸ¥çœ‹

```shell

ubuntu@server01:~$ docker info | grep Cgroup
 Cgroup Driver: systemd
 Cgroup Version: 2

```



å®‰è£…å®Œæˆåéœ€è¦ä½ å†å¯¹ Docker çš„é…ç½®åšä¸€ç‚¹ä¿®æ”¹, åœ¨ "/etc/docker/daemon.json"é‡ŒæŠŠ cgroup çš„é©±åŠ¨ç¨‹åºæ”¹æˆ systemd , ç„¶åé‡å¯ Docker çš„å®ˆæŠ¤è¿›ç¨‹, å…·ä½“çš„æ“ä½œæˆ‘åˆ—åœ¨äº†ä¸‹é¢: 

```shell

cat <<EOF | sudo tee /etc/docker/daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF

sudo systemctl enable docker
sudo systemctl daemon-reload
sudo systemctl restart docker
```

ç¬¬ä¸‰, ä¸ºäº†è®© Kubernetes èƒ½å¤Ÿæ£€æŸ¥, è½¬å‘ç½‘ç»œæµé‡, ä½ éœ€è¦ä¿®æ”¹ iptables çš„é…ç½®, å¯ç”¨ "br_netfilter"æ¨¡å—: 

https://kubernetes.io/zh-cn/docs/setup/production-environment/container-runtimes/

è½¬å‘ IPv4 å¹¶è®© iptables çœ‹åˆ°æ¡¥æ¥æµé‡

```shell
# imooc è¯¾ç¨‹
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
br_netfilter
EOF

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward=1 # better than modify /etc/sysctl.conf
EOF

sudo sysctl --system

# å®˜æ–¹æ–‡æ¡£
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# è®¾ç½®æ‰€éœ€çš„ sysctl å‚æ•°, å‚æ•°åœ¨é‡æ–°å¯åŠ¨åä¿æŒä¸å˜
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# åº”ç”¨ sysctl å‚æ•°è€Œä¸é‡æ–°å¯åŠ¨
sudo sysctl --system

# é€šè¿‡è¿è¡Œä»¥ä¸‹æŒ‡ä»¤ç¡®è®¤ br_netfilter å’Œ overlay æ¨¡å—è¢«åŠ è½½: 
lsmod | grep br_netfilter
lsmod | grep overlay

# é€šè¿‡è¿è¡Œä»¥ä¸‹æŒ‡ä»¤ç¡®è®¤ net.bridge.bridge-nf-call-iptables, net.bridge.bridge-nf-call-ip6tables å’Œ net.ipv4.ip_forward ç³»ç»Ÿå˜é‡åœ¨ä½ çš„ sysctl é…ç½®ä¸­è¢«è®¾ç½®ä¸º 1: 
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward
```

ç¬¬å››, ä½ éœ€è¦ä¿®æ”¹ "/etc/fstab", å…³é—­ Linux çš„ swap åˆ†åŒº, æå‡ Kubernetes çš„æ€§èƒ½: 

å…³é—­ Linux çš„ swap åˆ†åŒºå¯èƒ½ä¼šæå‡ Kubernetes çš„æ€§èƒ½, ä½†è¿™å–å†³äºæ‚¨çš„åº”ç”¨ç¨‹åºçš„å·¥ä½œè´Ÿè½½å’Œå¯ç”¨çš„ç³»ç»Ÿèµ„æº. 

åœ¨æŸäº›æƒ…å†µä¸‹, å½“ç³»ç»Ÿå†…å­˜ä¸è¶³æ—¶, Linuxä¼šä½¿ç”¨swapåˆ†åŒºæ¥å°†æœªä½¿ç”¨çš„å†…å­˜è½¬ç§»åˆ°ç¡¬ç›˜ä¸Š, ä»¥é‡Šæ”¾æ›´å¤šå†…å­˜ç”¨äºæ´»åŠ¨è¿›ç¨‹. ä½†æ˜¯, å°†æœªä½¿ç”¨çš„å†…å­˜è½¬ç§»åˆ°ç¡¬ç›˜ä¸Šä¼šé™ä½ç³»ç»Ÿæ€§èƒ½. å› æ­¤, å¦‚æœæ‚¨çš„åº”ç”¨ç¨‹åºçš„å·¥ä½œè´Ÿè½½éœ€è¦å¤§é‡çš„å†…å­˜, è€Œç³»ç»Ÿå†…å­˜ä¸è¶³, åˆ™å…³é—­swapåˆ†åŒºå¯èƒ½ä¼šæé«˜æ€§èƒ½. 

ç„¶è€Œ, å…³é—­swapåˆ†åŒºä¹Ÿæœ‰ä¸€äº›æ½œåœ¨çš„é£é™©. ä¾‹å¦‚, å¦‚æœæ‚¨çš„ç³»ç»Ÿå†…å­˜ä¸è¶³, ä¸”æœªå…³é—­swapåˆ†åŒº, åˆ™å¯èƒ½ä¼šå¯¼è‡´å†…å­˜ä¸è¶³é”™è¯¯å’Œåº”ç”¨ç¨‹åºå´©æºƒ. æ­¤å¤–, å¦‚æœæ‚¨çš„åº”ç”¨ç¨‹åºéœ€è¦å¤§é‡çš„å†…å­˜ä¸”ç³»ç»Ÿå†…å­˜ä¸è¶³, åˆ™å…³é—­swapåˆ†åŒºå¯èƒ½ä¼šå¯¼è‡´ç³»ç»Ÿæ­»æœº. 

å› æ­¤, åœ¨å…³é—­swapåˆ†åŒºä¹‹å‰, æ‚¨åº”è¯¥è€ƒè™‘æ‚¨çš„åº”ç”¨ç¨‹åºçš„å·¥ä½œè´Ÿè½½å’Œå¯ç”¨çš„ç³»ç»Ÿèµ„æº, ä»¥ç¡®ä¿è¿™æ ·åšä¸ä¼šå¯¼è‡´æ€§èƒ½é—®é¢˜æˆ–ç³»ç»Ÿä¸ç¨³å®š. åŒæ—¶, æ‚¨ä¹Ÿåº”è¯¥è°¨æ…åœ°è¿›è¡Œæµ‹è¯•å’Œç›‘æ§, ä»¥ç¡®ä¿å…³é—­swapåˆ†åŒºä¸ä¼šå¯¹ç³»ç»Ÿæ€§èƒ½æˆ–ç¨³å®šæ€§äº§ç”Ÿè´Ÿé¢å½±å“. 

`æ³¨æ„: ` å¿…é¡»è¦å…³é—­ swap åˆ†åŒº, å¦åˆ™åœ¨ kubeadm init æ—¶ä¼šæŠ¥é”™

```shell
root@server02:~# sudo kubeadm init \
    --pod-network-cidr=10.10.0.0/16 \
    --apiserver-advertise-address=192.168.10.210
[init] Using Kubernetes version: v1.26.3
[preflight] Running pre-flight checks
        [WARNING Swap]: swap is enabled; production deployments should disable swap unless testing the NodeSwap feature gate of the kubelet
error execution phase preflight: [preflight] Some fatal errors occurred:
        [ERROR CRI]: container runtime is not running: output: time="2023-03-28T10:16:09Z" level=fatal msg="validate service connection: CRI v1 runtime API is not implemented for endpoint \"unix:///var/run/containerd/containerd.sock\": rpc error: code = Unimplemented desc = unknown service runtime.v1.RuntimeService"
, error: exit status 1
[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
To see the stack trace of this error execute with --v=5 or higher

```



```shell
# Check if you have swap space enabled
sudo swapon --show
root@server02:~# sudo swapon --show
NAME      TYPE SIZE USED PRIO
/swap.img file 3.8G   0B   -2

# remove the swap entry from the /etc/fstab file. Open the file using a text editor with the following command:
# sudo nano /etc/fstab
# Find the line that references your swap partition or file and delete it. Save and exit the file.
sudo sed -ri '/\sswap\s/s/^#?/#/' /etc/fstab

# disable swap space
sudo swapoff -a
```



```shell
root@server01:~# cat /etc/fstab
# /etc/fstab: static file system information.
#
# Use 'blkid' to print the universally unique identifier for a
# device; this may be used with UUID= as a more robust way to name devices
# that works even if disks are added and removed. See fstab(5).
#
# <file system> <mount point>   <type>  <options>       <dump>  <pass>
# / was on /dev/ubuntu-vg/ubuntu-lv during curtin installation
/dev/disk/by-id/dm-uuid-LVM-7LAKs5lKcHQKXytimCD31JZgM1JLacG2uIvfqBT3bgULE4ceQnrTn6mq80UNcpGi / ext4 defaults 0 1
# /boot was on /dev/sda2 during curtin installation
/dev/disk/by-uuid/3c1930f3-4c87-4db4-8cac-5d0485d0aa31 /boot ext4 defaults 0 1
# /swap.img     none    swap    sw      0       0

```



#### å®‰è£… kubeadm

https://kubernetes.io/zh-cn/docs/tasks/tools/

https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

æŸ¥çœ‹ 6443 ç«¯å£æ˜¯å¦å¯ç”¨

netstat -tlnp | grep 6443

kubeadm å¯ä»¥ç›´æ¥ä» Google è‡ªå·±çš„è½¯ä»¶ä»“åº“ä¸‹è½½å®‰è£…, ä½†å›½å†…çš„ç½‘ç»œä¸ç¨³å®š, å¾ˆéš¾ä¸‹è½½æˆåŠŸ, éœ€è¦æ”¹ç”¨å…¶ä»–çš„è½¯ä»¶æº, è¿™é‡Œæˆ‘é€‰æ‹©äº†å›½å†…çš„æŸäº‘å‚å•†: 

https://developer.aliyun.com/mirror/kubernetes/

```shell
sudo apt-get update

sudo apt install -y apt-transport-https ca-certificates curl

curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add -

cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
EOF

æˆ–
# cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
# deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
# EOF

sudo apt update
```

æ›´æ–°äº†è½¯ä»¶ä»“åº“, æˆ‘ä»¬å°±å¯ä»¥ç”¨ apt install è·å– kubeadm, kubelet å’Œ kubectl è¿™ä¸‰ä¸ªå®‰è£…å¿…å¤‡å·¥å…·äº†. apt é»˜è®¤ä¼šä¸‹è½½æœ€æ–°ç‰ˆæœ¬, ä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥æŒ‡å®šç‰ˆæœ¬å·, æ¯”å¦‚ä½¿ç”¨å’Œ minikube ç›¸åŒçš„ "1.23.3": 

```shell
root@worker02:~# apt list -a kubeadm | grep 1.23

WARNING: apt does not have a stable CLI interface. Use with caution in scripts.

kubeadm/kubernetes-xenial 1.23.17-00 amd64
kubeadm/kubernetes-xenial 1.23.16-00 amd64
...

sudo apt install -y kubeadm=1.23.3-00 kubelet=1.23.3-00 kubectl=1.23.3-00
sudo apt install -y kubeadm=1.23.17-00 kubelet=1.23.17-00 kubectl=1.23.17-00
```



å®‰è£…å®Œæˆä¹‹å, ä½ å¯ä»¥ç”¨ kubeadm version, kubectl version æ¥éªŒè¯ç‰ˆæœ¬æ˜¯å¦æ­£ç¡®: 

```shell

kubeadm version
root@server01:~# kubeadm version
kubeadm version: &version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.3", GitCommit:"9e644106593f3f4aa98f8a84b23db5fa378900bd", GitTreeState:"clean", BuildDate:"2023-03-15T13:38:47Z", GoVersion:"go1.19.7", Compiler:"gc", Platform:"linux/amd64"}

kubectl version --client
root@server02:~# kubectl version --client
WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
Client Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.3", GitCommit:"9e644106593f3f4aa98f8a84b23db5fa378900bd", GitTreeState:"clean", BuildDate:"2023-03-15T13:40:17Z", GoVersion:"go1.19.7", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v4.5.7

root@server02:~# kubectl version --short
Flag --short has been deprecated, and will be removed in the future. The --short output will become the default.
Client Version: v1.26.3
Kustomize Version: v4.5.7
The connection to the server localhost:8080 was refused - did you specify the right host or port?


root@server02:~# kubectl version --output=yaml
clientVersion:
  buildDate: "2023-03-15T13:40:17Z"
  compiler: gc
  gitCommit: 9e644106593f3f4aa98f8a84b23db5fa378900bd
  gitTreeState: clean
  gitVersion: v1.26.3
  goVersion: go1.19.7
  major: "1"
  minor: "26"
  platform: linux/amd64
kustomizeVersion: v4.5.7

The connection to the server localhost:8080 was refused - did you specify the right host or port?

root@server02:~# kubectl version --output=json
{
  "clientVersion": {
    "major": "1",
    "minor": "26",
    "gitVersion": "v1.26.3",
    "gitCommit": "9e644106593f3f4aa98f8a84b23db5fa378900bd",
    "gitTreeState": "clean",
    "buildDate": "2023-03-15T13:40:17Z",
    "goVersion": "go1.19.7",
    "compiler": "gc",
    "platform": "linux/amd64"
  },
  "kustomizeVersion": "v4.5.7"
}
The connection to the server localhost:8080 was refused - did you specify the right host or port?

```



å¦å¤–æŒ‰ç…§ Kubernetes å®˜ç½‘çš„è¦æ±‚, æˆ‘ä»¬æœ€å¥½å†ä½¿ç”¨å‘½ä»¤ apt-mark hold , é”å®šè¿™ä¸‰ä¸ªè½¯ä»¶çš„ç‰ˆæœ¬, é¿å…æ„å¤–å‡çº§å¯¼è‡´ç‰ˆæœ¬é”™è¯¯: 

```shell\

sudo apt-mark hold kubeadm kubelet kubectl

apt-mark showhold

sudo apt-mark unhold kubeadm kubelet kubectl
```

#### ä¸‹è½½ Kubernetes ç»„ä»¶é•œåƒ

å‰é¢æˆ‘è¯´è¿‡, kubeadm æŠŠ apiserver, etcd, scheduler ç­‰ç»„ä»¶éƒ½æ‰“åŒ…æˆäº†é•œåƒ, ä»¥å®¹å™¨çš„æ–¹å¼å¯åŠ¨ Kubernetes, ä½†è¿™äº›é•œåƒä¸æ˜¯æ”¾åœ¨ Docker Hub ä¸Š, è€Œæ˜¯æ”¾åœ¨ Google è‡ªå·±çš„é•œåƒä»“åº“ç½‘ç«™ gcr.io, è€Œå®ƒåœ¨å›½å†…çš„è®¿é—®å¾ˆå›°éš¾, ç›´æ¥æ‹‰å–é•œåƒå‡ ä¹æ˜¯ä¸å¯èƒ½çš„. 

ä½¿ç”¨å‘½ä»¤ kubeadm config images list å¯ä»¥æŸ¥çœ‹å®‰è£… Kubernetes æ‰€éœ€çš„é•œåƒåˆ—è¡¨, å‚æ•° --kubernetes-version å¯ä»¥æŒ‡å®šç‰ˆæœ¬å·: 

```shell

root@server01:~# kubeadm config images list

registry.k8s.io/kube-apiserver:v1.26.3
registry.k8s.io/kube-controller-manager:v1.26.3
registry.k8s.io/kube-scheduler:v1.26.3
registry.k8s.io/kube-proxy:v1.26.3
registry.k8s.io/pause:3.9
registry.k8s.io/etcd:3.5.6-0
registry.k8s.io/coredns/coredns:v1.9.3

root@server01:~# kubeadm config images list --kubernetes-version=v1.23.17
registry.k8s.io/kube-apiserver:v1.23.17
registry.k8s.io/kube-controller-manager:v1.23.17
registry.k8s.io/kube-scheduler:v1.23.17
registry.k8s.io/kube-proxy:v1.23.17
registry.k8s.io/pause:3.6
registry.k8s.io/etcd:3.5.6-0
registry.k8s.io/coredns/coredns:v1.8.6

root@worker02:~# kubeadm config images pull --kubernetes-version=v1.23.17
[config/images] Pulled registry.k8s.io/kube-apiserver:v1.23.17
[config/images] Pulled registry.k8s.io/kube-controller-manager:v1.23.17
[config/images] Pulled registry.k8s.io/kube-scheduler:v1.23.17
[config/images] Pulled registry.k8s.io/kube-proxy:v1.23.17
[config/images] Pulled registry.k8s.io/pause:3.6
[config/images] Pulled registry.k8s.io/etcd:3.5.6-0
[config/images] Pulled registry.k8s.io/coredns/coredns:v1.8.6

```

è™šæ‹Ÿæœºåˆ›å»ºå¿«ç…§

```shell
vmrun.exe snapshot C:\vmware\k8s\server01\server01.vmx 20230329-pull-k8s
vmrun.exe snapshot C:\vmware\k8s\worker01\worker01.vmx 20230329-pull-k8s
vmrun.exe snapshot C:\vmware\k8s\worker02\worker02.vmx 20230329-pull-k8s
vmrun.exe snapshot C:\vmware\k8s\worker03\worker03.vmx 20230329-pull-k8s

vmrun.exe start C:\vmware\k8s\server01\server01.vmx
vmrun.exe start C:\vmware\k8s\worker01\worker01.vmx
vmrun.exe start C:\vmware\k8s\worker02\worker02.vmx
vmrun.exe start C:\vmware\k8s\worker03\worker03.vmx
```



#### ä½¿ç”¨ kubeadm åˆ›å»ºé›†ç¾¤

https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/

````shell
root@server01:~# kubeadm init -h
Run this command in order to set up the Kubernetes control plane

The "init" command executes the following phases:
```
preflight                    Run pre-flight checks
certs                        Certificate generation
  /ca                          Generate the self-signed Kubernetes CA to provision identities for other Kubernetes components
  /apiserver                   Generate the certificate for serving the Kubernetes API
  /apiserver-kubelet-client    Generate the certificate for the API server to connect to kubelet
  /front-proxy-ca              Generate the self-signed CA to provision identities for front proxy
  /front-proxy-client          Generate the certificate for the front proxy client
  /etcd-ca                     Generate the self-signed CA to provision identities for etcd
  /etcd-server                 Generate the certificate for serving etcd
  /etcd-peer                   Generate the certificate for etcd nodes to communicate with each other
  /etcd-healthcheck-client     Generate the certificate for liveness probes to healthcheck etcd
  /apiserver-etcd-client       Generate the certificate the apiserver uses to access etcd
  /sa                          Generate a private key for signing service account tokens along with its public key
kubeconfig                   Generate all kubeconfig files necessary to establish the control plane and the admin kubeconfig file
  /admin                       Generate a kubeconfig file for the admin to use and for kubeadm itself
  /kubelet                     Generate a kubeconfig file for the kubelet to use *only* for cluster bootstrapping purposes
  /controller-manager          Generate a kubeconfig file for the controller manager to use
  /scheduler                   Generate a kubeconfig file for the scheduler to use
kubelet-start                Write kubelet settings and (re)start the kubelet
control-plane                Generate all static Pod manifest files necessary to establish the control plane
  /apiserver                   Generates the kube-apiserver static Pod manifest
  /controller-manager          Generates the kube-controller-manager static Pod manifest
  /scheduler                   Generates the kube-scheduler static Pod manifest
etcd                         Generate static Pod manifest file for local etcd
  /local                       Generate the static Pod manifest file for a local, single-node local etcd instance
upload-config                Upload the kubeadm and kubelet configuration to a ConfigMap
  /kubeadm                     Upload the kubeadm ClusterConfiguration to a ConfigMap
  /kubelet                     Upload the kubelet component config to a ConfigMap
upload-certs                 Upload certificates to kubeadm-certs
mark-control-plane           Mark a node as a control-plane
bootstrap-token              Generates bootstrap tokens used to join a node to a cluster
kubelet-finalize             Updates settings relevant to the kubelet after TLS bootstrap
  /experimental-cert-rotation  Enable kubelet client certificate rotation
addon                        Install required addons for passing conformance tests
  /coredns                     Install the CoreDNS addon to a Kubernetes cluster
  /kube-proxy                  Install the kube-proxy addon to a Kubernetes cluster
show-join-command            Show the join command for control-plane and worker node
```

Usage:
  kubeadm init [flags]
  kubeadm init [command]

Available Commands:
  phase       Use this command to invoke single phase of the init workflow

Flags:
      --apiserver-advertise-address string   The IP address the API Server will advertise it's listening on. If not set the default network interface will be used.
      --apiserver-bind-port int32            Port for the API Server to bind to. (default 6443)
      --apiserver-cert-extra-sans strings    Optional extra Subject Alternative Names (SANs) to use for the API Server serving certificate. Can be both IP addresses and DNS names.
      --cert-dir string                      The path where to save and store the certificates. (default "/etc/kubernetes/pki")
      --certificate-key string               Key used to encrypt the control-plane certificates in the kubeadm-certs Secret.
      --config string                        Path to a kubeadm configuration file.
      --control-plane-endpoint string        Specify a stable IP address or DNS name for the control plane.
      --cri-socket string                    Path to the CRI socket to connect. If empty kubeadm will try to auto-detect this value; use this option only if you have more than one CRI installed or if you have non-standard CRI socket.
      --dry-run                              Don't apply any changes; just output what would be done.
      --feature-gates string                 A set of key=value pairs that describe feature gates for various features. Options are:
                                             PublicKeysECDSA=true|false (ALPHA - default=false)
                                             RootlessControlPlane=true|false (ALPHA - default=false)
  -h, --help                                 help for init
      --ignore-preflight-errors strings      A list of checks whose errors will be shown as warnings. Example: 'IsPrivilegedUser,Swap'. Value 'all' ignores errors from all checks.
      --image-repository string              Choose a container registry to pull control plane images from (default "registry.k8s.io")
      --kubernetes-version string            Choose a specific Kubernetes version for the control plane. (default "stable-1")
      --node-name string                     Specify the node name.
      --patches string                       Path to a directory that contains files named "target[suffix][+patchtype].extension". For example, "kube-apiserver0+merge.yaml" or just "etcd.json". "target" can be one of "kube-apiserver", "kube-controller-manager", "kube-scheduler", "etcd", "kubeletconfiguration". "patchtype" can be one of "strategic", "merge" or "json" and they match the patch formats supported by kubectl. The default "patchtype" is "strategic". "extension" must be either "json" or "yaml". "suffix" is an optional string that can be used to determine which patches are applied first alpha-numerically.
      --pod-network-cidr string              Specify range of IP addresses for the pod network. If set, the control plane will automatically allocate CIDRs for every node.
      --service-cidr string                  Use alternative range of IP address for service VIPs. (default "10.96.0.0/12")
      --service-dns-domain string            Use alternative domain for services, e.g. "myorg.internal". (default "cluster.local")
      --skip-certificate-key-print           Don't print the key used to encrypt the control-plane certificates.
      --skip-phases strings                  List of phases to be skipped
      --skip-token-print                     Skip printing of the default bootstrap token generated by 'kubeadm init'.
      --token string                         The token to use for establishing bidirectional trust between nodes and control-plane nodes. The format is [a-z0-9]{6}\.[a-z0-9]{16} - e.g. abcdef.0123456789abcdef
      --token-ttl duration                   The duration before the token is automatically deleted (e.g. 1s, 2m, 3h). If set to '0', the token will never expire (default 24h0m0s)
      --upload-certs                         Upload control-plane certificates to the kubeadm-certs Secret.

Global Flags:
      --add-dir-header           If true, adds the file directory to the header of the log messages
      --log-file string          If non-empty, use this log file (no effect when -logtostderr=true)
      --log-file-max-size uint   Defines the maximum size a log file can grow to (no effect when -logtostderr=true). Unit is megabytes. If the value is 0, the maximum file size is unlimited. (default 1800)
      --one-output               If true, only write logs to their native severity level (vs also writing to each lower severity level; no effect when -logtostderr=true)
      --rootfs string            [EXPERIMENTAL] The path to the 'real' host root filesystem.
      --skip-headers             If true, avoid header prefixes in the log messages
      --skip-log-headers         If true, avoid headers when opening log files (no effect when -logtostderr=true)
  -v, --v Level                  number for the log level verbosity

Use "kubeadm init [command] --help" for more information about a command.

````

[ä½¿ç”¨ Kubeadm éƒ¨ç½² | å‡¤å‡°æ¶æ„ (icyfenix.cn)](http://icyfenix.cn/appendix/deployment-env-setup/setup-kubernetes/setup-kubeadm.html)

[A.2.3 é›†ç¾¤åˆå§‹åŒ– Â· Kubernetes Documentation (renkeju.com)](https://kubernetes.renkeju.com/deploy/A.2.3.cluster-initialization.html)

kubeadm çš„ç”¨æ³•éå¸¸ç®€å•, åªéœ€è¦ä¸€ä¸ªå‘½ä»¤ kubeadm init å°±å¯ä»¥æŠŠç»„ä»¶åœ¨ Master èŠ‚ç‚¹ä¸Šè¿è¡Œèµ·æ¥, ä¸è¿‡å®ƒè¿˜æœ‰å¾ˆå¤šå‚æ•°ç”¨æ¥è°ƒæ•´é›†ç¾¤çš„é…ç½®, ä½ å¯ä»¥ç”¨ -h æŸ¥çœ‹. è¿™é‡Œæˆ‘åªè¯´ä¸€ä¸‹æˆ‘ä»¬å®éªŒç¯å¢ƒç”¨åˆ°çš„ 3 ä¸ªå‚æ•°: 

```
--pod-network-cidr, è®¾ç½®é›†ç¾¤é‡Œ Pod çš„ IP åœ°å€æ®µ. å‚æ•°æ˜¯ç»™Flannelç½‘ç»œåšç½‘æ®µåˆ’åˆ†ä½¿ç”¨çš„

https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network

--apiserver-advertise-address, è®¾ç½® apiserver çš„ IP åœ°å€, å¯¹äºå¤šç½‘å¡æœåŠ¡å™¨æ¥è¯´å¾ˆé‡è¦ï¼ˆæ¯”å¦‚ VirtualBox è™šæ‹Ÿæœºå°±ç”¨äº†ä¸¤å—ç½‘å¡), å¯ä»¥æŒ‡å®š apiserver åœ¨å“ªä¸ªç½‘å¡ä¸Šå¯¹å¤–æä¾›æœåŠ¡. 

`--apiserver-advertise-address` å‚æ•°æ˜¯APIServerçš„IPåœ°å€, å¦‚æœæœ‰å¤šå¼ ç‰©ç†ç½‘å¡, å»ºè®®æŒ‡å®šæ˜ç¡®çš„IPåœ°å€æ¥å»ºç«‹Kubernetesé›†ç¾¤. å› ä¸ºCAè¯ä¹¦ç›´æ¥ä¸åœ°å€ç›¸å…³, Kubernetesä¸­è¯¸å¤šé…ç½®ï¼ˆé…ç½®æ–‡ä»¶, ConfigMapèµ„æº)ä¹Ÿç›´æ¥å­˜å‚¨äº†è¿™ä¸ªåœ°å€, ä¸€æ—¦æ›´æ¢IP, è¦æƒ³è¦ä¸é‡ç½®é›†ç¾¤, æ‰‹å·¥æ¢èµ·æ¥å¼‚å¸¸éº»çƒ¦. 

`â€“-apiserver-advertise-address` æŒ‡æ˜ç”¨Masterçš„å“ªä¸ªinterfaceä¸Cluster çš„å…¶ä»–èŠ‚ç‚¹é€šä¿¡.  å¦‚æœMasteræœ‰å¤šä¸ªinterface, å»ºè®®æ˜ç¡®æŒ‡å®š, å¦‚æœ ä¸æŒ‡å®š, kubeadmä¼šè‡ªåŠ¨é€‰æ‹©æœ‰é»˜è®¤ç½‘å…³çš„interface. 

`--apiserver-advertise-address` API server é€šå‘Šç»™å…¶ä»–ç»„ä»¶çš„ IP åœ°å€, ä¸€èˆ¬åº”è¯¥ä¸º Master èŠ‚ç‚¹çš„ IP åœ°å€, 0.0.0.0 è¡¨ç¤ºèŠ‚ç‚¹ä¸Šæ‰€æœ‰å¯ç”¨çš„åœ°å€. 

`--kubernetes-version`å‚æ•°æŒ‡å®š Kubernetes çš„ç‰ˆæœ¬å·. è¦æ³¨æ„ç‰ˆæœ¬å·ä¸ kubelet ä¸€è‡´, ä¸å‰é¢é¢„æ‹‰å–æ˜¯ä¸€æ ·çš„, é¿å…é¢å¤–çš„ç½‘ç»œè®¿é—®å»æŸ¥è¯¢ç‰ˆæœ¬å·; å¦‚æœèƒ½å¤Ÿç§‘å­¦ä¸Šç½‘, ä¸éœ€è¦åŠ è¿™ä¸ªå‚æ•°. 

ï¼ˆæ¨è)å¦‚æœè®¡åˆ’å°†å•ä¸ªæ§åˆ¶å¹³é¢ kubeadm é›†ç¾¤å‡çº§æˆé«˜å¯ç”¨, ä½ åº”è¯¥æŒ‡å®š --control-plane-endpoint ä¸ºæ‰€æœ‰æ§åˆ¶å¹³é¢èŠ‚ç‚¹è®¾ç½®å…±äº«ç«¯ç‚¹.  ç«¯ç‚¹å¯ä»¥æ˜¯è´Ÿè½½å‡è¡¡å™¨çš„ DNS åç§°æˆ– IP åœ°å€. 

root@server01:~# resolvectl status | grep Current
    Current Scopes: DNS
Current DNS Server: 192.168.116.2
Current Scopes: none

```



ä¸‹é¢çš„è¿™ä¸ªå®‰è£…å‘½ä»¤é‡Œ, æˆ‘æŒ‡å®šäº† Pod çš„åœ°å€æ®µæ˜¯ "10.10.0.0/16", apiserver çš„æœåŠ¡åœ°å€æ˜¯ "192.168.10.210", Kubernetes çš„ç‰ˆæœ¬å·æ˜¯ "1.23.3": 

```shell

sudo kubeadm init \
    --pod-network-cidr=10.10.0.0/16 \
    --apiserver-advertise-address=192.168.116.150 \
    --control-plane-endpoint=192.168.116.150 \
    --kubernetes-version=v1.23.17
    
```

kubeadm init å®‰è£…æŠ¥é”™

```shell

root@server01:~# kubeadm init \
 --pod-network-cidr=10.10.0.0/16 \
 --apiserver-advertise-address=192.168.10.210
[init] Using Kubernetes version: v1.26.3
[preflight] Running pre-flight checks
error execution phase preflight: [preflight] Some fatal errors occurred:
        [ERROR CRI]: container runtime is not running: output: time="2023-03-28T10:55:31Z" level=fatal msg="validate service connection: CRI v1 runtime API is not implemented for endpoint \"unix:///var/run/containerd/containerd.sock\": rpc error: code = Unimplemented desc = unknown service runtime.v1.RuntimeService"
, error: exit status 1
[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
To see the stack trace of this error execute with --v=5 or higher


```

è§£å†³æ–¹æ¡ˆ

```shell
# rm -rf /etc/containerd/config.toml
mv /etc/containerd/config.toml /etc/containerd/config.toml.bak
systemctl restart containerd
```



```shell
master node
ubuntu@server01:~$ sudo kubeadm reset
[sudo] password for ubuntu:
[reset] Reading configuration from the cluster...
[reset] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
W0329 07:44:48.992975  469993 reset.go:106] [reset] Unable to fetch the kubeadm-config ConfigMap from cluster: failed to get config map: Get "https://192.168.116.150:6443/api/v1/namespaces/kube-system/configmaps/kubeadm-config?timeout=10s": dial tcp 192.168.116.150:6443: connect: connection refused
W0329 07:44:48.993296  469993 preflight.go:56] [reset] WARNING: Changes made to this host by 'kubeadm init' or 'kubeadm join' will be reverted.
[reset] Are you sure you want to proceed? [y/N]: y
[preflight] Running pre-flight checks
W0329 07:44:51.850180  469993 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory
[reset] Deleted contents of the etcd data directory: /var/lib/etcd
[reset] Stopping the kubelet service
[reset] Unmounting mounted directories in "/var/lib/kubelet"
[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]
[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]

The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d

The reset process does not reset or clean up iptables rules or IPVS tables.
If you wish to reset iptables, you must do so manually by using the "iptables" command.

If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)
to reset your system's IPVS tables.

The reset process does not clean your kubeconfig files and you must remove them manually.
Please, check the contents of the $HOME/.kube/config file.


ubuntu@server01:~$ sudo kubeadm init \
 --pod-network-cidr=10.10.0.0/16 \
 --apiserver-advertise-address=192.168.10.210
[init] Using Kubernetes version: v1.26.3
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'

root@server01:~# kubeadm config images pull
[config/images] Pulled registry.k8s.io/kube-apiserver:v1.26.3
[config/images] Pulled registry.k8s.io/kube-controller-manager:v1.26.3
[config/images] Pulled registry.k8s.io/kube-scheduler:v1.26.3
[config/images] Pulled registry.k8s.io/kube-proxy:v1.26.3
[config/images] Pulled registry.k8s.io/pause:3.9
[config/images] Pulled registry.k8s.io/etcd:3.5.6-0
[config/images] Pulled registry.k8s.io/coredns/coredns:v1.9.3


root@server01:~# sudo kubeadm init --pod-network-cidr=10.10.0.0/16 --apiserver-advertise-address=192.168.116.150 --control-plane-endpoint=192.168.116.150 --kubernetes-version=v1.23.17
[init] Using Kubernetes version: v1.23.17
[preflight] Running pre-flight checks
        [WARNING SystemVerification]: this Docker version is not on the list of validated versions: 23.0.2. Latest validated version: 20.10
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local server01] and IPs [10.96.0.1 192.168.116.150]
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [localhost server01] and IPs [192.168.116.150 127.0.0.1 ::1]
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [localhost server01] and IPs [192.168.116.150 127.0.0.1 ::1]
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "sa" key and public key
[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
[kubeconfig] Writing "admin.conf" kubeconfig file
[kubeconfig] Writing "kubelet.conf" kubeconfig file
[kubeconfig] Writing "controller-manager.conf" kubeconfig file
[kubeconfig] Writing "scheduler.conf" kubeconfig file
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Starting the kubelet
[control-plane] Using manifest folder "/etc/kubernetes/manifests"
[control-plane] Creating static Pod manifest for "kube-apiserver"
[control-plane] Creating static Pod manifest for "kube-controller-manager"
[control-plane] Creating static Pod manifest for "kube-scheduler"
[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
[apiclient] All control plane components are healthy after 7.504834 seconds
[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[kubelet] Creating a ConfigMap "kubelet-config-1.23" in namespace kube-system with the configuration for the kubelets in the cluster
NOTE: The "kubelet-config-1.23" naming of the kubelet ConfigMap is deprecated. Once the UnversionedKubeletConfigMap feature gate graduates to Beta the default name will become just "kubelet-config". Kubeadm upgrade will handle this transition transparently.
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node server01 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
[mark-control-plane] Marking the node server01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: ktji70.rdy7e6mniugdzcur
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of control-plane nodes by copying certificate authorities
and service account keys on each node and then running the following as root:

  kubeadm join 192.168.116.150:6443 --token ktji70.rdy7e6mniugdzcur \
        --discovery-token-ca-cert-hash sha256:f6ff89f9089d3f0b90aff7029ddfe69a7d14ac5929751106de90edd7675a6d0e \
        --control-plane

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.116.150:6443 --token ktji70.rdy7e6mniugdzcur \
        --discovery-token-ca-cert-hash sha256:f6ff89f9089d3f0b90aff7029ddfe69a7d14ac5929751106de90edd7675a6d0e

```



```shell
ubuntu@server01:~$ kubectl version
Client Version: version.Info{Major:"1", Minor:"23", GitVersion:"v1.23.17", GitCommit:"953be8927218ec8067e1af2641e540238ffd7576", GitTreeState:"clean", BuildDate:"2023-02-22T13:34:27Z", GoVersion:"go1.19.6", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"23", GitVersion:"v1.23.17", GitCommit:"953be8927218ec8067e1af2641e540238ffd7576", GitTreeState:"clean", BuildDate:"2023-02-22T13:27:46Z", GoVersion:"go1.19.6", Compiler:"gc", Platform:"linux/amd64"}

ubuntu@server01:~$ kubectl get nodes
NAME       STATUS     ROLES                  AGE     VERSION
server01   NotReady   control-plane,master   3m23s   v1.23.17

ubuntu@server01:~$ kubectl delete node server02
node "server02" deleted

```



#### é…ç½®ç½‘ç»œ

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/



[GitHub - flannel-io/flannel: flannel is a network fabric for containers, designed for Kubernetes](https://github.com/flannel-io/flannel/)

```shell
# kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml

ubuntu@server01:~$ wget https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
--2023-03-29 12:38:23--  https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
Resolving github.com (github.com)... 192.30.255.112
Connecting to github.com (github.com)|192.30.255.112|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://github.com/flannel-io/flannel/releases/download/v0.21.4/kube-flannel.yml [following]
--2023-03-29 12:38:25--  https://github.com/flannel-io/flannel/releases/download/v0.21.4/kube-flannel.yml
Reusing existing connection to github.com:443.
HTTP request sent, awaiting response...
302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/21704134/39341d29-c730-4c07-89a6-a0c4e299cc6d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230329%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230329T043825Z&X-Amz-Expires=300&X-Amz-Signature=efb1f446fbbfdbf40c440ea1db9d5e81c6c9d8f35ad140bd1d9cff3f4c01fd84&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=21704134&response-content-disposition=attachment%3B%20filename%3Dkube-flannel.yml&response-content-type=application%2Foctet-stream [following]
--2023-03-29 12:38:25--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/21704134/39341d29-c730-4c07-89a6-a0c4e299cc6d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230329%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230329T043825Z&X-Amz-Expires=300&X-Amz-Signature=efb1f446fbbfdbf40c440ea1db9d5e81c6c9d8f35ad140bd1d9cff3f4c01fd84&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=21704134&response-content-disposition=attachment%3B%20filename%3Dkube-flannel.yml&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response...
200 OK
Length: 4459 (4.4K) [application/octet-stream]
Saving to: â€˜kube-flannel.ymlâ€™

kube-flannel.yml                                    100%[=================================================================================================================>]   4.35K  --.-KB/s    in 0s

2023-03-29 12:38:26 (32.2 MB/s) - â€˜kube-flannel.ymlâ€™ saved [4459/4459]

```



ä¿®æ”¹ net-conf.json ä¸­çš„åœ°å€

```yaml

  net-conf.json: |
    {
      "Network": "10.10.0.0/16",
      "Backend": {
        "Type": "vxlan"
      }
    }

```



ä½¿ç”¨ kubectl apply æ¥å®‰è£… Flannel ç½‘ç»œäº†

```shell

kubectl apply -f kube-flannel.yml

```

ç¨ç­‰ä¸€å°ä¼š, ç­‰é•œåƒæ‹‰å–ä¸‹æ¥å¹¶è¿è¡Œä¹‹å, ä½ å°±å¯ä»¥æ‰§è¡Œ kubectl get node æ¥çœ‹èŠ‚ç‚¹çŠ¶æ€: 

```shell
ubuntu@server01:~$ kubectl get node
NAME       STATUS   ROLES                  AGE     VERSION
server01   Ready    control-plane,master   9m57s   v1.23.17

```

#### åŠ å…¥ worker èŠ‚ç‚¹



```shell
kubeadm join 192.168.116.150:6443 --token ktji70.rdy7e6mniugdzcur \
        --discovery-token-ca-cert-hash sha256:f6ff89f9089d3f0b90aff7029ddfe69a7d14ac5929751106de90edd7675a6d0e

ubuntu@server01:~$ kubectl get nodes
NAME       STATUS   ROLES                  AGE     VERSION
server01   Ready    control-plane,master   65m     v1.23.17
worker01   Ready    <none>                 2m16s   v1.23.17
worker02   Ready    <none>                 2m15s   v1.23.17
worker03   Ready    <none>                 2m16s   v1.23.17

```



### Deployment

 "Deployment", é¡¾åæ€ä¹‰, å®ƒæ˜¯ä¸“é—¨ç”¨æ¥éƒ¨ç½²åº”ç”¨ç¨‹åºçš„, èƒ½å¤Ÿè®©åº”ç”¨æ°¸ä¸å®•æœº, å¤šç”¨æ¥å‘å¸ƒæ— çŠ¶æ€çš„åº”ç”¨, æ˜¯ Kubernetes é‡Œæœ€å¸¸ç”¨ä¹Ÿæ˜¯æœ€æœ‰ç”¨çš„ä¸€ä¸ªå¯¹è±¡. 

API å¯¹è±¡ Job å’Œ CronJob, å®ƒä»¬ä»£è¡¨äº†ç”Ÿäº§ç¯å¢ƒä¸­çš„ç¦»çº¿ä¸šåŠ¡, é€šè¿‡å¯¹ Pod çš„åŒ…è£…, å‘ Pod æ·»åŠ æ§åˆ¶å­—æ®µ, å®ç°äº†åŸºäº Pod è¿è¡Œä¸´æ—¶ä»»åŠ¡å’Œå®šæ—¶ä»»åŠ¡çš„åŠŸèƒ½. 

è¿™ä¸ªç”¨æ¥ç®¡ç† Pod, å®ç°åœ¨çº¿ä¸šåŠ¡åº”ç”¨çš„æ–° API å¯¹è±¡, å°±æ˜¯ Deployment. 



```shell
$ kubectl api-resources | grep dep
deployments                       deploy       apps/v1                                true         Deployment

$ kubectl get deployment
NAME      READY   UP-TO-DATE   AVAILABLE   AGE
ngx-dep   1/1     1            1           7m24s

$ kubectl delete deployment ngx-dep

$ export out="--dry-run=client -o yaml"
$ kubectl create deploy ngx-dep --image=nginx:alpine $out
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: ngx-dep
  name: ngx-dep

spec:
  # replicas  "å‰¯æœ¬æ•°é‡"çš„æ„æ€, æŒ‡å®šè¦åœ¨ Kubernetes é›†ç¾¤é‡Œè¿è¡Œå¤šå°‘ä¸ª Pod å®ä¾‹. 
  replicas: 1
  # selector ç­›é€‰"å‡ºè¦è¢« Deployment ç®¡ç†çš„ Pod å¯¹è±¡
  selector:
    # matchLabels å®šä¹‰äº† Pod å¯¹è±¡åº”è¯¥æºå¸¦çš„ label, å®ƒå¿…é¡»å’Œ "template"é‡Œ Pod å®šä¹‰çš„ "labels"å®Œå…¨ç›¸åŒ, å¦åˆ™ Deployment å°±ä¼šæ‰¾ä¸åˆ°è¦æ§åˆ¶çš„ Pod å¯¹è±¡, apiserver ä¹Ÿä¼šå‘Šè¯‰ä½  YAML æ ¼å¼æ ¡éªŒé”™è¯¯æ— æ³•åˆ›å»º. 
    matchLabels:
      app: ngx-dep
  strategy: {}
  template:
    # ä»¥ä¸‹å®šä¹‰äº†ä¸€ä¸ª pod
    metadata:
      creationTimestamp: null
      # labels ä¸­çš„æ ‡ç­¾å¿…é¡»è¦å’Œ matchLabels ä¸­å®šä¹‰çš„å®Œå…¨ç›¸åŒ
      labels:
        app: ngx-dep
    spec:
      containers:
      - image: nginx:alpine
        name: nginx
        resources: {}
status: {}

```

replicas å­—æ®µ

å°±æ˜¯ "å‰¯æœ¬æ•°é‡"çš„æ„æ€, ä¹Ÿå°±æ˜¯è¯´, æŒ‡å®šè¦åœ¨ Kubernetes é›†ç¾¤é‡Œè¿è¡Œå¤šå°‘ä¸ª Pod å®ä¾‹. 

æœ‰äº†è¿™ä¸ªå­—æ®µ, å°±ç›¸å½“äºä¸º Kubernetes æ˜ç¡®äº†åº”ç”¨éƒ¨ç½²çš„ "æœŸæœ›çŠ¶æ€", Deployment å¯¹è±¡å°±å¯ä»¥æ‰®æ¼”è¿ç»´ç›‘æ§äººå‘˜çš„è§’è‰², è‡ªåŠ¨åœ°åœ¨é›†ç¾¤é‡Œè°ƒæ•´ Pod çš„æ•°é‡. 

æ¯”å¦‚, Deployment å¯¹è±¡åˆšåˆ›å»ºå‡ºæ¥çš„æ—¶å€™, Pod æ•°é‡è‚¯å®šæ˜¯ 0, é‚£ä¹ˆå®ƒå°±ä¼šæ ¹æ® YAML æ–‡ä»¶é‡Œçš„ Pod æ¨¡æ¿, é€ä¸ªåˆ›å»ºå‡ºè¦æ±‚æ•°é‡çš„ Pod. 

æ¥ä¸‹æ¥ Kubernetes è¿˜ä¼šæŒç»­åœ°ç›‘æ§ Pod çš„è¿è¡ŒçŠ¶æ€, ä¸‡ä¸€æœ‰ Pod å‘ç”Ÿæ„å¤–æ¶ˆå¤±äº†, æ•°é‡ä¸æ»¡è¶³ "æœŸæœ›çŠ¶æ€", å®ƒå°±ä¼šé€šè¿‡ apiserver, scheduler ç­‰æ ¸å¿ƒç»„ä»¶å»é€‰æ‹©æ–°çš„èŠ‚ç‚¹, åˆ›å»ºå‡ºæ–°çš„ Pod, ç›´è‡³æ•°é‡ä¸ "æœŸæœ›çŠ¶æ€"ä¸€è‡´. 

selectorå­—æ®µ

å®ƒçš„ä½œç”¨æ˜¯ "ç­›é€‰"å‡ºè¦è¢« Deployment ç®¡ç†çš„ Pod å¯¹è±¡, ä¸‹å±å­—æ®µ "matchLabels"å®šä¹‰äº† Pod å¯¹è±¡åº”è¯¥æºå¸¦çš„ label, å®ƒå¿…é¡»å’Œ "template"é‡Œ Pod å®šä¹‰çš„ "labels"å®Œå…¨ç›¸åŒ, å¦åˆ™ Deployment å°±ä¼šæ‰¾ä¸åˆ°è¦æ§åˆ¶çš„ Pod å¯¹è±¡, apiserver ä¹Ÿä¼šå‘Šè¯‰ä½  YAML æ ¼å¼æ ¡éªŒé”™è¯¯æ— æ³•åˆ›å»º. 

è¿™ä¸ª selector å­—æ®µçš„ç”¨æ³•åˆçœ‹èµ·æ¥å¥½åƒæ˜¯æœ‰ç‚¹å¤šä½™, ä¸ºäº†ä¿è¯ Deployment æˆåŠŸåˆ›å»º, æˆ‘ä»¬å¿…é¡»åœ¨ YAML é‡ŒæŠŠ label é‡å¤å†™ä¸¤æ¬¡: ä¸€æ¬¡æ˜¯åœ¨ "selector.matchLabels", å¦ä¸€æ¬¡æ˜¯åœ¨ "template.matadata". åƒåœ¨è¿™é‡Œ, ä½ å°±è¦åœ¨è¿™ä¸¤ä¸ªåœ°æ–¹è¿ç»­å†™ app: ngx-dep : 

ä½ ä¹Ÿè®¸ä¼šäº§ç”Ÿç–‘é—®: ä¸ºä»€ä¹ˆè¦è¿™ä¹ˆéº»çƒ¦ï¼Ÿä¸ºä»€ä¹ˆä¸èƒ½åƒ Job å¯¹è±¡ä¸€æ ·, ç›´æ¥ç”¨ "template"é‡Œå®šä¹‰å¥½çš„ Pod å°±è¡Œäº†å‘¢ï¼Ÿ

è¿™æ˜¯å› ä¸ºåœ¨çº¿ä¸šåŠ¡å’Œç¦»çº¿ä¸šåŠ¡çš„åº”ç”¨åœºæ™¯å·®å¼‚å¾ˆå¤§. ç¦»çº¿ä¸šåŠ¡ä¸­çš„ Pod åŸºæœ¬ä¸Šæ˜¯ä¸€æ¬¡æ€§çš„, åªä¸è¿™ä¸ªä¸šåŠ¡æœ‰å…³, ç´§ç´§åœ°ç»‘å®šåœ¨ Job å¯¹è±¡é‡Œ, ä¸€èˆ¬ä¸ä¼šè¢«å…¶ä»–å¯¹è±¡æ‰€ä½¿ç”¨. 

è€Œåœ¨çº¿ä¸šåŠ¡å°±è¦å¤æ‚å¾—å¤šäº†, å› ä¸º Pod æ°¸è¿œåœ¨çº¿, é™¤äº†è¦åœ¨ Deployment é‡Œéƒ¨ç½²è¿è¡Œ, è¿˜å¯èƒ½ä¼šè¢«å…¶ä»–çš„ API å¯¹è±¡å¼•ç”¨æ¥ç®¡ç†, æ¯”å¦‚è´Ÿè´£è´Ÿè½½å‡è¡¡çš„ Service å¯¹è±¡. 

æ‰€ä»¥ Deployment å’Œ Pod å®é™…ä¸Šæ˜¯ä¸€ç§æ¾æ•£çš„ç»„åˆå…³ç³», Deployment å®é™…ä¸Šå¹¶ä¸ "æŒæœ‰"Pod å¯¹è±¡, å®ƒåªæ˜¯å¸®åŠ© Pod å¯¹è±¡èƒ½å¤Ÿæœ‰è¶³å¤Ÿçš„å‰¯æœ¬æ•°é‡è¿è¡Œ, ä»…æ­¤è€Œå·². å¦‚æœåƒ Job é‚£æ ·, æŠŠ Pod åœ¨æ¨¡æ¿é‡Œ "å†™æ­»", é‚£ä¹ˆå…¶ä»–çš„å¯¹è±¡å†æƒ³è¦å»ç®¡ç†è¿™äº› Pod å°±æ— èƒ½ä¸ºåŠ›äº†. 

å¥½æ˜ç™½äº†è¿™ä¸€ç‚¹, é‚£æˆ‘ä»¬è¯¥ç”¨ä»€ä¹ˆæ–¹å¼æ¥æè¿° Deployment å’Œ Pod çš„ç»„åˆå…³ç³»å‘¢ï¼Ÿ

Kubernetes é‡‡ç”¨çš„æ˜¯è¿™ç§ "è´´æ ‡ç­¾"çš„æ–¹å¼, é€šè¿‡åœ¨ API å¯¹è±¡çš„ "metadata"å…ƒä¿¡æ¯é‡ŒåŠ å„ç§æ ‡ç­¾ï¼ˆlabels), æˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ç±»ä¼¼å…³ç³»æ•°æ®åº“é‡ŒæŸ¥è¯¢è¯­å¥çš„æ–¹å¼, ç­›é€‰å‡ºå…·æœ‰ç‰¹å®šæ ‡è¯†çš„é‚£äº›å¯¹è±¡. é€šè¿‡æ ‡ç­¾è¿™ç§è®¾è®¡, Kubernetes å°±è§£é™¤äº† Deployment å’Œæ¨¡æ¿é‡Œ Pod çš„å¼ºç»‘å®š, æŠŠç»„åˆå…³ç³»å˜æˆäº† "å¼±å¼•ç”¨". 



```yaml
# deploy.yml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: ngx-dep
  labels:
    app: ngx-dep

spec:
  # replicas  "å‰¯æœ¬æ•°é‡"çš„æ„æ€, æŒ‡å®šè¦åœ¨ Kubernetes é›†ç¾¤é‡Œè¿è¡Œå¤šå°‘ä¸ª Pod å®ä¾‹. 
  replicas: 2
  # selector ç­›é€‰"å‡ºè¦è¢« Deployment ç®¡ç†çš„ Pod å¯¹è±¡
  selector:
    # matchLabels å®šä¹‰äº† Pod å¯¹è±¡åº”è¯¥æºå¸¦çš„ label, å®ƒå¿…é¡»å’Œ "template"é‡Œ Pod å®šä¹‰çš„ "labels"å®Œå…¨ç›¸åŒ, å¦åˆ™ Deployment å°±ä¼šæ‰¾ä¸åˆ°è¦æ§åˆ¶çš„ Pod å¯¹è±¡
    matchLabels:
      app: ngx-dep
  template:
    # ä»¥ä¸‹å†…å®¹å®šä¹‰äº†ä¸€ä¸ª pod
    metadata:
      # labels ä¸­çš„æ ‡ç­¾å¿…é¡»è¦å’Œ matchLabels ä¸­å®šä¹‰çš„å®Œå…¨ç›¸åŒ
      labels:
        app: ngx-dep
    spec:
      containers:
      - image: nginx:alpine
        name: nginx

```

#### æ“ä½œ Deployment

```shell
# åˆ›å»º deployment å¯¹è±¡

kubectl apply -f deploy.yml

# æŸ¥çœ‹ deployment çš„çŠ¶æ€

kubectl get deploy
kubectl get deployment
kubectl get deployments

$ kubectl get deploy
NAME      READY   UP-TO-DATE   AVAILABLE   AGE
ngx-dep   2/2     2            2           72s
$ kubectl get deployment
NAME      READY   UP-TO-DATE   AVAILABLE   AGE
ngx-dep   2/2     2            2           76s
$ kubectl get deployments
NAME      READY   UP-TO-DATE   AVAILABLE   AGE
ngx-dep   2/2     2            2           81s

```

- READY è¡¨ç¤ºè¿è¡Œçš„ Pod æ•°é‡, å‰é¢çš„æ•°å­—æ˜¯å½“å‰æ•°é‡, åé¢çš„æ•°å­—æ˜¯æœŸæœ›æ•°é‡, æ‰€ä»¥ "2/2"çš„æ„æ€å°±æ˜¯è¦æ±‚æœ‰ä¸¤ä¸ª Pod è¿è¡Œ, ç°åœ¨å·²ç»å¯åŠ¨äº†ä¸¤ä¸ª Pod. 
- UP-TO-DATE æŒ‡çš„æ˜¯å½“å‰å·²ç»æ›´æ–°åˆ°æœ€æ–°çŠ¶æ€çš„ Pod æ•°é‡. å› ä¸ºå¦‚æœè¦éƒ¨ç½²çš„ Pod æ•°é‡å¾ˆå¤šæˆ–è€… Pod å¯åŠ¨æ¯”è¾ƒæ…¢, Deployment å®Œå…¨ç”Ÿæ•ˆéœ€è¦ä¸€ä¸ªè¿‡ç¨‹, UP-TO-DATE å°±è¡¨ç¤ºç°åœ¨æœ‰å¤šå°‘ä¸ª Pod å·²ç»å®Œæˆäº†éƒ¨ç½², è¾¾æˆäº†æ¨¡æ¿é‡Œçš„ "æœŸæœ›çŠ¶æ€". 
- AVAILABLE è¦æ¯” READY, UP-TO-DATE æ›´è¿›ä¸€æ­¥, ä¸ä»…è¦æ±‚å·²ç»è¿è¡Œ, è¿˜å¿…é¡»æ˜¯å¥åº·çŠ¶æ€, èƒ½å¤Ÿæ­£å¸¸å¯¹å¤–æä¾›æœåŠ¡, å®ƒæ‰æ˜¯æˆ‘ä»¬æœ€å…³å¿ƒçš„ Deployment æŒ‡æ ‡. 
- AGE è¡¨ç¤º Deployment ä»åˆ›å»ºåˆ°ç°åœ¨æ‰€ç»è¿‡çš„æ—¶é—´, ä¹Ÿå°±æ˜¯è¿è¡Œçš„æ—¶é—´. 


- æŸ¥çœ‹ pod

```shell

# è¯´æ˜: è¢« Deployment ç®¡ç†çš„ Pod è‡ªåŠ¨å¸¦ä¸Šäº†åå­—, å‘½åçš„è§„åˆ™æ˜¯ Deployment çš„åå­—åŠ ä¸Šä¸¤ä¸²éšæœºæ•°ï¼ˆå…¶å®æ˜¯ Pod æ¨¡æ¿çš„ Hash å€¼). 
kubectl get pods
# NAME                      READY   STATUS    RESTARTS   AGE
# ngx-dep-bfbb5f64b-bf6nz   1/1     Running   0          3m7s
# ngx-dep-bfbb5f64b-k99dj   1/1     Running   0          3m7s

# kubectl delete åˆ é™¤ä¸€ä¸ª Pod, æ¨¡æ‹Ÿä¸€ä¸‹ Pod å‘ç”Ÿæ•…éšœçš„æƒ…æ™¯: 
kubectl delete pod ngx-dep-bfbb5f64b-bf6nz
# pod "ngx-dep-bfbb5f64b-bf6nz" deleted

# è¢«åˆ é™¤çš„ Pod ç¡®å®æ˜¯æ¶ˆå¤±äº†, ä½† Kubernetes åœ¨ Deployment çš„ç®¡ç†ä¹‹ä¸‹, å¾ˆå¿«åˆåˆ›å»ºå‡ºäº†ä¸€ä¸ªæ–°çš„ Pod, ä¿è¯äº†åº”ç”¨å®ä¾‹çš„æ•°é‡å§‹ç»ˆæ˜¯æˆ‘ä»¬åœ¨ YAML é‡Œå®šä¹‰çš„æ•°é‡. 
kubectl get pods -w
# NAME                      READY   STATUS    RESTARTS   AGE
# ngx-dep-bfbb5f64b-k99dj   1/1     Running   0          5m1s
# ngx-dep-bfbb5f64b-v6zrr   1/1     Running   0          4s

# kubectl scale å¯¹ deployment å®ç° "æ‰©å®¹"å’Œ "ç¼©å®¹"
# æ³¨æ„, kubectl scale æ˜¯å‘½ä»¤å¼æ“ä½œ, æ‰©å®¹å’Œç¼©å®¹åªæ˜¯ä¸´æ—¶çš„æªæ–½, å¦‚æœåº”ç”¨éœ€è¦é•¿æ—¶é—´ä¿æŒä¸€ä¸ªç¡®å®šçš„ Pod æ•°é‡, æœ€å¥½è¿˜æ˜¯ç¼–è¾‘ Deployment çš„ YAML æ–‡ä»¶, æ”¹åŠ¨ "replicas", å†ä»¥å£°æ˜å¼çš„ kubectl apply ä¿®æ”¹å¯¹è±¡çš„çŠ¶æ€. 
kubectl scale --replicas=5 deploy ngx-dep

```

labels å­—æ®µçš„ä½¿ç”¨æ–¹æ³•

ä¹‹å‰æˆ‘ä»¬é€šè¿‡ labels ä¸ºå¯¹è±¡ "è´´"äº†å„ç§ "æ ‡ç­¾", åœ¨ä½¿ç”¨ kubectl get å‘½ä»¤çš„æ—¶å€™, åŠ ä¸Šå‚æ•° -l, ä½¿ç”¨ ==, !=, in, notin çš„è¡¨è¾¾å¼, å°±èƒ½å¤Ÿå¾ˆå®¹æ˜“åœ°ç”¨ "æ ‡ç­¾"ç­›é€‰, è¿‡æ»¤å‡ºæ‰€è¦æŸ¥æ‰¾çš„å¯¹è±¡ï¼ˆæœ‰ç‚¹ç±»ä¼¼ç¤¾äº¤åª’ä½“çš„ #tag åŠŸèƒ½), æ•ˆæœå’Œ Deployment é‡Œçš„ selector å­—æ®µæ˜¯ä¸€æ ·çš„. 

```shell

# æ‰¾å‡º "app"æ ‡ç­¾æ˜¯ nginx çš„æ‰€æœ‰ Pod
kubectl get pod -l app=nginx

# æ‰¾å‡º "app"æ ‡ç­¾æ˜¯ ngx, nginx, ngx-dep çš„æ‰€æœ‰ Pod
kubectl get pod -l 'app in (ngx, nginx, ngx-dep)'


kubectl get pod -l app=nginx
# No resources found in default namespace.

kubectl get pod -l 'app in (ngx, nginx, ngx-dep)'
# NAME                      READY   STATUS    RESTARTS   AGE
# ngx-dep-bfbb5f64b-k99dj   1/1     Running   0          14m
# ngx-dep-bfbb5f64b-q9n87   1/1     Running   0          6m16s
# ngx-dep-bfbb5f64b-v6zrr   1/1     Running   0          9m16s

```

### Daemonset: å¿ å®å¯é çš„çœ‹é—¨ç‹—

ä½œç”¨: 
DaemonSet, å®ƒä¼šåœ¨ Kubernetes é›†ç¾¤çš„æ¯ä¸ªèŠ‚ç‚¹ä¸Šéƒ½è¿è¡Œä¸€ä¸ª Pod, å°±å¥½åƒæ˜¯ Linux ç³»ç»Ÿé‡Œçš„ "å®ˆæŠ¤è¿›ç¨‹"ï¼ˆDaemon). å®ƒåœ¨å½¢å¼ä¸Šå’Œ Deployment ç±»ä¼¼, éƒ½æ˜¯ç®¡ç†æ§åˆ¶ Pod, ä½†ç®¡ç†è°ƒåº¦ç­–ç•¥å´ä¸åŒ. DaemonSet çš„ç›®æ ‡æ˜¯åœ¨é›†ç¾¤çš„æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œä¸”ä»…è¿è¡Œä¸€ä¸ª Pod, å°±å¥½åƒæ˜¯ä¸ºèŠ‚ç‚¹é…ä¸Šä¸€åª "çœ‹é—¨ç‹—", å¿ å®åœ° "å®ˆæŠ¤"ç€èŠ‚ç‚¹, è¿™å°±æ˜¯ DaemonSet åå­—çš„ç”±æ¥. 

ä¸ºä»€ä¹ˆå¼•å…¥ Daemonset
æœ‰ä¸€äº›ä¸šåŠ¡æ¯”è¾ƒç‰¹æ®Š, å®ƒä»¬ä¸æ˜¯å®Œå…¨ç‹¬ç«‹äºç³»ç»Ÿè¿è¡Œçš„, è€Œæ˜¯ä¸ä¸»æœºå­˜åœ¨ "ç»‘å®š"å…³ç³», å¿…é¡»è¦ä¾é™„äºèŠ‚ç‚¹æ‰èƒ½äº§ç”Ÿä»·å€¼, æ¯”å¦‚è¯´: 
ç½‘ç»œåº”ç”¨ï¼ˆå¦‚ kube-proxy), å¿…é¡»æ¯ä¸ªèŠ‚ç‚¹éƒ½è¿è¡Œä¸€ä¸ª Pod, å¦åˆ™èŠ‚ç‚¹å°±æ— æ³•åŠ å…¥ Kubernetes ç½‘ç»œ. 
ç›‘æ§åº”ç”¨ï¼ˆå¦‚ Prometheus), å¿…é¡»æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰ä¸€ä¸ª Pod ç”¨æ¥ç›‘æ§èŠ‚ç‚¹çš„çŠ¶æ€, å®æ—¶ä¸ŠæŠ¥ä¿¡æ¯. 
æ—¥å¿—åº”ç”¨ï¼ˆå¦‚ Fluentd), å¿…é¡»åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œä¸€ä¸ª Pod, æ‰èƒ½å¤Ÿæœé›†å®¹å™¨è¿è¡Œæ—¶äº§ç”Ÿçš„æ—¥å¿—æ•°æ®. 
å®‰å…¨åº”ç”¨, åŒæ ·çš„, æ¯ä¸ªèŠ‚ç‚¹éƒ½è¦æœ‰ä¸€ä¸ª Pod æ¥æ‰§è¡Œå®‰å…¨å®¡è®¡, å…¥ä¾µæ£€æŸ¥, æ¼æ´æ‰«æç­‰å·¥ä½œ. 

daemonset ç¤ºä¾‹
https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/

```yaml
# https://raw.githubusercontent.com/kubernetes/website/main/content/zh-cn/examples/controllers/daemonset.yaml

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-elasticsearch
  namespace: kube-system
  labels:
    k8s-app: fluentd-logging

spec:
  selector:
    matchLabels:
      name: fluentd-elasticsearch
  template:
    metadata:
      labels:
        name: fluentd-elasticsearch
    spec:
      tolerations:
      # è¿™äº›å®¹å¿åº¦è®¾ç½®æ˜¯ä¸ºäº†è®©è¯¥å®ˆæŠ¤è¿›ç¨‹é›†åœ¨æ§åˆ¶å¹³é¢èŠ‚ç‚¹ä¸Šè¿è¡Œ
      # å¦‚æœä½ ä¸å¸Œæœ›è‡ªå·±çš„æ§åˆ¶å¹³é¢èŠ‚ç‚¹è¿è¡Œ Pod, å¯ä»¥åˆ é™¤å®ƒä»¬
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: NoSchedule
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      containers:
      - name: fluentd-elasticsearch
        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlog
        hostPath:
          path: /var/log

```

ä¹‹å‰å®‰è£…çš„ç½‘ç»œæ’ä»¶ Flannel å°±æ˜¯ä¸€ä¸ª DaemonSet, å®ƒä½äºå‘½åç©ºé—´ kube-system ä¸­, å¯ä»¥ä½¿ç”¨ `kubectl get ds -n kube-system` å‘½ä»¤çœ‹åˆ°

```shell

kubectl get ds -n kube-system
# NAME         DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
# kube-proxy   4         4         4       4            4           kubernetes.io/os=linux   46h

```

```shell

# åŸºäº YAML æ–‡ä»¶åˆ›å»º DaemonSet: 
kubectl apply -f https://k8s.io/examples/controllers/daemonset.yaml

```

```yaml
# daemonset-redis.yml

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: redis-ds
  labels:
    app: redis-ds

spec:
  selector:
    matchLabels:
      name: redis-ds

  template:
    metadata:
      labels:
        name: redis-ds
    spec:
      containers:
      - image: redis:6-alpine
        name: redis
        ports:
        - containerPort: 6379

```

```shell
kubectl get pods
# NAME                      READY   STATUS    RESTARTS   AGE
# ngx-dep-bfbb5f64b-k99dj   1/1     Running   0          32m
# ngx-dep-bfbb5f64b-q9n87   1/1     Running   0          24m
# ngx-dep-bfbb5f64b-v6zrr   1/1     Running   0          27m
# redis-ds-fldq9            1/1     Running   0          6m38s
# redis-ds-fv5qd            1/1     Running   0          6m38s
# redis-ds-mpsq2            1/1     Running   0          6m38s

```

æ²¡æœ‰æŒ‡å®š DaemonSet é‡Œè¦è¿è¡Œçš„ Pod æ•°é‡, å®ƒè‡ªå·±å°±ä¼šå»æŸ¥æ‰¾é›†ç¾¤é‡Œçš„èŠ‚ç‚¹, åœ¨èŠ‚ç‚¹é‡Œåˆ›å»º Pod. Master é»˜è®¤æ˜¯ä¸è·‘åº”ç”¨çš„, æ‰€ä»¥ DaemonSet å°±åœ¨æ¯ä¸€ä¸ª  "worker"èŠ‚ç‚¹åˆ›å»ºäº†ä¸€ä¸ª Pod


æŒ‰ç…§ DaemonSet çš„æœ¬æ„, åº”è¯¥åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šéƒ½è¿è¡Œä¸€ä¸ª Pod å®ä¾‹æ‰å¯¹, ä½† Master èŠ‚ç‚¹å´è¢«æ’é™¤åœ¨å¤–äº†, è¿™å°±ä¸ç¬¦åˆæˆ‘ä»¬å½“åˆçš„è®¾æƒ³äº†. 

å¦‚æœè¦åœ¨ Master èŠ‚ç‚¹è¿è¡Œåº”ç”¨, åˆä¸ "Master é»˜è®¤æ˜¯ä¸è·‘åº”ç”¨çš„" è¿™ä¸ªé»˜è®¤è®¾å®šç›¸è¿èƒŒäº†.
ä¸ºäº†åº”å¯¹ Pod åœ¨æŸäº›èŠ‚ç‚¹çš„ "è°ƒåº¦"å’Œ "é©±é€"é—®é¢˜, å®ƒå®šä¹‰äº†ä¸¤ä¸ªæ–°çš„æ¦‚å¿µ: æ±¡ç‚¹ï¼ˆtaint)å’Œå®¹å¿åº¦ï¼ˆtoleration). 

#### æ±¡ç‚¹ï¼ˆtaint)å’Œå®¹å¿åº¦ï¼ˆtoleration)

https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/taint-and-toleration/

 "æ±¡ç‚¹"æ˜¯ Kubernetes èŠ‚ç‚¹çš„ä¸€ä¸ªå±æ€§, å®ƒçš„ä½œç”¨ä¹Ÿæ˜¯ç»™èŠ‚ç‚¹ "è´´æ ‡ç­¾", ä½†ä¸ºäº†ä¸å’Œå·²æœ‰çš„ labels å­—æ®µæ··æ·†, å°±æ”¹æˆäº† taint. 

Pod çš„ "å®¹å¿åº¦", é¡¾åæ€ä¹‰, å°±æ˜¯ Pod èƒ½å¦ "å®¹å¿"æ±¡ç‚¹. 

é›†ç¾¤é‡Œçš„èŠ‚ç‚¹å„å¼å„æ ·, æœ‰çš„èŠ‚ç‚¹ "çº¯æ´æ— ç‘•", æ²¡æœ‰ "æ±¡ç‚¹"; è€Œæœ‰çš„èŠ‚ç‚¹å› ä¸ºæŸç§åŸå› ç²˜ä¸Šäº† "æ³¥å·´", ä¹Ÿå°±æœ‰äº† "æ±¡ç‚¹". 

Pod ä¹Ÿè„¾æ°”å„å¼‚, æœ‰çš„ "æ´ç™–"å¾ˆä¸¥é‡, ä¸èƒ½å®¹å¿ "æ±¡ç‚¹", åªèƒ½æŒ‘é€‰ "å¹²å‡€"çš„èŠ‚ç‚¹; è€Œæœ‰çš„ Pod åˆ™æ¯”è¾ƒ "å¤§å¤§å’§å’§", è¦æ±‚ä¸é‚£ä¹ˆé«˜, å¯ä»¥é€‚å½“åœ°å®¹å¿ä¸€äº›å° "æ±¡ç‚¹". 

è¿™ä¹ˆçœ‹æ¥, "æ±¡ç‚¹"å’Œ "å®¹å¿åº¦"å€’æ˜¯æœ‰ç‚¹åƒæ˜¯ä¸€ä¸ª "ç›¸äº²"çš„è¿‡ç¨‹. Pod å°±æ˜¯ä¸€ä¸ªæŒ‘å‰”çš„ "ç”²æ–¹", è€Œ "ä¹™æ–¹"å°±æ˜¯é›†ç¾¤é‡Œçš„å„ä¸ªèŠ‚ç‚¹, Pod ä¼šæ ¹æ®è‡ªå·±å¯¹ "æ±¡ç‚¹"çš„ "å®¹å¿ç¨‹åº¦"æ¥é€‰æ‹©åˆé€‚çš„ç›®æ ‡, æ¯”å¦‚è¦æ±‚ "ä¸æŠ½çƒŸä¸å–é…’", ä½†å¯ä»¥ "æ— è½¦æ— æˆ¿", æœ€ç»ˆå†³å®šåœ¨å“ªä¸ªèŠ‚ç‚¹ä¸Š "è½æˆ·". 

Kubernetes åœ¨åˆ›å»ºé›†ç¾¤çš„æ—¶å€™ä¼šè‡ªåŠ¨ç»™èŠ‚ç‚¹ Node åŠ ä¸Šä¸€äº› "æ±¡ç‚¹", æ–¹ä¾¿ Pod çš„è°ƒåº¦å’Œéƒ¨ç½². ä½ å¯ä»¥ç”¨ kubectl describe node æ¥æŸ¥çœ‹ Master å’Œ Worker çš„çŠ¶æ€: 


```shell

kubectl describe node server01
# Name:               server01
# Roles:              control-plane,master
# Labels:             beta.kubernetes.io/arch=amd64
#                     beta.kubernetes.io/os=linux
#                     kubernetes.io/arch=amd64
#                     kubernetes.io/hostname=server01
#                     kubernetes.io/os=linux
#                     node-role.kubernetes.io/control-plane=
#                     node-role.kubernetes.io/master=
#                     node.kubernetes.io/exclude-from-external-load-balancers=
# Annotations:        flannel.alpha.coreos.com/backend-data: {"VNI":1,"VtepMAC":"96:c0:b0:ab:cc:6e"}
#                     flannel.alpha.coreos.com/backend-type: vxlan
#                     flannel.alpha.coreos.com/kube-subnet-manager: true
#                     flannel.alpha.coreos.com/public-ip: 192.168.116.150
#                     kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock
#                     node.alpha.kubernetes.io/ttl: 0
#                     volumes.kubernetes.io/controller-managed-attach-detach: true
# CreationTimestamp:  Wed, 29 Mar 2023 12:33:42 +0800
# Taints:             node-role.kubernetes.io/master:NoSchedule
# Unschedulable:      false
# Lease:
#   HolderIdentity:  server01
#   AcquireTime:     <unset>
#   RenewTime:       Fri, 31 Mar 2023 10:29:57 +0800
# Conditions:
#   Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
#   ----                 ------  -----------------                 ------------------                ------                       -------
#   NetworkUnavailable   False   Wed, 29 Mar 2023 12:40:29 +0800   Wed, 29 Mar 2023 12:40:29 +0800   FlannelIsUp                  Flannel is running on this node
#   MemoryPressure       False   Fri, 31 Mar 2023 10:26:52 +0800   Wed, 29 Mar 2023 12:33:39 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available
#   DiskPressure         False   Fri, 31 Mar 2023 10:26:52 +0800   Wed, 29 Mar 2023 12:33:39 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure
#   PIDPressure          False   Fri, 31 Mar 2023 10:26:52 +0800   Wed, 29 Mar 2023 12:33:39 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available
#   Ready                True    Fri, 31 Mar 2023 10:26:52 +0800   Wed, 29 Mar 2023 12:40:36 +0800   KubeletReady                 kubelet is posting ready status. AppArmor enabled
# Addresses:
#   InternalIP:  192.168.116.150
#   Hostname:    server01
# Capacity:
#   cpu:                4
#   ephemeral-storage:  29751268Ki
#   hugepages-1Gi:      0
#   hugepages-2Mi:      0
#   memory:             3983176Ki
#   pods:               110
# Allocatable:
#   cpu:                4
#   ephemeral-storage:  27418768544
#   hugepages-1Gi:      0
#   hugepages-2Mi:      0
#   memory:             3880776Ki
#   pods:               110
# System Info:
#   Machine ID:                 12e42a5e05244a898f146aee13477b76
#   System UUID:                c8964d56-dc94-b450-084b-399b4129fdbe
#   Boot ID:                    ef23b04a-a8a0-4626-8476-f2006d9dccfc
#   Kernel Version:             5.15.0-69-generic
#   OS Image:                   Ubuntu 22.04.2 LTS
#   Operating System:           linux
#   Architecture:               amd64
#   Container Runtime Version:  docker://23.0.2
#   Kubelet Version:            v1.23.17
#   Kube-Proxy Version:         v1.23.17
# PodCIDR:                      10.10.0.0/24
# PodCIDRs:                     10.10.0.0/24
# Non-terminated Pods:          (8 in total)
#   Namespace                   Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
#   ---------                   ----                                ------------  ----------  ---------------  -------------  ---
#   kube-flannel                kube-flannel-ds-fztgz               100m (2%)     0 (0%)      50Mi (1%)        0 (0%)         45h
#   kube-system                 coredns-bd6b6df9f-smdg6             100m (2%)     0 (0%)      70Mi (1%)        170Mi (4%)     45h
#   kube-system                 coredns-bd6b6df9f-xrc9j             100m (2%)     0 (0%)      70Mi (1%)        170Mi (4%)     45h
#   kube-system                 etcd-server01                       100m (2%)     0 (0%)      100Mi (2%)       0 (0%)         45h
#   kube-system                 kube-apiserver-server01             250m (6%)     0 (0%)      0 (0%)           0 (0%)         45h
#   kube-system                 kube-controller-manager-server01    200m (5%)     0 (0%)      0 (0%)           0 (0%)         45h
#   kube-system                 kube-proxy-h6ldm                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         45h
#   kube-system                 kube-scheduler-server01             100m (2%)     0 (0%)      0 (0%)           0 (0%)         45h
# Allocated resources:
#   (Total limits may be over 100 percent, i.e., overcommitted.)
#   Resource           Requests    Limits
#   --------           --------    ------
#   cpu                950m (23%)  0 (0%)
#   memory             290Mi (7%)  340Mi (8%)
#   ephemeral-storage  0 (0%)      0 (0%)
#   hugepages-1Gi      0 (0%)      0 (0%)
#   hugepages-2Mi      0 (0%)      0 (0%)
# Events:              <none>


kubectl describe node worker01
# Name:               worker01
# Roles:              <none>
# Labels:             beta.kubernetes.io/arch=amd64
#                     beta.kubernetes.io/os=linux
#                     kubernetes.io/arch=amd64
#                     kubernetes.io/hostname=worker01
#                     kubernetes.io/os=linux
# Annotations:        flannel.alpha.coreos.com/backend-data: {"VNI":1,"VtepMAC":"ae:5f:f2:ff:1e:c7"}
#                     flannel.alpha.coreos.com/backend-type: vxlan
#                     flannel.alpha.coreos.com/kube-subnet-manager: true
#                     flannel.alpha.coreos.com/public-ip: 192.168.116.153
#                     kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock
#                     node.alpha.kubernetes.io/ttl: 0
#                     volumes.kubernetes.io/controller-managed-attach-detach: true
# CreationTimestamp:  Wed, 29 Mar 2023 13:36:36 +0800
# Taints:             <none>
# Unschedulable:      false
# Lease:
#   HolderIdentity:  worker01
#   AcquireTime:     <unset>
#   RenewTime:       Fri, 31 Mar 2023 10:30:10 +0800
# Conditions:
#   Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
#   ----                 ------  -----------------                 ------------------                ------                       -------
#   NetworkUnavailable   False   Wed, 29 Mar 2023 13:38:35 +0800   Wed, 29 Mar 2023 13:38:35 +0800   FlannelIsUp                  Flannel is running on this node
#   MemoryPressure       False   Fri, 31 Mar 2023 10:27:24 +0800   Wed, 29 Mar 2023 13:36:36 +0800   KubeletHasSufficientMemory   kubelet has sufficient memory available
#   DiskPressure         False   Fri, 31 Mar 2023 10:27:24 +0800   Wed, 29 Mar 2023 13:36:36 +0800   KubeletHasNoDiskPressure     kubelet has no disk pressure
#   PIDPressure          False   Fri, 31 Mar 2023 10:27:24 +0800   Wed, 29 Mar 2023 13:36:36 +0800   KubeletHasSufficientPID      kubelet has sufficient PID available
#   Ready                True    Fri, 31 Mar 2023 10:27:24 +0800   Wed, 29 Mar 2023 13:38:39 +0800   KubeletReady                 kubelet is posting ready status. AppArmor enabled
# Addresses:
#   InternalIP:  192.168.116.153
#   Hostname:    worker01
# Capacity:
#   cpu:                4
#   ephemeral-storage:  29751268Ki
#   hugepages-1Gi:      0
#   hugepages-2Mi:      0
#   memory:             3983176Ki
#   pods:               110
# Allocatable:
#   cpu:                4
#   ephemeral-storage:  27418768544
#   hugepages-1Gi:      0
#   hugepages-2Mi:      0
#   memory:             3880776Ki
#   pods:               110
# System Info:
#   Machine ID:                 12e42a5e05244a898f146aee13477b76
#   System UUID:                48eb4d56-c334-ad41-1217-287ba373062a
#   Boot ID:                    f2731a99-4294-4b3f-bbc4-8a22e8fbfd01
#   Kernel Version:             5.15.0-69-generic
#   OS Image:                   Ubuntu 22.04.2 LTS
#   Operating System:           linux
#   Architecture:               amd64
#   Container Runtime Version:  docker://23.0.2
#   Kubelet Version:            v1.23.17
#   Kube-Proxy Version:         v1.23.17
# PodCIDR:                      10.10.2.0/24
# PodCIDRs:                     10.10.2.0/24
# Non-terminated Pods:          (4 in total)
#   Namespace                   Name                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
#   ---------                   ----                       ------------  ----------  ---------------  -------------  ---
#   default                     ngx-dep-bfbb5f64b-v6zrr    0 (0%)        0 (0%)      0 (0%)           0 (0%)         36m
#   default                     redis-ds-fv5qd             0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m
#   kube-flannel                kube-flannel-ds-twsd9      100m (2%)     0 (0%)      50Mi (1%)        0 (0%)         44h
#   kube-system                 kube-proxy-7thgx           0 (0%)        0 (0%)      0 (0%)           0 (0%)         44h
# Allocated resources:
#   (Total limits may be over 100 percent, i.e., overcommitted.)
#   Resource           Requests   Limits
#   --------           --------   ------
#   cpu                100m (2%)  0 (0%)
#   memory             50Mi (1%)  0 (0%)
#   ephemeral-storage  0 (0%)     0 (0%)
#   hugepages-1Gi      0 (0%)     0 (0%)
#   hugepages-2Mi      0 (0%)     0 (0%)
# Events:              <none>

```

```shell

# Master èŠ‚ç‚¹é»˜è®¤æœ‰ä¸€ä¸ª taint, å®ƒçš„æ•ˆæœæ˜¯ NoSchedule, 
# ä¹Ÿå°±æ˜¯è¯´è¿™ä¸ªæ±¡ç‚¹ä¼šæ‹’ç» Pod è°ƒåº¦åˆ°æœ¬èŠ‚ç‚¹ä¸Šè¿è¡Œ, è€Œ Worker èŠ‚ç‚¹çš„ taint å­—æ®µåˆ™æ˜¯ç©ºçš„. 
# é€šå¸¸æ¥è¯´ Pod éƒ½ä¸èƒ½å®¹å¿ä»»ä½• "æ±¡ç‚¹", æ‰€ä»¥åŠ ä¸Šäº† taint å±æ€§çš„ Master èŠ‚ç‚¹ä¹Ÿå°±ä¼šæ— ç¼˜ Pod äº†. 
kubectl describe node server01
# Taints:             node-role.kubernetes.io/master:NoSchedule

kubectl describe node worker01
# Taints:             <none>

```

#### åœ¨ Master èŠ‚ç‚¹è¿è¡Œ Pod

DaemonSet åœ¨ Master èŠ‚ç‚¹ï¼ˆæˆ–è€…ä»»æ„å…¶ä»–èŠ‚ç‚¹)ä¸Šè¿è¡Œäº†, æ–¹æ³•æœ‰ä¸¤ç§. 

ç¬¬ä¸€ç§æ–¹æ³•
å»æ‰ Master èŠ‚ç‚¹ä¸Šçš„ taint, è®© Master å˜å¾—å’Œ Worker ä¸€æ · "çº¯æ´æ— ç‘•", DaemonSet è‡ªç„¶å°±ä¸éœ€è¦å†åŒºåˆ† Master/Worker. 

```shell
# kubectl taint, ç„¶åæŒ‡å®šèŠ‚ç‚¹å, æ±¡ç‚¹åå’Œæ±¡ç‚¹çš„æ•ˆæœ, å»æ‰æ±¡ç‚¹è¦é¢å¤–åŠ ä¸Šä¸€ä¸ª -
# å»æ‰ Master èŠ‚ç‚¹çš„ "NoSchedule"æ•ˆæœ
kubectl taint node server01 node-role.kubernetes.io/master:NoSchedule-

kubectl get pods
# NAME                      READY   STATUS              RESTARTS   AGE
# ngx-dep-bfbb5f64b-k99dj   1/1     Running             0          50m
# ngx-dep-bfbb5f64b-q9n87   1/1     Running             0          42m
# ngx-dep-bfbb5f64b-v6zrr   1/1     Running             0          45m
# redis-ds-bx7sv            0/1     ContainerCreating   0          10s
# redis-ds-fldq9            1/1     Running             0          25m
# redis-ds-fv5qd            1/1     Running             0          25m
# redis-ds-mpsq2            1/1     Running             0          25m


```

ä½†æ˜¯, è¿™ç§æ–¹æ³•ä¿®æ”¹çš„æ˜¯ Node çš„çŠ¶æ€, å½±å“é¢ä¼šæ¯”è¾ƒå¤§, å¯èƒ½ä¼šå¯¼è‡´å¾ˆå¤š Pod éƒ½è·‘åˆ°è¿™ä¸ª master èŠ‚ç‚¹ä¸Šè¿è¡Œ, æ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä¿ç•™ Node çš„ "æ±¡ç‚¹", ä¸ºéœ€è¦çš„ Pod æ·»åŠ  "å®¹å¿åº¦", åªè®©æŸäº› Pod è¿è¡Œåœ¨ä¸ªåˆ«èŠ‚ç‚¹ä¸Š, å®ç° "ç²¾ç»†åŒ–"è°ƒåº¦. 

ç¬¬äºŒç§æ–¹æ³•, ä¸º Pod æ·»åŠ å­—æ®µ tolerations, è®©å®ƒèƒ½å¤Ÿ "å®¹å¿"æŸäº› "æ±¡ç‚¹", å°±å¯ä»¥åœ¨ä»»æ„çš„èŠ‚ç‚¹ä¸Šè¿è¡Œäº†. 

tolerations æ˜¯ä¸€ä¸ªæ•°ç»„, é‡Œé¢å¯ä»¥åˆ—å‡ºå¤šä¸ªè¢« "å®¹å¿"çš„ "æ±¡ç‚¹", éœ€è¦å†™æ¸…æ¥š "æ±¡ç‚¹"çš„åå­—, æ•ˆæœ. æ¯”è¾ƒç‰¹åˆ«æ˜¯è¦ç”¨ operator å­—æ®µæŒ‡å®šå¦‚ä½•åŒ¹é… "æ±¡ç‚¹", ä¸€èˆ¬æˆ‘ä»¬éƒ½ä½¿ç”¨ Exists, ä¹Ÿå°±æ˜¯è¯´å­˜åœ¨è¿™ä¸ªåå­—å’Œæ•ˆæœçš„ "æ±¡ç‚¹". 

å¦‚æœæˆ‘ä»¬æƒ³è®© DaemonSet é‡Œçš„ Pod èƒ½å¤Ÿåœ¨ Master èŠ‚ç‚¹ä¸Šè¿è¡Œ, å°±è¦å†™å‡ºè¿™æ ·çš„ä¸€ä¸ª tolerations, å®¹å¿èŠ‚ç‚¹çš„ node-role.kubernetes.io/master:NoSchedule è¿™ä¸ªæ±¡ç‚¹: 

```yaml

tolerations:
- key: node-role.kubernetes.io/master
  effect: NoSchedule
  operator: Exists

```


```shell

# å…ˆç”¨ kubectl taint å‘½ä»¤æŠŠ Master çš„ "æ±¡ç‚¹"åŠ ä¸Š: 
kubectl taint node server01 node-role.kubernetes.io/master:NoSchedule

```

ç»™ DaemonSet åŠ ä¸Š  "å®¹å¿åº¦"

```yaml
# daemonset-redis.yml

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: redis-ds
  labels:
    app: redis-ds

spec:
  selector:
    matchLabels:
      name: redis-ds

  template:
    metadata:
      labels:
        name: redis-ds
    spec:
      containers:
      - image: redis:6-alpine
        name: redis
        ports:
        - containerPort: 6379

      tolerations:
      # this toleration is to have the daemonset runnable on master nodes
      # remove it if your masters can't run pods
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
        operator: Exists

```

æ³¨æ„, "å®¹å¿åº¦"å¹¶ä¸æ˜¯ DaemonSet ç‹¬æœ‰çš„æ¦‚å¿µ, è€Œæ˜¯ä»å±äº Pod, æ‰€ä»¥ç†è§£äº† "æ±¡ç‚¹"å’Œ "å®¹å¿åº¦"ä¹‹å, ä½ å¯ä»¥åœ¨ Job/CronJob, Deployment é‡Œä¸ºå®ƒä»¬ç®¡ç†çš„ Pod ä¹ŸåŠ ä¸Š tolerations, ä»è€Œèƒ½å¤Ÿæ›´çµæ´»åœ°è°ƒåº¦åº”ç”¨. 


#### é™æ€ Pod

DaemonSet æ˜¯åœ¨ Kubernetes é‡Œè¿è¡ŒèŠ‚ç‚¹ä¸“å± Pod æœ€å¸¸ç”¨çš„æ–¹å¼, ä½†å®ƒä¸æ˜¯å”¯ä¸€çš„æ–¹å¼, Kubernetes è¿˜æ”¯æŒå¦å¤–ä¸€ç§å« "é™æ€ Pod"çš„åº”ç”¨éƒ¨ç½²æ‰‹æ®µ. 

 "é™æ€ Pod"éå¸¸ç‰¹æ®Š, å®ƒä¸å— Kubernetes ç³»ç»Ÿçš„ç®¡æ§, ä¸ä¸ apiserver, scheduler å‘ç”Ÿå…³ç³», æ‰€ä»¥æ˜¯ "é™æ€"çš„. 

ä½†æ—¢ç„¶å®ƒæ˜¯ Pod, ä¹Ÿå¿…ç„¶ä¼š "è·‘"åœ¨å®¹å™¨è¿è¡Œæ—¶ä¸Š, ä¹Ÿä¼šæœ‰ YAML æ–‡ä»¶æ¥æè¿°å®ƒ, è€Œå”¯ä¸€èƒ½å¤Ÿç®¡ç†å®ƒçš„ Kubernetes ç»„ä»¶ä¹Ÿå°±åªæœ‰åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œçš„ kubelet äº†. 

 "é™æ€ Pod"çš„ YAML æ–‡ä»¶é»˜è®¤éƒ½å­˜æ”¾åœ¨èŠ‚ç‚¹çš„ /etc/kubernetes/manifests ç›®å½•ä¸‹, å®ƒæ˜¯ Kubernetes çš„ä¸“ç”¨ç›®å½•. 

ä½ å¯ä»¥çœ‹åˆ°, Kubernetes çš„ 4 ä¸ªæ ¸å¿ƒç»„ä»¶ apiserver, etcd, scheduler, controller-manager åŸæ¥éƒ½ä»¥é™æ€ Pod çš„å½¢å¼å­˜åœ¨çš„, è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå®ƒä»¬èƒ½å¤Ÿå…ˆäº Kubernetes é›†ç¾¤å¯åŠ¨çš„åŸå› . 

```shell

pwd
# /etc/kubernetes/manifests

ll
# total 24
# drwxr-xr-x 2 root root 4096 Mar 29 12:33 ./
# drwxr-xr-x 4 root root 4096 Mar 29 12:33 ../
# -rw------- 1 root root 2284 Mar 29 12:33 etcd.yaml
# -rw------- 1 root root 3875 Mar 29 12:33 kube-apiserver.yaml
# -rw------- 1 root root 3370 Mar 29 12:33 kube-controller-manager.yaml
# -rw------- 1 root root 1441 Mar 29 12:33 kube-scheduler.yaml

```

å¦‚æœä½ æœ‰ä¸€äº› DaemonSet æ— æ³•æ»¡è¶³çš„ç‰¹æ®Šçš„éœ€æ±‚, å¯ä»¥è€ƒè™‘ä½¿ç”¨é™æ€ Pod, ç¼–å†™ä¸€ä¸ª YAML æ–‡ä»¶æ”¾åˆ°è¿™ä¸ªç›®å½•é‡Œ, èŠ‚ç‚¹çš„ kubelet ä¼šå®šæœŸæ£€æŸ¥ç›®å½•é‡Œçš„æ–‡ä»¶, å‘ç°å˜åŒ–å°±ä¼šè°ƒç”¨å®¹å™¨è¿è¡Œæ—¶åˆ›å»ºæˆ–è€…åˆ é™¤é™æ€ Pod. 


### Service

https://kubernetes.io/zh-cn/docs/concepts/services-networking/service/

åœ¨ Kubernetes é›†ç¾¤é‡Œ Pod çš„ç”Ÿå‘½å‘¨æœŸæ˜¯æ¯”è¾ƒ "çŸ­æš‚"çš„, è™½ç„¶ Deployment å’Œ DaemonSet å¯ä»¥ç»´æŒ Pod æ€»ä½“æ•°é‡çš„ç¨³å®š, ä½†åœ¨è¿è¡Œè¿‡ç¨‹ä¸­, éš¾å…ä¼šæœ‰ Pod é”€æ¯åˆé‡å»º, è¿™å°±ä¼šå¯¼è‡´ Pod é›†åˆå¤„äºåŠ¨æ€çš„å˜åŒ–ä¹‹ä¸­. 

è¿™ç§ "åŠ¨æ€ç¨³å®š"å¯¹äºç°åœ¨æµè¡Œçš„å¾®æœåŠ¡æ¶æ„æ¥è¯´æ˜¯éå¸¸è‡´å‘½çš„, è¯•æƒ³ä¸€ä¸‹, åå° Pod çš„ IP åœ°å€è€æ˜¯å˜æ¥å˜å», å®¢æˆ·ç«¯è¯¥æ€ä¹ˆè®¿é—®å‘¢ï¼Ÿå¦‚æœä¸å¤„ç†å¥½è¿™ä¸ªé—®é¢˜, Deployment å’Œ DaemonSet æŠŠ Pod ç®¡ç†å¾—å†å®Œå–„ä¹Ÿæ˜¯æ²¡æœ‰ä»·å€¼çš„. 

å…¶å®, è¿™ä¸ªé—®é¢˜ä¹Ÿå¹¶ä¸æ˜¯ä»€ä¹ˆéš¾äº‹, ä¸šå†…æ—©å°±æœ‰è§£å†³æ–¹æ¡ˆæ¥é’ˆå¯¹è¿™æ · "ä¸ç¨³å®š"çš„åç«¯æœåŠ¡, é‚£å°±æ˜¯ "è´Ÿè½½å‡è¡¡", å…¸å‹çš„åº”ç”¨æœ‰ LVS, Nginx ç­‰ç­‰. å®ƒä»¬åœ¨å‰ç«¯ä¸åç«¯ä¹‹é—´åŠ å…¥äº†ä¸€ä¸ª "ä¸­é—´å±‚", å±è”½åç«¯çš„å˜åŒ–, ä¸ºå‰ç«¯æä¾›ä¸€ä¸ªç¨³å®šçš„æœåŠ¡. 

ä½† LVS, Nginx æ¯•ç«Ÿä¸æ˜¯äº‘åŸç”ŸæŠ€æœ¯, æ‰€ä»¥ Kubernetes å°±æŒ‰ç…§è¿™ä¸ªæ€è·¯, å®šä¹‰äº†æ–°çš„ API å¯¹è±¡: Service. 

Service çš„å·¥ä½œåŸç†å’Œ LVS, Nginx å·®ä¸å¤š, Kubernetes ä¼šç»™å®ƒåˆ†é…ä¸€ä¸ªé™æ€ IP åœ°å€, ç„¶åå®ƒå†å»è‡ªåŠ¨ç®¡ç†, ç»´æŠ¤åé¢åŠ¨æ€å˜åŒ–çš„ Pod é›†åˆ, å½“å®¢æˆ·ç«¯è®¿é—® Service, å®ƒå°±æ ¹æ®æŸç§ç­–ç•¥, æŠŠæµé‡è½¬å‘ç»™åé¢çš„æŸä¸ª Pod. 

Service ä½¿ç”¨äº† iptables æŠ€æœ¯, æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„ kube-proxy ç»„ä»¶è‡ªåŠ¨ç»´æŠ¤ iptables è§„åˆ™, å®¢æˆ·ä¸å†å…³å¿ƒ Pod çš„å…·ä½“åœ°å€, åªè¦è®¿é—® Service çš„å›ºå®š IP åœ°å€, Service å°±ä¼šæ ¹æ® iptables è§„åˆ™è½¬å‘è¯·æ±‚ç»™å®ƒç®¡ç†çš„å¤šä¸ª Pod, æ˜¯å…¸å‹çš„è´Ÿè½½å‡è¡¡æ¶æ„. 

```shell

export out="--dry-run=client -o yaml"
kubectl expose deploy ngx-dep --port=80 --target-port=80 $out


apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    app: ngx-dep
  name: ngx-dep

spec:
  # ports å°±å¾ˆå¥½ç†è§£äº†, é‡Œé¢çš„ä¸‰ä¸ªå­—æ®µåˆ†åˆ«è¡¨ç¤ºå¤–éƒ¨ç«¯å£, å†…éƒ¨ç«¯å£å’Œä½¿ç”¨çš„åè®®, åœ¨è¿™é‡Œå°±æ˜¯å†…å¤–éƒ¨éƒ½ä½¿ç”¨ 80 ç«¯å£, åè®®æ˜¯ TCP. 
  ports:
  # Pod å¤–éƒ¨ç«¯å£, å³å®¿ä¸»æœºç«¯å£
  - port: 80
    # Pod å†…éƒ¨ç«¯å£
    # ä¸ Deployment yaml ä¸­ spec.containers.ports ä¸­å®šä¹‰çš„ç«¯å£ä¿æŒä¸€è‡´
    targetPort: 80
    # ä½¿ç”¨çš„åè®®
    protocol: TCP
  # selector å’Œ Deployment/DaemonSet é‡Œçš„ä½œç”¨æ˜¯ä¸€æ ·çš„, ç”¨æ¥è¿‡æ»¤å‡ºè¦ä»£ç†çš„é‚£äº› Pod. å› ä¸ºæˆ‘ä»¬æŒ‡å®šè¦ä»£ç† Deployment, æ‰€ä»¥ Kubernetes å°±ä¸ºæˆ‘ä»¬è‡ªåŠ¨å¡«ä¸Šäº† ngx-dep çš„æ ‡ç­¾, ä¼šé€‰æ‹©è¿™ä¸ª Deployment å¯¹è±¡éƒ¨ç½²çš„æ‰€æœ‰ Pod. 
  # å¯¹åº” deployment yaml ä¸­ spec.template.metadata.labels ä¸­å®šä¹‰çš„ app
  selector:
    app: ngx-dep

status:
  loadBalancer: {}

```

åˆ›å»º ConfigMap, åœ¨å…¶ä¸­å®šä¹‰ä¸€ä¸ª Nginx çš„é…ç½®ç‰‡æ®µ, å®ƒä¼šè¾“å‡ºæœåŠ¡å™¨çš„åœ°å€ã€ä¸»æœºåã€è¯·æ±‚çš„ URI ç­‰åŸºæœ¬ä¿¡æ¯

```yaml
# ngx-conf-cm.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: ngx-conf

data:
  default.conf: |
    server {
      listen 80;
      location / {
        default_type text/plain;
        return 200
          'srv : $server_addr:$server_port\nhost: $hostname\nuri : $request_method $host $request_uri\ndate: $time_iso8601\n';
      }
    }

```



```shell
kubectl apply -f ngx-conf-cm.yml
```

ç„¶åæˆ‘ä»¬åœ¨ Deployment çš„ "template.volumes"é‡Œå®šä¹‰å­˜å‚¨å·, å†ç”¨ "volumeMounts"æŠŠé…ç½®æ–‡ä»¶åŠ è½½è¿› Nginx å®¹å™¨é‡Œ: 


```yaml
# deploy-ngx.yml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: ngx-dep

spec:
  replicas: 2
  selector:
    matchLabels:
      app: ngx-dep

  template:
    metadata:
      labels:
        app: ngx-dep
    spec:
      volumes:
      - name: ngx-conf-vol
        configMap:
          name: ngx-conf

      containers:
      - image: nginx:alpine
        name: nginx
        ports:
        - containerPort: 80

        volumeMounts:
        - mountPath: /etc/nginx/conf.d
          name: ngx-conf-vol
```

éƒ¨ç½² deployment

```shell

kubectl apply -f deploy-ngx.yml

```

åˆ›å»º service é…ç½®æ–‡ä»¶

```yaml
# service-ngx.yml
# chrono @ 2022-05

# kubectl expose deploy ngx-dep --port=80 $out
# kubectl apply -f svc.yml
# kubectl describe svc ngx-svc
# kubectl get pod -o wide
# kubectl exec -it ngx-dep-785b6bbbd7-7hmtv -- sh

apiVersion: v1
kind: Service
metadata:
  name: ngx-svc

spec:
  selector:
    app: ngx-dep

  ports:
  - port: 80
    protocol: TCP
    targetPort: 80

  #type: ClusterIP
  type: NodePort

```



```shell

# åˆ›å»º Service å¯¹è±¡
kubectl apply -f service-ngx.yml

# æŸ¥çœ‹ Service å¯¹è±¡
# Kubernetes ä¸º Service å¯¹è±¡è‡ªåŠ¨åˆ†é…äº†ä¸€ä¸ª IP åœ°å€ "10.96.240.115", 
# è¿™ä¸ªåœ°å€æ®µæ˜¯ç‹¬ç«‹äº Pod åœ°å€æ®µçš„ï¼ˆæ¯”å¦‚ç¬¬ 17 è®²é‡Œçš„ 10.10.xx.xx). 
# è€Œä¸” Service å¯¹è±¡çš„ IP åœ°å€è¿˜æœ‰ä¸€ä¸ªç‰¹ç‚¹, å®ƒæ˜¯ä¸€ä¸ª "è™šåœ°å€", ä¸å­˜åœ¨å®ä½“, åªèƒ½ç”¨æ¥è½¬å‘æµé‡. 
kubectl get service
# NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
# kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP   4d21h
# ngx-svc      ClusterIP   10.104.67.95    <none>        80/TCP    2d16h

# æŸ¥çœ‹ Service ä»£ç†äº†å“ªäº›åç«¯çš„ Pod
# å¯è§ Service å¯¹è±¡ç®¡ç†äº†ä¸¤ä¸ª endpoint, åˆ†åˆ«æ˜¯ "10.10.0.232:80"å’Œ "10.10.1.86:80", 
# åˆæ­¥åˆ¤æ–­ä¸ Serviceã€Deployment çš„å®šä¹‰ç›¸ç¬¦, é‚£ä¹ˆè¿™ä¸¤ä¸ª IP åœ°å€æ˜¯ä¸æ˜¯ Nginx Pod çš„å®é™…åœ°å€å‘¢
# ä½¿ç”¨å‘½ä»¤ `kubectl get pod -o wide` æŸ¥çœ‹ pod çš„è¯¦æƒ…
kubectl describe svc ngx-svc
# Name:                     ngx-svc
# Namespace:                default
# Labels:                   <none>
# Annotations:              <none>
# Selector:                 app=ngx-dep
# Type:                     NodePort
# IP Family Policy:         SingleStack
# IP Families:              IPv4
# IP:                       10.104.67.95
# IPs:                      10.104.67.95
# Port:                     <unset>  80/TCP
# TargetPort:               80/TCP
# NodePort:                 <unset>  32447/TCP
# Endpoints:                10.10.1.10:80,10.10.3.10:80
# Session Affinity:         None
# External Traffic Policy:  Cluster
# Events:                   <none>

# æŠŠ Pod çš„åœ°å€ä¸ Service çš„ä¿¡æ¯åšä¸ªå¯¹æ¯”, 
# æˆ‘ä»¬å°±èƒ½å¤ŸéªŒè¯ Service ç¡®å®ç”¨ä¸€ä¸ªé™æ€ IP åœ°å€ä»£ç†äº†ä¸¤ä¸ª Pod çš„åŠ¨æ€ IP åœ°å€. 
kubectl get pod -o wide
# NAME                       READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES
# ngx-dep-6796688696-rcdjl   1/1     Running   0          111s    10.10.1.10   worker03   <none>           <none>
# ngx-dep-6796688696-rvd42   1/1     Running   0          113s    10.10.3.10   worker02   <none>           <none>
# redis-ds-f67kg             1/1     Running   0          6h54m   10.10.2.9    worker01   <none>           <none>
# redis-ds-lzvxr             1/1     Running   0          6h54m   10.10.3.9    worker02   <none>           <none>
# redis-ds-xhr8n             1/1     Running   0          6h54m   10.10.1.9    worker03   <none>           <none>

# æµ‹è¯• Service çš„è´Ÿè½½å‡è¡¡æ•ˆæœ
# å› ä¸º Serviceã€ Pod çš„ IP åœ°å€éƒ½æ˜¯ Kubernetes é›†ç¾¤çš„å†…éƒ¨ç½‘æ®µ, 
# æ‰€ä»¥æˆ‘ä»¬éœ€è¦ç”¨ kubectl exec è¿›å…¥åˆ° Pod å†…éƒ¨ï¼ˆæˆ–è€… ssh ç™»å½•é›†ç¾¤èŠ‚ç‚¹), 
# å†ç”¨ curl ç­‰å·¥å…·æ¥è®¿é—® Service: 
# åœ¨ Pod é‡Œ, ç”¨ curl è®¿é—® Service çš„ IP åœ°å€, å°±ä¼šçœ‹åˆ°å®ƒæŠŠæ•°æ®è½¬å‘ç»™åç«¯çš„ Pod, 
# è¾“å‡ºä¿¡æ¯ä¼šæ˜¾ç¤ºå…·ä½“æ˜¯å“ªä¸ª Pod å“åº”äº†è¯·æ±‚, å°±è¡¨æ˜ Service ç¡®å®å®Œæˆäº†å¯¹ Pod çš„è´Ÿè½½å‡è¡¡ä»»åŠ¡. 
kubectl exec -it ngx-dep-6796688696-rcdjl -- sh

curl 10.104.67.95
# srv : 10.10.1.10:80
# host: ngx-dep-6796688696-rcdjl
# uri : GET 10.104.67.95 /
# date: 2023-03-31T10:08:29+00:00

curl 10.104.67.95
# srv : 10.10.1.10:80
# host: ngx-dep-6796688696-rcdjl
# uri : GET 10.104.67.95 /
# date: 2023-03-31T10:08:45+00:00

curl 10.104.67.95
# srv : 10.10.3.10:80
# host: ngx-dep-6796688696-rvd42
# uri : GET 10.104.67.95 /
# date: 2023-03-31T10:09:07+00:00

curl 10.104.67.95
# srv : 10.10.3.10:80
# host: ngx-dep-6796688696-rvd42
# uri : GET 10.104.67.95 /
# date: 2023-03-31T10:09:13+00:00

curl 10.104.67.95
# srv : 10.10.3.10:80
# host: ngx-dep-6796688696-rvd42
# uri : GET 10.104.67.95 /
# date: 2023-03-31T10:09:15+00:00

curl 10.104.67.95
# srv : 10.10.1.10:80
# host: ngx-dep-6796688696-rcdjl
# uri : GET 10.104.67.95 /
# date: 2023-03-31T10:09:17+00:00

exit

# æˆ‘ä»¬å†è¯•ç€åˆ é™¤ä¸€ä¸ª Pod, çœ‹çœ‹ Service æ˜¯å¦ä¼šæ›´æ–°åç«¯ Pod çš„ä¿¡æ¯, å®ç°è‡ªåŠ¨åŒ–çš„æœåŠ¡å‘ç°: 
# ç”±äº Pod è¢« Deployment å¯¹è±¡ç®¡ç†, åˆ é™¤åä¼šè‡ªåŠ¨é‡å»º, 
# è€Œ Service åˆä¼šé€šè¿‡ controller-manager å®æ—¶ç›‘æ§ Pod çš„å˜åŒ–æƒ…å†µ, 
# æ‰€ä»¥å°±ä¼šç«‹å³æ›´æ–°å®ƒä»£ç†çš„ IP åœ°å€. é€šè¿‡æˆªå›¾ä½ å°±å¯ä»¥çœ‹åˆ°æœ‰ä¸€ä¸ª IP åœ°å€ "10.10.1.86"æ¶ˆå¤±äº†, 
# æ¢æˆäº†æ–°çš„ "10.10.1.87", å®ƒå°±æ˜¯æ–°åˆ›å»ºçš„ Pod. 
kubectl delete pod ngx-dep-6796688696-rcdjl
# pod "ngx-dep-6796688696-rcdjl" deleted

kubectl get pod -o wide
# NAME                       READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES
# ngx-dep-6796688696-klnmr   1/1     Running   0          26s     10.10.2.10   worker01   <none>           <none>
# ngx-dep-6796688696-rvd42   1/1     Running   0          5m3s    10.10.3.10   worker02   <none>           <none>
# redis-ds-f67kg             1/1     Running   0          6h57m   10.10.2.9    worker01   <none>           <none>
# redis-ds-lzvxr             1/1     Running   0          6h57m   10.10.3.9    worker02   <none>           <none>
# redis-ds-xhr8n             1/1     Running   0          6h57m   10.10.1.9    worker03   <none>           <none>


```

ä½ ä¹Ÿå¯ä»¥å†å°è¯•ä¸€ä¸‹ä½¿ç”¨ "ping"æ¥æµ‹è¯• Service çš„ IP åœ°å€: 
ä¼šå‘ç°æ ¹æœ¬ ping ä¸é€š, å› ä¸º Service çš„ IP åœ°å€æ˜¯ "è™š"çš„, åªç”¨äºè½¬å‘æµé‡, æ‰€ä»¥ ping æ— æ³•å¾—åˆ°å›åº”æ•°æ®åŒ…, ä¹Ÿå°±å¤±è´¥äº†. 

```shell

kubectl exec -it ngx-dep-6796688696-klnmr -- sh
curl 10.104.67.95
# srv : 10.10.3.10:80
# host: ngx-dep-6796688696-rvd42
# uri : GET 10.104.67.95 /
# date: 2023-03-31T10:45:51+00:00

ping 10.104.67.95
PING 10.104.67.95 (10.104.67.95): 56 data bytes
^C
--- 10.104.67.95 ping statistics ---
5 packets transmitted, 0 packets received, 100% packet loss

```

#### ä»¥åŸŸåçš„æ–¹å¼ä½¿ç”¨ Service

Service å¯¹è±¡çš„ IP åœ°å€æ˜¯é™æ€çš„, ä¿æŒç¨³å®š, è¿™åœ¨å¾®æœåŠ¡é‡Œç¡®å®å¾ˆé‡è¦, ä¸è¿‡æ•°å­—å½¢å¼çš„ IP åœ°å€ç”¨èµ·æ¥è¿˜æ˜¯ä¸å¤ªæ–¹ä¾¿. è¿™ä¸ªæ—¶å€™ Kubernetes çš„ DNS æ’ä»¶å°±æ´¾ä¸Šäº†ç”¨å¤„, å®ƒå¯ä»¥ä¸º Service åˆ›å»ºæ˜“å†™æ˜“è®°çš„åŸŸå, è®© Service æ›´å®¹æ˜“ä½¿ç”¨. 

- åå­—ç©ºé—´ï¼ˆnamespace)

namespace åœ¨é›†ç¾¤é‡Œå®ç°å¯¹ API å¯¹è±¡çš„éš”ç¦»å’Œåˆ†ç»„. 

kubectl get ns æ¥æŸ¥çœ‹å½“å‰é›†ç¾¤é‡Œéƒ½æœ‰å“ªäº›åå­—ç©ºé—´, ä¹Ÿå°±æ˜¯è¯´ API å¯¹è±¡æœ‰å“ªäº›åˆ†ç»„: 

```shell

kubectl get ns
# NAME              STATUS   AGE
# default           Active   4d21h
# kube-flannel      Active   4d21h
# kube-node-lease   Active   4d21h
# kube-public       Active   4d21h
# kube-system       Active   4d21h

```

Kubernetes æœ‰ä¸€ä¸ªé»˜è®¤çš„åå­—ç©ºé—´, å« "default", å¦‚æœä¸æ˜¾å¼æŒ‡å®š, API å¯¹è±¡éƒ½ä¼šåœ¨è¿™ä¸ª "default"åå­—ç©ºé—´é‡Œ. è€Œå…¶ä»–çš„åå­—ç©ºé—´éƒ½æœ‰å„è‡ªçš„ç”¨é€”, æ¯”å¦‚ "kube-system"å°±åŒ…å«äº† apiserverã€etcd ç­‰æ ¸å¿ƒç»„ä»¶çš„ Pod. 

å› ä¸º DNS æ˜¯ä¸€ç§å±‚æ¬¡ç»“æ„, ä¸ºäº†é¿å…å¤ªå¤šçš„åŸŸåå¯¼è‡´å†²çª, Kubernetes å°±æŠŠåå­—ç©ºé—´ä½œä¸ºåŸŸåçš„ä¸€éƒ¨åˆ†, å‡å°‘äº†é‡åçš„å¯èƒ½æ€§. 

Service å¯¹è±¡çš„åŸŸåå®Œå…¨å½¢å¼æ˜¯ "å¯¹è±¡. åå­—ç©ºé—´.svc.cluster.local", ä½†å¾ˆå¤šæ—¶å€™ä¹Ÿå¯ä»¥çœç•¥åé¢çš„éƒ¨åˆ†, ç›´æ¥å†™ "å¯¹è±¡. åå­—ç©ºé—´"ç”šè‡³ "å¯¹è±¡å"å°±è¶³å¤Ÿäº†, é»˜è®¤ä¼šä½¿ç”¨å¯¹è±¡æ‰€åœ¨çš„åå­—ç©ºé—´ï¼ˆæ¯”å¦‚è¿™é‡Œå°±æ˜¯ default). 

è¯•éªŒä¸€ä¸‹ DNS åŸŸåçš„ç”¨æ³•, è¿˜æ˜¯å…ˆ kubectl exec è¿›å…¥ Pod, ç„¶åç”¨ curl è®¿é—® ngx-svcã€ngx-svc.default ç­‰åŸŸå: 


```shell

kubectl get pods
# NAME                       READY   STATUS    RESTARTS   AGE
# ngx-dep-6796688696-klnmr   1/1     Running   0          2d15h
# ngx-dep-6796688696-rvd42   1/1     Running   0          2d15h
# redis-ds-f67kg             1/1     Running   0          2d22h
# redis-ds-lzvxr             1/1     Running   0          2d22h
# redis-ds-xhr8n             1/1     Running   0          2d22h

kubectl exec -it ngx-dep-6796688696-klnmr -- sh

curl ngx-svc
# srv : 10.10.3.10:80
# host: ngx-dep-6796688696-rvd42
# uri : GET ngx-svc /
# date: 2023-04-03T02:02:18+00:00

curl ngx-svc.default
# srv : 10.10.3.10:80
# host: ngx-dep-6796688696-rvd42
# uri : GET ngx-svc.default /
# date: 2023-04-03T02:02:35+00:00

curl ngx-svc.default.svc.cluster.local
# srv : 10.10.2.10:80
# host: ngx-dep-6796688696-klnmr
# uri : GET ngx-svc.default.svc.cluster.local /
# date: 2023-04-03T02:02:51+00:00

exit

```

å¯ä»¥çœ‹åˆ°, ç°åœ¨æˆ‘ä»¬å°±ä¸å†å…³å¿ƒ Service å¯¹è±¡çš„ IP åœ°å€, åªéœ€è¦çŸ¥é“å®ƒçš„åå­—, å°±å¯ä»¥ç”¨ DNS çš„æ–¹å¼å»è®¿é—®åç«¯æœåŠ¡. 

æ¯”èµ· Docker, è¿™æ— ç–‘æ˜¯ä¸€ä¸ªå·¨å¤§çš„è¿›æ­¥, è€Œä¸”å¯¹æ¯”å…¶ä»–å¾®æœåŠ¡æ¡†æ¶ï¼ˆå¦‚ Dubboã€Spring Cloud), ç”±äºæœåŠ¡å‘ç°æœºåˆ¶è¢«é›†æˆåœ¨äº†åŸºç¡€è®¾æ–½é‡Œ, ä¹Ÿä¼šè®©åº”ç”¨çš„å¼€å‘æ›´åŠ ä¾¿æ·. 

Kubernetes ä¹Ÿä¸ºæ¯ä¸ª Pod åˆ†é…äº†åŸŸå, å½¢å¼æ˜¯ "IP åœ°å€. åå­—ç©ºé—´.pod.cluster.local", ä½†éœ€è¦æŠŠ IP åœ°å€é‡Œçš„ . æ”¹æˆ - . æ¯”å¦‚åœ°å€ 10.10.1.87, å®ƒå¯¹åº”çš„åŸŸåå°±æ˜¯ 10-10-1-87.default.pod

#### è®© Service å¯¹å¤–æš´éœ²æœåŠ¡

ç”±äº Service æ˜¯ä¸€ç§è´Ÿè½½å‡è¡¡æŠ€æœ¯, æ‰€ä»¥å®ƒä¸ä»…èƒ½å¤Ÿç®¡ç† Kubernetes é›†ç¾¤å†…éƒ¨çš„æœåŠ¡, è¿˜èƒ½å¤Ÿæ‹…å½“å‘é›†ç¾¤å¤–éƒ¨æš´éœ²æœåŠ¡çš„é‡ä»». 

Service å¯¹è±¡æœ‰ä¸€ä¸ªå…³é”®å­—æ®µ "type", è¡¨ç¤º Service æ˜¯å“ªç§ç±»å‹çš„è´Ÿè½½å‡è¡¡. å‰é¢æˆ‘ä»¬çœ‹åˆ°çš„ç”¨æ³•éƒ½æ˜¯å¯¹é›†ç¾¤å†…éƒ¨ Pod çš„è´Ÿè½½å‡è¡¡, æ‰€ä»¥è¿™ä¸ªå­—æ®µçš„å€¼å°±æ˜¯é»˜è®¤çš„ "ClusterIP", Service çš„é™æ€ IP åœ°å€åªèƒ½åœ¨é›†ç¾¤å†…è®¿é—®. 

é™¤äº† "ClusterIP", Service è¿˜æ”¯æŒå…¶ä»–ä¸‰ç§ç±»å‹, åˆ†åˆ«æ˜¯ "ExternalName" "LoadBalancer" "NodePort". ä¸è¿‡å‰ä¸¤ç§ç±»å‹ä¸€èˆ¬ç”±äº‘æœåŠ¡å•†æä¾›, æˆ‘ä»¬çš„å®éªŒç¯å¢ƒç”¨ä¸åˆ°, æ‰€ä»¥æ¥ä¸‹æ¥å°±é‡ç‚¹çœ‹ "NodePort"è¿™ä¸ªç±»å‹. 

å¦‚æœæˆ‘ä»¬åœ¨ä½¿ç”¨å‘½ä»¤ kubectl expose çš„æ—¶å€™åŠ ä¸Šå‚æ•° --type=NodePort, æˆ–è€…åœ¨ YAML é‡Œæ·»åŠ å­—æ®µ type:NodePort, é‚£ä¹ˆ Service é™¤äº†ä¼šå¯¹åç«¯çš„ Pod åšè´Ÿè½½å‡è¡¡ä¹‹å¤–, è¿˜ä¼šåœ¨é›†ç¾¤é‡Œçš„æ¯ä¸ªèŠ‚ç‚¹ä¸Šåˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„ç«¯å£, ç”¨è¿™ä¸ªç«¯å£å¯¹å¤–æä¾›æœåŠ¡, è¿™ä¹Ÿæ­£æ˜¯ "NodePort"è¿™ä¸ªåå­—çš„ç”±æ¥. 

ä¿®æ”¹ service.yml

```yaml

apiVersion: v1
kind: Service
metadata:
  name: ngx-svc

spec:
  selector:
    app: ngx-dep

  ports:
  - port: 80
    protocol: TCP
    targetPort: 80

  # é»˜è®¤ ClusterIP
  #type: ClusterIP
  type: NodePort

```

åˆ›å»ºå¹¶æŸ¥çœ‹ service å¯¹è±¡
å°±ä¼šçœ‹åˆ° "TYPE"å˜æˆäº† "NodePort", è€Œåœ¨ "PORT"åˆ—é‡Œçš„ç«¯å£ä¿¡æ¯ä¹Ÿä¸ä¸€æ ·, é™¤äº†é›†ç¾¤å†…éƒ¨ä½¿ç”¨çš„ "80"ç«¯å£, è¿˜å¤šå‡ºäº†ä¸€ä¸ª "30651"ç«¯å£, è¿™å°±æ˜¯ Kubernetes åœ¨èŠ‚ç‚¹ä¸Šä¸º Service åˆ›å»ºçš„ä¸“ç”¨æ˜ å°„ç«¯å£. 

```shell

kubectl get pod -o wide
# NAME                       READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES
# ngx-dep-6796688696-klnmr   1/1     Running   0          2d16h   10.10.2.10   worker01   <none>           <none>
# ngx-dep-6796688696-rvd42   1/1     Running   0          2d16h   10.10.3.10   worker02   <none>           <none>

kubectl get svc
# NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
# kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        4d21h
# ngx-dep      ClusterIP   10.100.240.45   <none>        80/TCP         2d22h
# ngx-svc      NodePort    10.104.67.95    <none>        80:31652/TCP   2d16h

kubectl get service
# NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
# kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        4d21h
# ngx-dep      ClusterIP   10.100.240.45   <none>        80/TCP         2d22h
# ngx-svc      NodePort    10.104.67.95    <none>        80:31652/TCP   2d16h

kubectl get services
# NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
# kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        4d21h
# ngx-dep      ClusterIP   10.100.240.45   <none>        80/TCP         2d22h
# ngx-svc      NodePort    10.104.67.95    <none>        80:31652/TCP   2d16h

```

å› ä¸ºè¿™ä¸ªç«¯å£å·å±äºèŠ‚ç‚¹, å¤–éƒ¨èƒ½å¤Ÿç›´æ¥è®¿é—®, æ‰€ä»¥ç°åœ¨æˆ‘ä»¬å°±å¯ä»¥ä¸ç”¨ç™»å½•é›†ç¾¤èŠ‚ç‚¹æˆ–è€…è¿›å…¥ Pod å†…éƒ¨, ç›´æ¥åœ¨é›†ç¾¤å¤–ä½¿ç”¨ä»»æ„ä¸€ä¸ªèŠ‚ç‚¹çš„ IP åœ°å€, å°±èƒ½å¤Ÿè®¿é—® Service å’Œå®ƒä»£ç†çš„åç«¯æœåŠ¡äº†. 

æ¯”å¦‚æˆ‘ç°åœ¨æ‰€åœ¨çš„æœåŠ¡å™¨æ˜¯ "192.168.10.208", åœ¨è¿™å°ä¸»æœºä¸Šç”¨ curl è®¿é—® Kubernetes é›†ç¾¤çš„ä¸¤ä¸ªèŠ‚ç‚¹ "192.168.10.210" "192.168.10.220", å°±å¯ä»¥å¾—åˆ° Nginx Pod çš„å“åº”æ•°æ®: 


```shell

curl 192.168.116.153:31652
# srv : 10.10.2.10:80
# host: ngx-dep-6796688696-klnmr
# uri : GET 192.168.116.153 /
# date: 2023-04-03T02:27:37+00:00

curl 192.168.116.154:31652
# srv : 10.10.3.10:80
# host: ngx-dep-6796688696-rvd42
# uri : GET 192.168.116.154 /
# date: 2023-04-03T02:27:42+00:00

```


### Ingress: é›†ç¾¤è¿›å‡ºæµé‡çš„æ€»ç®¡

Service å¯¹è±¡, å®ƒæ˜¯ Kubernetes å†…ç½®çš„è´Ÿè½½å‡è¡¡æœºåˆ¶, ä½¿ç”¨é™æ€ IP åœ°å€ä»£ç†åŠ¨æ€å˜åŒ–çš„ Pod, æ”¯æŒåŸŸåè®¿é—®å’ŒæœåŠ¡å‘ç°, æ˜¯å¾®æœåŠ¡æ¶æ„å¿…éœ€çš„åŸºç¡€è®¾æ–½. 

Service å¾ˆæœ‰ç”¨, ä½†ä¹Ÿåªèƒ½è¯´æ˜¯ "åŸºç¡€è®¾æ–½", å®ƒå¯¹ç½‘ç»œæµé‡çš„ç®¡ç†æ–¹æ¡ˆè¿˜æ˜¯å¤ªç®€å•, ç¦»å¤æ‚çš„ç°ä»£åº”ç”¨æ¶æ„éœ€æ±‚è¿˜æœ‰å¾ˆå¤§çš„å·®è·, æ‰€ä»¥ Kubernetes å°±åœ¨ Service ä¹‹ä¸Šåˆæå‡ºäº†ä¸€ä¸ªæ–°çš„æ¦‚å¿µ: Ingress. 

#### ä¸ºä»€ä¹ˆè¦æœ‰ Ingress

é€šè¿‡ä¸Šæ¬¡è¯¾ç¨‹çš„è®²è§£, æˆ‘ä»¬çŸ¥é“äº† Service çš„åŠŸèƒ½å’Œè¿è¡Œæœºåˆ¶, å®ƒæœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªç”± kube-proxy æ§åˆ¶çš„å››å±‚è´Ÿè½½å‡è¡¡, åœ¨ TCP/IP åè®®æ ˆä¸Šè½¬å‘æµé‡ï¼ˆService å·¥ä½œåŸç†ç¤ºæ„å›¾): 

https://kubernetes.io/zh-cn/docs/concepts/services-networking/service/


ä½†åœ¨å››å±‚ä¸Šçš„è´Ÿè½½å‡è¡¡åŠŸèƒ½è¿˜æ˜¯å¤ªæœ‰é™äº†, åªèƒ½å¤Ÿä¾æ® IP åœ°å€å’Œç«¯å£å·åšä¸€äº›ç®€å•çš„åˆ¤æ–­å’Œç»„åˆ, è€Œæˆ‘ä»¬ç°åœ¨çš„ç»å¤§å¤šæ•°åº”ç”¨éƒ½æ˜¯è·‘åœ¨ä¸ƒå±‚çš„ HTTP/HTTPS åè®®ä¸Šçš„, æœ‰æ›´å¤šçš„é«˜çº§è·¯ç”±æ¡ä»¶, æ¯”å¦‚ä¸»æœºåã€URIã€è¯·æ±‚å¤´ã€è¯ä¹¦ç­‰ç­‰, è€Œè¿™äº›åœ¨ TCP/IP ç½‘ç»œæ ˆé‡Œæ˜¯æ ¹æœ¬çœ‹ä¸è§çš„. 

Service è¿˜æœ‰ä¸€ä¸ªç¼ºç‚¹, å®ƒæ¯”è¾ƒé€‚åˆä»£ç†é›†ç¾¤å†…éƒ¨çš„æœåŠ¡. å¦‚æœæƒ³è¦æŠŠæœåŠ¡æš´éœ²åˆ°é›†ç¾¤å¤–éƒ¨, å°±åªèƒ½ä½¿ç”¨ NodePort æˆ–è€… LoadBalancer è¿™ä¸¤ç§æ–¹å¼, è€Œå®ƒä»¬éƒ½ç¼ºä¹è¶³å¤Ÿçš„çµæ´»æ€§, éš¾ä»¥ç®¡æ§, è¿™å°±å¯¼è‡´äº†ä¸€ç§å¾ˆæ— å¥ˆçš„å±€é¢: æˆ‘ä»¬çš„æœåŠ¡ç©ºæœ‰ä¸€èº«æœ¬é¢†, å´æ²¡æœ‰åˆé€‚çš„æœºä¼šèµ°å‡ºå»å¤§å±•æ‹³è„š. 

Ingress, æ„æ€å°±æ˜¯é›†ç¾¤å†…å¤–è¾¹ç•Œä¸Šçš„å…¥å£, åœ¨ä¸ƒå±‚ä¸Šåšè´Ÿè½½å‡è¡¡

é™¤äº†ä¸ƒå±‚è´Ÿè½½å‡è¡¡, è¿™ä¸ªå¯¹è±¡è¿˜åº”è¯¥æ‰¿æ‹…æ›´å¤šçš„èŒè´£, ä¹Ÿå°±æ˜¯ä½œä¸ºæµé‡çš„æ€»å…¥å£, ç»Ÿç®¡é›†ç¾¤çš„è¿›å‡ºå£æ•°æ®, "æ‰‡å…¥" "æ‰‡å‡º"æµé‡ï¼ˆä¹Ÿå°±æ˜¯æˆ‘ä»¬å¸¸è¯´çš„ "å—åŒ—å‘"), è®©å¤–éƒ¨ç”¨æˆ·èƒ½å¤Ÿå®‰å…¨ã€é¡ºç•…ã€ä¾¿æ·åœ°è®¿é—®å†…éƒ¨æœåŠ¡ï¼ˆå›¾ç‰‡æ¥æº): 


#### ä¸ºä»€ä¹ˆè¦æœ‰ Ingress Controller

Ingress å¯ä»¥è¯´æ˜¯åœ¨ä¸ƒå±‚ä¸Šå¦ä¸€ç§å½¢å¼çš„ Serviceï¼Œå®ƒåŒæ ·ä¼šä»£ç†ä¸€äº›åç«¯çš„ Podï¼Œä¹Ÿæœ‰ä¸€äº›è·¯ç”±è§„åˆ™æ¥å®šä¹‰æµé‡åº”è¯¥å¦‚ä½•åˆ†é…ã€è½¬å‘ï¼Œåªä¸è¿‡è¿™äº›è§„åˆ™éƒ½ä½¿ç”¨çš„æ˜¯ HTTP/HTTPS åè®®ã€‚

ä½ åº”è¯¥çŸ¥é“ï¼ŒService æœ¬èº«æ˜¯æ²¡æœ‰æœåŠ¡èƒ½åŠ›çš„ï¼Œå®ƒåªæ˜¯ä¸€äº› iptables è§„åˆ™ï¼ŒçœŸæ­£é…ç½®ã€åº”ç”¨è¿™äº›è§„åˆ™çš„å®é™…ä¸Šæ˜¯èŠ‚ç‚¹é‡Œçš„ kube-proxy ç»„ä»¶ã€‚å¦‚æœæ²¡æœ‰ kube-proxyï¼ŒService å®šä¹‰å¾—å†å®Œå–„ä¹Ÿæ²¡æœ‰ç”¨ã€‚

åŒæ ·çš„ï¼ŒIngress ä¹Ÿåªæ˜¯ä¸€äº› HTTP è·¯ç”±è§„åˆ™çš„é›†åˆï¼Œç›¸å½“äºä¸€ä»½é™æ€çš„æè¿°æ–‡ä»¶ï¼ŒçœŸæ­£è¦æŠŠè¿™äº›è§„åˆ™åœ¨é›†ç¾¤é‡Œå®æ–½è¿è¡Œï¼Œè¿˜éœ€è¦æœ‰å¦å¤–ä¸€ä¸ªä¸œè¥¿ï¼Œè¿™å°±æ˜¯ Ingress Controllerï¼Œå®ƒçš„ä½œç”¨å°±ç›¸å½“äº Service çš„ kube-proxyï¼Œèƒ½å¤Ÿè¯»å–ã€åº”ç”¨ Ingress è§„åˆ™ï¼Œå¤„ç†ã€è°ƒåº¦æµé‡ã€‚

ä¸è¿‡ Ingress Controller è¦åšçš„äº‹æƒ…å¤ªå¤šï¼Œä¸ä¸Šå±‚ä¸šåŠ¡è”ç³»å¤ªå¯†åˆ‡ï¼Œæ‰€ä»¥ Kubernetes æŠŠ Ingress Controller çš„å®ç°äº¤ç»™äº†ç¤¾åŒºï¼Œä»»ä½•äººéƒ½å¯ä»¥å¼€å‘ Ingress Controllerï¼Œåªè¦éµå®ˆ Ingress è§„åˆ™å°±å¥½ã€‚


Nginx æ˜¯å¼€æºçš„ï¼Œè°éƒ½å¯ä»¥åŸºäºæºç åšäºŒæ¬¡å¼€å‘ï¼Œæ‰€ä»¥å®ƒåˆæœ‰å¾ˆå¤šçš„å˜ç§ï¼Œæ¯”å¦‚ç¤¾åŒºçš„ Kubernetes Ingress Controllerï¼ˆhttps://github.com/kubernetes/ingress-nginxï¼‰ã€Nginx å…¬å¸è‡ªå·±çš„ Nginx Ingress Controllerï¼ˆhttps://github.com/nginxinc/kubernetes-ingressï¼‰ã€è¿˜æœ‰åŸºäº OpenResty çš„ Kong Ingress Controllerï¼ˆhttps://github.com/Kong/kubernetes-ingress-controllerï¼‰ç­‰ç­‰ã€‚


#### ä¸ºä»€ä¹ˆè¦æœ‰ IngressClass

ä¸€ä¸ªé›†ç¾¤é‡Œæœ‰ä¸€ä¸ª Ingress Controllerï¼Œå†ç»™å®ƒé…ä¸Šè®¸å¤šä¸åŒçš„ Ingress è§„åˆ™ï¼Œåº”è¯¥å°±å¯ä»¥è§£å†³è¯·æ±‚çš„è·¯ç”±å’Œåˆ†å‘é—®é¢˜äº†ã€‚

ä½†éšç€ Ingress åœ¨å®è·µä¸­çš„å¤§é‡åº”ç”¨ï¼Œå¾ˆå¤šç”¨æˆ·å‘ç°è¿™ç§ç”¨æ³•ä¼šå¸¦æ¥ä¸€äº›é—®é¢˜ï¼Œ

æ‰€ä»¥ï¼ŒKubernetes å°±åˆæå‡ºäº†ä¸€ä¸ª Ingress Class çš„æ¦‚å¿µï¼Œè®©å®ƒæ’åœ¨ Ingress å’Œ Ingress Controller ä¸­é—´ï¼Œä½œä¸ºæµé‡è§„åˆ™å’Œæ§åˆ¶å™¨çš„åè°ƒäººï¼Œè§£é™¤äº† Ingress å’Œ Ingress Controller çš„å¼ºç»‘å®šå…³ç³»ã€‚

ç°åœ¨ï¼ŒKubernetes ç”¨æˆ·å¯ä»¥è½¬å‘ç®¡ç† Ingress Classï¼Œç”¨å®ƒæ¥å®šä¹‰ä¸åŒçš„ä¸šåŠ¡é€»è¾‘åˆ†ç»„ï¼Œç®€åŒ– Ingress è§„åˆ™çš„å¤æ‚åº¦ã€‚æ¯”å¦‚è¯´ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ Class A å¤„ç†åšå®¢æµé‡ã€Class B å¤„ç†çŸ­è§†é¢‘æµé‡ã€Class C å¤„ç†è´­ç‰©æµé‡ã€‚


```shell

kubectl api-resources | grep ingress
# ingressclasses               networking.k8s.io/v1       false        IngressClass
# ingresses        ing         networking.k8s.io/v1       true         Ingress

```

Ingress Controller å’Œå…¶ä»–ä¸¤ä¸ªå¯¹è±¡ä¸å¤ªä¸€æ ·ï¼Œå®ƒä¸åªæ˜¯æè¿°æ–‡ä»¶ï¼Œæ˜¯ä¸€ä¸ªè¦å®é™…å¹²æ´»ã€å¤„ç†æµé‡çš„åº”ç”¨ç¨‹åºï¼Œè€Œåº”ç”¨ç¨‹åºåœ¨ Kubernetes é‡Œæ—©å°±æœ‰å¯¹è±¡æ¥ç®¡ç†äº†ï¼Œé‚£å°±æ˜¯ Deployment å’Œ DaemonSet



```shell
# ç”Ÿæˆ ingress æè¿°æ–‡ä»¶
export out="--dry-run=client -o yaml"
kubectl create ing ngx-ing --rule="ngx.test/=ngx-svc:80" --class=ngx-ink $out

```

--classï¼ŒæŒ‡å®š Ingress ä»å±çš„ Ingress Class å¯¹è±¡ã€‚

--ruleï¼ŒæŒ‡å®šè·¯ç”±è§„åˆ™ï¼ŒåŸºæœ¬å½¢å¼æ˜¯â€œURI=Serviceâ€ï¼Œä¹Ÿå°±æ˜¯è¯´æ˜¯è®¿é—® HTTP è·¯å¾„å°±è½¬å‘åˆ°å¯¹åº”çš„ Service å¯¹è±¡ï¼Œå†ç”± Service å¯¹è±¡è½¬å‘ç»™åç«¯çš„ Podã€‚

```yaml


apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ngx-ing
  
spec:
  # --class=ngx-ink
  ingressClassName: ngx-ink
  
  # --rule="ngx.test/=ngx-svc:80"
  # rules æŠŠè·¯ç”±è§„åˆ™æ‹†æ•£äº†ï¼Œæœ‰ host å’Œ http pathï¼Œåœ¨ path é‡ŒåˆæŒ‡å®šäº†è·¯å¾„çš„åŒ¹é…æ–¹å¼ï¼Œ
  # å¯ä»¥æ˜¯ç²¾ç¡®åŒ¹é…ï¼ˆExactï¼‰æˆ–è€…æ˜¯å‰ç¼€åŒ¹é…ï¼ˆPrefixï¼‰ï¼Œå†ç”¨ backend æ¥æŒ‡å®šè½¬å‘çš„ç›®æ ‡ Service å¯¹è±¡
  rules:
  - host: ngx.test
    http:
      paths:
      - path: /
        # ç²¾ç¡®åŒ¹é…ï¼ˆExactï¼‰æˆ–è€…æ˜¯å‰ç¼€åŒ¹é…ï¼ˆPrefix)
        pathType: Exact
        # backend æ¥æŒ‡å®šè½¬å‘çš„ç›®æ ‡ Service å¯¹è±¡
        backend:
          service:
            name: ngx-svc
            port:
              number: 80

```



Ingress Class æœ¬èº«å¹¶æ²¡æœ‰ä»€ä¹ˆå®é™…çš„åŠŸèƒ½ï¼Œåªæ˜¯èµ·åˆ°è”ç³» Ingress å’Œ Ingress Controller çš„ä½œç”¨ï¼Œæ‰€ä»¥å®ƒçš„å®šä¹‰éå¸¸ç®€å•ï¼Œåœ¨â€œspecâ€é‡Œåªæœ‰ä¸€ä¸ªå¿…éœ€çš„å­—æ®µâ€œcontrollerâ€ï¼Œè¡¨ç¤ºè¦ä½¿ç”¨å“ªä¸ª Ingress Controller

æ¯”å¦‚ï¼Œå¦‚æœæˆ‘è¦ç”¨ Nginx å¼€å‘çš„ Ingress Controllerï¼Œé‚£ä¹ˆå°±è¦ç”¨åå­—â€œnginx.org/ingress-controllerâ€ï¼š

```yaml
# ingress-class.yml

apiVersion: networking.k8s.io/v1
kind: IngressClass
metadata:
  name: ngx-ink

spec:
  controller: nginx.org/ingress-controller

```



æŠŠ ingress class å’Œ ingress åˆå¹¶æˆä¸€ä¸ª yml æ–‡ä»¶



```yaml
# ingress.yml

# kubectl create ing ngx-ing --rule="ngx.test/=ngx-svc:80" $out
# kubectl create ing ngx-ing --rule="ngx.test/=ngx-svc:80" --class=ngx-ink $out

# https://docs.nginx.com/nginx-ingress-controller/

# curl 127.1/nginx-health
# curl 127.1:8081/nginx-ready

---
# ingress class
apiVersion: networking.k8s.io/v1
kind: IngressClass
metadata:
  name: ngx-ink

spec:
  controller: nginx.org/ingress-controller

---

# ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ngx-ing

  # customize the behaviors of nginx
  annotations:
    nginx.org/lb-method: round_robin

spec:
  ingressClassName: ngx-ink

  rules:
  - host: ngx.test
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: ngx-svc
            port:
              number: 80
---


```

```shell

kubectl apply -f ingress.yml
# ingressclass.networking.k8s.io/ngx-ink created
# ingress.networking.k8s.io/ngx-ing created

kubectl get ingressclass
# NAME      CONTROLLER                     PARAMETERS   AGE
# ngx-ink   nginx.org/ingress-controller   <none>       11s

kubectl get ingress
# NAME      CLASS     HOSTS      ADDRESS   PORTS   AGE
# ngx-ing   ngx-ink   ngx.test             80      20s

# Ingress å¯¹è±¡çš„è·¯ç”±è§„åˆ™ Host/Path å°±æ˜¯åœ¨ YAML é‡Œè®¾ç½®çš„åŸŸåâ€œngx.test/â€ï¼Œ
# è€Œä¸”å·²ç»å…³è”äº†ç¬¬ 20 è®²é‡Œåˆ›å»ºçš„ Service å¯¹è±¡ï¼Œè¿˜æœ‰ Service åé¢çš„ä¸¤ä¸ª Podã€‚
# ä¸è¦å¯¹ Ingress é‡Œâ€œDefault backendâ€çš„é”™è¯¯æç¤ºæ„Ÿåˆ°æƒŠè®¶ï¼Œåœ¨æ‰¾ä¸åˆ°è·¯ç”±çš„æ—¶å€™ï¼Œ
# å®ƒè¢«è®¾è®¡ç”¨æ¥æä¾›ä¸€ä¸ªé»˜è®¤çš„åç«¯æœåŠ¡ï¼Œä½†ä¸è®¾ç½®ä¹Ÿä¸ä¼šæœ‰ä»€ä¹ˆé—®é¢˜ï¼Œæ‰€ä»¥å¤§å¤šæ•°æ—¶å€™æˆ‘ä»¬éƒ½å¿½ç•¥å®ƒã€‚
kubectl describe ing ngx-ing
# Name:             ngx-ing
# Labels:           <none>
# Namespace:        default
# Address:
# Default backend:  default-http-backend:80 (<error: endpoints "default-http-backend" not found>)
# Rules:
#   Host        Path  Backends
#   ----        ----  --------
#   ngx.test
#               /   ngx-svc:80 (10.10.2.10:80,10.10.3.10:80)
# Annotations:  nginx.org/lb-method: round_robin
# Events:       <none>

```

#### Ingress Controller

Nginx Ingress Controller çš„é¡¹ç›®
https://github.com/nginxinc/kubernetes-ingress
å› ä¸ºå®ƒä»¥ Pod çš„å½¢å¼è¿è¡Œåœ¨ Kubernetes é‡Œï¼Œæ‰€ä»¥åŒæ—¶æ”¯æŒ Deployment å’Œ DaemonSet ä¸¤ç§éƒ¨ç½²æ–¹å¼ã€‚

è¿™é‡Œé€‰æ‹©çš„æ˜¯ Deploymentï¼Œç›¸å…³çš„ YAML ä¹Ÿéƒ½åœ¨ä»¥ä¸‹é¡¹ç›®é‡Œå¤åˆ¶äº†ä¸€ä»½ã€‚
https://github.com/chronolaw/k8s_study/tree/master/ingress

Nginx Ingress Controller çš„å®‰è£…ç•¥å¾®éº»çƒ¦ä¸€äº›ï¼Œæœ‰å¾ˆå¤šä¸ª YAML éœ€è¦æ‰§è¡Œï¼Œä½†å¦‚æœåªæ˜¯åšç®€å•çš„è¯•éªŒï¼Œå°±åªéœ€è¦ç”¨åˆ° 4 ä¸ª YAMLï¼š

```shell


kubectl apply -f common/ns-and-sa.yaml
kubectl apply -f rbac/rbac.yaml
kubectl apply -f common/nginx-config.yaml
kubectl apply -f common/default-server-secret.yaml

```

å‰ä¸¤æ¡å‘½ä»¤ä¸º Ingress Controller åˆ›å»ºäº†ä¸€ä¸ªç‹¬ç«‹çš„åå­—ç©ºé—´â€œnginx-ingressâ€ï¼Œè¿˜æœ‰ç›¸åº”çš„è´¦å·å’Œæƒé™ï¼Œè¿™æ˜¯ä¸ºäº†è®¿é—® apiserver è·å– Serviceã€Endpoint ä¿¡æ¯ç”¨çš„ï¼›åä¸¤æ¡åˆ™æ˜¯åˆ›å»ºäº†ä¸€ä¸ª ConfigMap å’Œ Secretï¼Œç”¨æ¥é…ç½® HTTP/HTTPS æœåŠ¡ã€‚

éƒ¨ç½² Ingress Controller ä¸éœ€è¦æˆ‘ä»¬è‡ªå·±ä»å¤´ç¼–å†™ Deploymentï¼ŒNginx å·²ç»ä¸ºæˆ‘ä»¬æä¾›äº†ç¤ºä¾‹ YAMLï¼Œä½†åˆ›å»ºä¹‹å‰ä¸ºäº†é€‚é…æˆ‘ä»¬è‡ªå·±çš„åº”ç”¨è¿˜å¿…é¡»è¦åšå‡ å¤„å°æ”¹åŠ¨ï¼š

- metadata é‡Œçš„ name è¦æ”¹æˆè‡ªå·±çš„åå­—ï¼Œæ¯”å¦‚ ngx-kic-depã€‚
- spec.selector å’Œ template.metadata.labels ä¹Ÿè¦ä¿®æ”¹æˆè‡ªå·±çš„åå­—ï¼Œæ¯”å¦‚è¿˜æ˜¯ç”¨ ngx-kic-depã€‚
- containers.image å¯ä»¥æ”¹ç”¨ apline ç‰ˆæœ¬ï¼ŒåŠ å¿«ä¸‹è½½é€Ÿåº¦ï¼Œæ¯”å¦‚ nginx/nginx-ingress:2.2-alpineã€‚
- æœ€ä¸‹é¢çš„ args è¦åŠ ä¸Š -ingress-class=ngx-inkï¼Œä¹Ÿå°±æ˜¯å‰é¢åˆ›å»ºçš„ Ingress Class çš„åå­—ï¼Œè¿™æ˜¯è®© Ingress Controller ç®¡ç† Ingress çš„å…³é”®ã€‚

ä¿®æ”¹å®Œä¹‹åï¼ŒIngress Controller çš„ YAML å¤§æ¦‚æ˜¯è¿™ä¸ªæ ·å­ï¼š

```shell

apiVersion: apps/v1
kind: Deployment
metadata:
  name: ngx-kic-dep
  namespace: nginx-ingress

spec:
  replicas: 1
  selector:
    matchLabels:
      app: ngx-kic-dep

  template:
    metadata:
      labels:
        app: ngx-kic-dep
    ...
    spec:
      containers:
      - image: nginx/nginx-ingress:2.2-alpine
        ...
        args:
          - -ingress-class=ngx-ink

```

ç¡®è®¤ Ingress Controller çš„ YAML ä¿®æ”¹å®Œæ¯•ä¹‹åï¼Œå°±å¯ä»¥ç”¨ kubectl apply åˆ›å»ºå¯¹è±¡ï¼š

```shell


kubectl apply -f kic.yml

```

æ³¨æ„ Ingress Controller ä½äºåå­—ç©ºé—´â€œnginx-ingressâ€ï¼Œæ‰€ä»¥æŸ¥çœ‹çŠ¶æ€éœ€è¦ç”¨â€œ-nâ€å‚æ•°æ˜¾å¼æŒ‡å®šï¼Œå¦åˆ™æˆ‘ä»¬åªèƒ½çœ‹åˆ°â€œdefaultâ€åå­—ç©ºé—´é‡Œçš„ Podï¼š

```shell

kubectl get deploy -n nginx-ingress
kubectl get pod -n nginx-ingress

```

ä¸è¿‡è¿˜æœ‰æœ€åä¸€é“å·¥åºï¼Œå› ä¸º Ingress Controller æœ¬èº«ä¹Ÿæ˜¯ä¸€ä¸ª Podï¼Œæƒ³è¦å‘å¤–æä¾›æœåŠ¡è¿˜æ˜¯è¦ä¾èµ–äº Service å¯¹è±¡ã€‚æ‰€ä»¥ä½ è‡³å°‘è¿˜è¦å†ä¸ºå®ƒå®šä¹‰ä¸€ä¸ª Serviceï¼Œä½¿ç”¨ NodePort æˆ–è€… LoadBalancer æš´éœ²ç«¯å£ï¼Œæ‰èƒ½çœŸæ­£æŠŠé›†ç¾¤çš„å†…å¤–æµé‡æ‰“é€šã€‚è¿™ä¸ªå·¥ä½œå°±äº¤ç»™ä½ è¯¾ä¸‹è‡ªå·±å»å®Œæˆäº†ã€‚

è¿™é‡Œï¼Œæˆ‘å°±ç”¨ç¬¬ 15 è®²é‡Œæåˆ°çš„å‘½ä»¤kubectl port-forwardï¼Œå®ƒå¯ä»¥ç›´æ¥æŠŠæœ¬åœ°çš„ç«¯å£æ˜ å°„åˆ° Kubernetes é›†ç¾¤çš„æŸä¸ª Pod é‡Œï¼Œåœ¨æµ‹è¯•éªŒè¯çš„æ—¶å€™éå¸¸æ–¹ä¾¿ã€‚

ä¸‹é¢è¿™æ¡å‘½ä»¤å°±æŠŠæœ¬åœ°çš„ 8080 ç«¯å£æ˜ å°„åˆ°äº† Ingress Controller Pod çš„ 80 ç«¯å£ï¼š

```shell


kubectl port-forward -n nginx-ingress ngx-kic-dep-8859b7b86-cplgp 8080:80 &

```

æˆ‘ä»¬åœ¨ curl å‘æµ‹è¯•è¯·æ±‚çš„æ—¶å€™éœ€è¦æ³¨æ„ï¼Œå› ä¸º Ingress çš„è·¯ç”±è§„åˆ™æ˜¯ HTTP åè®®ï¼Œæ‰€ä»¥å°±ä¸èƒ½ç”¨ IP åœ°å€çš„æ–¹å¼è®¿é—®ï¼Œå¿…é¡»è¦ç”¨åŸŸåã€URIã€‚

ä½ å¯ä»¥ä¿®æ”¹ /etc/hosts æ¥æ‰‹å·¥æ·»åŠ åŸŸåè§£æï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ --resolve å‚æ•°ï¼ŒæŒ‡å®šåŸŸåçš„è§£æè§„åˆ™ï¼Œæ¯”å¦‚åœ¨è¿™é‡Œæˆ‘å°±æŠŠâ€œngx.testâ€å¼ºåˆ¶è§£æåˆ°â€œ127.0.0.1â€ï¼Œä¹Ÿå°±æ˜¯è¢« kubectl port-forward è½¬å‘çš„æœ¬åœ°åœ°å€ï¼š

```shell

curl --resolve ngx.test:8080:127.0.0.1 http://ngx.test:8080

```

æŠŠè¿™ä¸ªè®¿é—®ç»“æœå’Œä¸Šä¸€èŠ‚è¯¾é‡Œçš„ Service å¯¹æ¯”ä¸€ä¸‹ï¼Œä½ ä¼šå‘ç°æœ€ç»ˆæ•ˆæœæ˜¯ä¸€æ ·çš„ï¼Œéƒ½æ˜¯æŠŠè¯·æ±‚è½¬å‘åˆ°äº†é›†ç¾¤å†…éƒ¨çš„ Podï¼Œä½† Ingress çš„è·¯ç”±è§„åˆ™ä¸å†æ˜¯ IP åœ°å€ï¼Œè€Œæ˜¯ HTTP åè®®é‡Œçš„åŸŸåã€URI ç­‰è¦ç´ ã€‚

